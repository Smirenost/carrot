{"version":3,"sources":["../../../src/enums/ConnectionType.ts","../../../src/enums/NodeType.ts","../../../src/utils/Utils.ts","../../../src/methods/Mutation.ts","../../../src/architecture/Connection.ts","../../../src/architecture/Node.ts","../../../src/enums/GatingType.ts","../../../../src/architecture/Layers/Layer.ts","../../../../src/architecture/Nodes/ConstantNode.ts","../../../../src/architecture/Nodes/NoiseNode.ts","../../../../../src/architecture/Layers/NoiseLayers/NoiseLayer.ts","../../../../../src/architecture/Layers/CoreLayers/InputLayer.ts","../../../../../src/architecture/Layers/CoreLayers/OutputLayer.ts","../../../src/methods/Loss.ts","../../../src/methods/Selection.ts","../../../src/interfaces/EvolveOptions.ts","../../../src/architecture/Species.ts","../../src/NEAT.ts","../../../src/architecture/Network.ts","../../../src/architecture/Architect.ts","../../../../src/architecture/Nodes/ActivationNode.ts","../../../../../src/architecture/Layers/CoreLayers/ActivationLayer.ts","../../../../../src/architecture/Layers/CoreLayers/DenseLayer.ts","../../../../src/architecture/Nodes/DropoutNode.ts","../../../../../src/architecture/Layers/CoreLayers/DropoutLayer.ts","../../../../src/architecture/Nodes/PoolNode.ts","../../../../../src/architecture/Layers/PoolingLayers/PoolingLayer.ts","../../../../../src/architecture/Layers/PoolingLayers/AvgPooling1DLayer.ts","../../../../../src/architecture/Layers/PoolingLayers/GlobalAvgPooling1DLayer.ts","../../../../../src/architecture/Layers/PoolingLayers/MaxPooling1DLayer.ts","../../../../../src/architecture/Layers/PoolingLayers/GlobalMaxPooling1DLayer.ts","../../../../../src/architecture/Layers/PoolingLayers/MinPooling1DLayer.ts","../../../../../src/architecture/Layers/PoolingLayers/GlobalMinPooling1DLayer.ts","../../../../../src/architecture/Layers/RecurrentLayers/GRULayer.ts","../../../../../src/architecture/Layers/RecurrentLayers/HopfieldLayer.ts","../../../../../src/architecture/Layers/RecurrentLayers/LSTMLayer.ts","../../../../../src/architecture/Layers/RecurrentLayers/MemoryLayer.ts","../../../../../src/architecture/Layers/RecurrentLayers/RNNLayer.ts","../../../src/methods/Rate.ts","../../../src/interfaces/TrainOptions.ts","../../scripts/index.ts"],"names":[],"mappings":";AAGA,aAAA,IAAY,EAAZ,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,oBAAA,EAAA,SAAY,GAIV,EAAA,EAAA,cAAA,GAAA,gBAIA,EAAA,EAAA,WAAA,GAAA,aAIA,EAAA,EAAA,WAAA,GAAA,aAIA,EAAA,EAAA,QAAA,GAAA,UAhBF,CAAY,EAAA,QAAA,iBAAA,QAAA,eAAc;;ACoC1B,aApCA,IAAY,EAkBA,EAkBA,EAAZ,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,cAAA,QAAA,aAAA,QAAA,cAAA,EApCA,SAAY,GAIV,EAAA,EAAA,MAAA,GAAA,QAIA,EAAA,EAAA,OAAA,GAAA,SAIA,EAAA,EAAA,OAAA,GAAA,SAZF,CAAY,EAAA,QAAA,WAAA,QAAA,SAAQ,KAkBpB,SAAY,GAIV,EAAA,EAAA,YAAA,GAAA,cAIA,EAAA,EAAA,YAAA,GAAA,cAIA,EAAA,EAAA,YAAA,GAAA,cAZF,CAAY,EAAA,QAAA,eAAA,QAAA,aAAY,KAkBxB,SAAY,GAIV,EAAA,EAAA,eAAA,GAAA,iBAJF,CAAY,EAAA,QAAA,gBAAA,QAAA,cAAa;;AC+LvB,aAhOF,SAAS,EAAc,GACjB,GAAA,MAAM,QAAQ,GAAM,CAClB,GAAe,IAAf,EAAI,OACA,MAAA,IAAI,WAAW,mCAEhB,OAAA,EAAI,EAAQ,EAAG,EAAI,SAEnB,OAAA,EAAW,MAAM,KAAK,IAWjC,SAAS,EAAQ,EAAa,GACrB,OAAA,KAAK,MAAM,KAAK,UAAY,EAAM,GAAO,GAUlD,SAAS,EAAW,EAAa,GACxB,OAAA,KAAK,UAAY,EAAM,GAAO,EAQvC,SAAS,IACA,OAAA,KAAK,UAAY,GAU1B,SAAS,EAAmB,EAAU,GAC9B,MAAA,EAAgB,EAAI,QAAQ,GAC9B,OAAW,IAAX,IAGF,EAAI,OAAO,EAAO,IACX,GASX,SAAS,EAAW,GAEb,IAAA,IAAI,EAAkB,EAAM,OAAS,EAAG,EAAU,EAAG,IAAW,CAE7D,MAAA,EAAgB,EAAQ,EAAG,GAG3B,EAAU,EAAM,GACtB,EAAM,GAAW,EAAM,GACvB,EAAM,GAAS,GASnB,SAAS,EAAI,GACP,GAAiB,IAAjB,EAAM,OACF,MAAA,IAAI,WAER,IAAA,EAAmB,EAAM,GACxB,IAAA,IAAI,EAAI,EAAG,EAAI,EAAM,OAAQ,IAC5B,EAAM,GAAK,IACb,EAAW,EAAM,IAGd,OAAA,EAQT,SAAS,EAAc,GACjB,GAAiB,IAAjB,EAAM,OACF,MAAA,IAAI,WAER,IAAA,EAAmB,EAAM,GACzB,EAAgB,EACf,IAAA,IAAI,EAAI,EAAG,EAAI,EAAM,OAAQ,IAC5B,EAAM,GAAK,IACb,EAAW,EAAM,GACjB,EAAgB,GAGb,OAAA,EAQT,SAAS,EAAc,GACjB,GAAiB,IAAjB,EAAM,OACF,MAAA,IAAI,WAER,IAAA,EAAmB,EAAM,GACzB,EAAgB,EACf,IAAA,IAAI,EAAI,EAAG,EAAI,EAAM,OAAQ,IAC5B,EAAM,GAAK,IACb,EAAW,EAAM,GACjB,EAAgB,GAGb,OAAA,EAQT,SAAS,EAAI,GACP,GAAiB,IAAjB,EAAM,OACF,MAAA,IAAI,WAER,IAAA,EAAmB,EAAM,GACxB,IAAA,IAAI,EAAI,EAAG,EAAI,EAAM,OAAQ,IAC5B,EAAM,GAAK,IACb,EAAW,EAAM,IAGd,OAAA,EAQT,SAAS,EAAI,GACJ,OAAA,EAAI,GAAS,EAAM,OAQ5B,SAAS,EAAI,GACP,GAAiB,IAAjB,EAAM,OACF,MAAA,IAAI,WAER,IAAA,EAAM,EACL,IAAA,MAAM,KAAS,EAClB,GAAO,EAEF,OAAA,EAWT,SAAS,EAAiB,EAAO,EAAG,EAAY,GAC1C,IAAA,EAAM,EAEL,IAAA,IAAI,EAAI,EAAG,EADG,GACa,IAC9B,GAAO,KAAK,SAGN,OAAA,EAAY,EALD,GAKqB,EAAO,GAAM,EAavD,SAAS,EAAQ,EAAW,GAClB,MAAA,IAAU,EAAI,IAAM,EAAI,EAAI,GAAK,EAiBzC,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,QAAA,QAAA,iBAAA,QAAA,IAAA,QAAA,IAAA,QAAA,IAAA,QAAA,cAAA,QAAA,cAAA,QAAA,IAAA,QAAA,QAAA,QAAA,gBAAA,QAAA,YAAA,QAAA,WAAA,QAAA,QAAA,QAAA,gBAAA,EAbA,QAAA,WAAA,EACA,QAAA,QAAA,EACA,QAAA,WAAA,EACA,QAAA,YAAA,EACA,QAAA,gBAAA,EACA,QAAA,QAAA,EACA,QAAA,IAAA,EACA,QAAA,cAAA,EACA,QAAA,cAAA,EACA,QAAA,IAAA,EAEA,QAAA,IAAA,EADA,QAAA,IAAA,EAEA,QAAA,iBAAA,EACA,QAAA,QAAA;;ACiYA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,kBAAA,QAAA,0BAAA,QAAA,0BAAA,QAAA,0BAAA,QAAA,0BAAA,QAAA,gBAAA,QAAA,gBAAA,QAAA,sBAAA,QAAA,gBAAA,QAAA,kBAAA,QAAA,sBAAA,QAAA,sBAAA,QAAA,gBAAA,QAAA,gBAAA,QAAA,SAAA,QAAA,eAAA,QAAA,uBAAA,QAAA,sBAAA,QAAA,mBAAA,EApmBF,MAAA,EAAA,QAAA,wBACA,EAAA,QAAA,qBACA,EAAA,QAAA,kBASA,MAAe,GA0lBb,QAAA,SAAA,EAvjBF,MAAM,UAAwB,EAU5B,YAAY,GAAmB,GAC7B,QACK,KAAA,iBAAmB,EASnB,OACL,EACA,EAKI,IAIF,QAAqB,IAArB,EAAQ,UACR,EAAQ,MAAM,QAAU,EAAQ,SAEhC,OAGI,MAAA,EAAa,IAAI,EAAA,KAAK,EAAA,SAAS,QACjC,KAAK,kBACP,EAAK,mBAGD,MAAA,EAAyB,EAAA,WAAW,MAAM,KAAK,EAAQ,cACvD,EAAa,EAAW,KACxB,EAAW,EAAW,GAC5B,EAAQ,WAAW,EAAM,GAGnB,MAAA,EAAmB,KAAK,IAC5B,EAAQ,UACR,EAAI,EAAQ,MAAM,QAAQ,IAE5B,EAAQ,MAAM,OAAO,EAAU,EAAG,GAC5B,MAAA,EAA6B,EAAQ,QAAQ,EAAM,EAAM,GACzD,EAA6B,EAAQ,QACzC,EACA,EACA,EAAW,QAGe,OAAxB,EAAW,WAGT,EAAA,cACF,EAAQ,QAAQ,EAAW,SAAU,GAErC,EAAQ,QAAQ,EAAW,SAAU,KAqf3C,QAAA,gBAAA,EA1eF,MAAM,UAAwB,EAM5B,YAAY,GAAY,GACtB,QACK,KAAA,UAAY,EAQZ,OAAO,GACN,MAAA,EAAmB,EAAQ,MAAM,OACrC,QAAiB,IAAT,GAAsB,EAAK,gBAEjC,EAAS,OAAS,GACpB,EAAQ,WAAW,EAAA,WAAW,GAAW,KAAK,YAsdlD,QAAA,gBAAA,EA5cF,MAAM,UAA8B,EAO3B,OACL,EACA,EAKI,IAIF,QAA2B,IAA3B,EAAQ,gBACR,EAAQ,YAAY,MAAQ,EAAQ,eAEpC,OAEI,MAAA,EAAqB,GAEtB,IAAA,IAAI,EAAI,EAAG,EAAI,EAAQ,MAAM,OAAS,EAAQ,WAAY,IAAK,CAC5D,MAAA,EAAa,EAAQ,MAAM,GAE/B,IAAA,IAAI,EAAY,KAAK,IAAI,EAAI,EAAG,EAAQ,WACxC,EAAI,EAAQ,MAAM,OAClB,IACA,CACM,MAAA,EAAW,EAAQ,MAAM,GAC1B,EAAK,eAAe,IACvB,EAAS,KAAK,CAAC,EAAM,KAKvB,GAAA,EAAS,OAAS,EAAG,CACjB,MAAA,EAAe,EAAA,WAAW,GAChC,EAAQ,QAAQ,EAAK,GAAI,EAAK,MAoalC,QAAA,sBAAA,EA1ZF,MAAM,UAA8B,EAM3B,OAAO,GACN,MAAA,EAAyB,MAAM,KAAK,EAAQ,aAC/C,OAAO,GAAQ,EAAK,KAAK,SAAS,KAAO,GACzC,OAAO,GAAQ,EAAK,GAAG,SAAS,KAAO,GACvC,OACC,GACE,EAAQ,MAAM,QAAQ,EAAK,IAAM,EAAQ,MAAM,QAAQ,EAAK,OAE9D,GAAA,EAAS,OAAS,EAAG,CACjB,MAAA,EAA+B,EAAA,WAAW,GAChD,EAAQ,WAAW,EAAiB,KAAM,EAAiB,MA2Y/D,QAAA,sBAAA,EAjYF,MAAM,UAA0B,EAe9B,YAAY,GAAM,EAAI,EAAM,GAC1B,QACK,KAAA,IAAM,EACN,KAAA,IAAM,EAQN,OAAO,GAEZ,EAAA,WAAW,MAAM,KAAK,EAAQ,cAAc,QAAU,EAAA,WACpD,KAAK,IACL,KAAK,MAoWT,QAAA,kBAAA,EA1VF,MAAM,UAAwB,EAe5B,YAAY,GAAM,EAAI,EAAM,GAC1B,QACK,KAAA,IAAM,EACN,KAAA,IAAM,EAQN,OAAO,GACZ,EAAA,WAAW,EAAQ,MAAM,OAAO,IAAS,EAAK,gBAC3C,WAAW,OA+ThB,QAAA,gBAAA,EAtTF,MAAM,UAA8B,EAUlC,YAAY,GAAe,GACzB,QACK,KAAA,aAAe,EASf,OACL,EACA,EAKI,IAEE,MAAA,EAAmB,KAAK,aAC1B,EAAQ,MAAM,OAAO,IAAS,EAAK,eACnC,EAAQ,MAAM,OAAO,GAAQ,EAAK,gBAClC,EAAS,OAAS,GACpB,EAAA,WAAW,GAAU,iBAAiB,EAAQ,qBAqRlD,QAAA,sBAAA,EA3QF,MAAM,UAAkC,EAM/B,OAAO,GACN,MAAA,EAAmB,EAAQ,MAC9B,OAAO,IAAS,EAAK,eACrB,OAAO,GAAuC,IAA/B,EAAK,eAAe,QAClC,GAAA,EAAS,OAAS,EAAG,CACjB,MAAA,EAAa,EAAA,WAAW,GAC9B,EAAQ,QAAQ,EAAM,KAkQ1B,QAAA,0BAAA,EAxPF,MAAM,UAAkC,EAM/B,OAAO,GACN,MAAA,EAAyB,MAAM,KAAK,EAAQ,aAAa,OAC7D,GAAQ,EAAK,OAAS,EAAK,IAEzB,GAAA,EAAS,OAAS,EAAG,CACjB,MAAA,EAA+B,EAAA,WAAW,GAChD,EAAQ,WAAW,EAAiB,KAAM,EAAiB,MA6O/D,QAAA,0BAAA,EAnOF,MAAM,UAAwB,EAOrB,OACL,EACA,EAKI,IAIF,QAAqB,IAArB,EAAQ,UACR,EAAQ,MAAM,MAAQ,EAAQ,SAE9B,OAII,MAAA,EAAyB,MAAM,KAAK,EAAQ,aAAa,OAC7D,GAA0B,OAAlB,EAAK,UAEX,GAAA,EAAS,OAAS,EAAG,CACjB,MAAA,EAAa,EAAA,WACjB,EAAQ,MAAM,OAAO,IAAS,EAAK,gBAE/B,EAAyB,EAAA,WAAW,GAE1C,EAAQ,QAAQ,EAAM,KA8L1B,QAAA,gBAAA,EApLF,MAAM,UAAwB,EAMrB,OAAO,GACR,EAAQ,MAAM,KAAO,GACvB,EAAQ,WAAW,EAAA,WAAW,MAAM,KAAK,EAAQ,UA6KrD,QAAA,gBAAA,EAnKF,MAAM,UAAkC,EAM/B,OAAO,GACN,MAAA,EAAqB,GACtB,IAAA,IAAI,EAAY,EAAQ,UAAW,EAAI,EAAQ,MAAM,OAAQ,IAAK,CAC/D,MAAA,EAAa,EAAQ,MAAM,GAC5B,IAAA,IAAI,EAAY,EAAQ,UAAW,EAAI,EAAG,IAAK,CAC5C,MAAA,EAAW,EAAQ,MAAM,GAC1B,EAAK,eAAe,IACvB,EAAS,KAAK,CAAC,EAAM,KAIvB,GAAA,EAAS,OAAS,EAAG,CACjB,MAAA,EAAe,EAAA,WAAW,GAChC,EAAQ,QAAQ,EAAK,GAAI,EAAK,MAmJlC,QAAA,0BAAA,EAzIF,MAAM,UAAkC,EAM/B,OAAO,GACN,MAAA,EAAyB,MAAM,KAAK,EAAQ,aAC/C,OAAO,GAAQ,EAAK,KAAK,SAAS,KAAO,GACzC,OAAO,GAAQ,EAAK,GAAG,SAAS,KAAO,GACvC,OACC,GACE,EAAQ,MAAM,QAAQ,EAAK,MAAQ,EAAQ,MAAM,QAAQ,EAAK,KAEhE,GAAA,EAAS,OAAS,EAAG,CACjB,MAAA,EAA+B,EAAA,WAAW,GAChD,EAAQ,WAAW,EAAiB,KAAM,EAAiB,MA0H/D,QAAA,0BAAA,EAhHF,MAAM,UAA0B,EAU9B,YAAY,GAAe,GACzB,QACK,KAAA,aAAe,EAQf,OAAO,GACN,MAAA,EAAmB,KAAK,aAC1B,EAAQ,MAAM,OAAO,QAAiB,IAAT,IAAuB,EAAK,eACzD,EAAQ,MAAM,OAAO,QAAiB,IAAT,GAAsB,EAAK,gBAExD,GAAA,EAAS,QAAU,EAAG,CAElB,MAAA,EAAc,EAAA,WAAW,GACzB,EAAc,EAAA,WAAW,EAAS,OAAO,GAAQ,IAAS,IAG1D,EAAmB,EAAM,KACzB,EAA6B,EAAM,OAEzC,EAAM,KAAO,EAAM,KACnB,EAAM,OAAS,EAAM,OACrB,EAAM,KAAO,EACb,EAAM,OAAS,IA4EnB,QAAA,kBAAA,EApEF,MAAM,EAA4B,CAChC,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,GAoCJ,QAAA,cAAA,EA/BF,MAAM,EAAoC,CACxC,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,GAwBJ,QAAA,sBAAA,EArBF,MAAM,EAAqC,CACzC,IAAI,EACJ,IAAI,EACJ,IAAI,GAmBJ,QAAA,uBAAA,EAjBF,MAAM,EAA6B,CACjC,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,EACJ,IAAI,GAOJ,QAAA,eAAA;;AChmBF,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,gBAAA,EANA,MAAA,EAAA,QAAA,kBAMA,MAAa,EAwCX,YAAY,EAAY,EAAU,EAAiB,GAC5C,KAAA,KAAO,EACP,KAAA,GAAK,EACL,KAAA,OAAS,MAAA,EAAA,EAAU,EACnB,KAAA,KAAO,EACP,KAAA,YAAc,EACd,KAAA,qBAAuB,EACvB,KAAA,kBAAoB,EACpB,KAAA,OAAS,IAAI,IAEd,GACG,KAAA,SAAW,EAChB,EAAS,QAAQ,OAEZ,KAAA,SAAW,KASb,SACE,MAAA,CACL,UAAW,KAAK,KAAK,MACrB,QAAS,KAAK,GAAG,MACjB,cAAiC,OAAlB,KAAK,SAAoB,KAAO,KAAK,SAAS,MAC7D,OAAQ,KAAK,QAOV,kBACE,OAAA,EAAA,QAAQ,KAAK,KAAK,MAAO,KAAK,GAAG,QA5E5C,QAAA,WAAA;;ACYA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,UAAA,EAnBA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,qBAEA,EAAA,QAAA,uBACA,EAAA,QAAA,kBACA,EAAA,QAAA,gBAcA,MAAa,EA0EX,YAAY,EAAiB,EAAA,SAAS,QAC/B,KAAA,KAAO,EACP,KAAA,KAAO,EAAA,YAAY,EAAG,GACtB,KAAA,OAAS,EAAA,SACT,KAAA,WAAa,EACb,KAAA,gBAAkB,EAClB,KAAA,MAAQ,EACR,KAAA,IAAM,EACN,KAAA,KAAO,EACP,KAAA,kBAAoB,EACpB,KAAA,eAAiB,EACjB,KAAA,SAAW,IAAI,IACf,KAAA,SAAW,IAAI,IACf,KAAA,MAAQ,IAAI,IACZ,KAAA,eAAiB,IAAI,EAAA,WAAW,KAAM,KAAM,GAC5C,KAAA,oBAAsB,EACtB,KAAA,eAAiB,EACjB,KAAA,WAAa,EACb,KAAA,MAAQ,IAUR,SAAS,GAtGlB,IAAA,EAAA,EAAA,EAAA,EA4GW,OALF,KAAA,KAAgB,QAAZ,EAAG,EAAK,YAAI,IAAA,EAAA,EAAI,EAAA,YAAY,EAAG,GACnC,KAAA,KAAO,EAAK,KACZ,KAAA,OAAoB,QAAd,EAAG,EAAK,cAAM,IAAA,EAAA,EAAI,EAAA,SACxB,KAAA,KAAgB,QAAZ,EAAG,EAAK,YAAI,IAAA,EAAA,EAAI,EACpB,KAAA,MAAkB,QAAb,EAAG,EAAK,aAAK,IAAA,EAAA,EAAI,IACpB,KAQF,QACA,KAAA,SAAS,QAAQ,IACpB,EAAW,YAAc,EACzB,EAAW,OAAO,UAGf,KAAA,MAAM,QAAQ,GAAS,EAAK,KAAO,GAEnC,KAAA,oBAAsB,KAAK,eAAiB,KAAK,WAAa,EAC9D,KAAA,IAAM,KAAK,MAAQ,KAAK,WAAa,EAQrC,WAAW,EAA0B,IAAI,EAAA,iBACzC,KAAA,MAAQ,EAAA,WAAW,EAAO,IAAK,EAAO,KAMtC,iBACL,EAAuC,OAAO,OAAO,EAAA,kBAG/C,MAAA,EAA6B,EAAmB,OACpD,GAAc,IAAe,KAAK,QAEhC,EAAS,OAAS,IACf,KAAA,OAAS,EAAA,WAAW,IAWtB,cAAc,GACf,OAAA,IAAS,KAE2B,IAA/B,KAAK,eAAe,OAEpB,MAAM,KAAK,KAAK,UACpB,IAAI,GAAQ,EAAK,MACjB,SAAS,GAWT,eAAe,GAChB,OAAA,IAAS,KAE2B,IAA/B,KAAK,eAAe,OAEpB,MAAM,KAAK,KAAK,UACpB,IAAI,GAAQ,EAAK,IACjB,SAAS,GAST,QAAQ,GACR,KAAA,MAAM,IAAI,GACf,EAAW,SAAW,KAQjB,WAAW,GACX,KAAA,MAAM,OAAO,GAClB,EAAW,SAAW,KACtB,EAAW,KAAO,EAUb,QAAQ,EAAc,EAAS,EAAG,GAAW,GAC9C,GAAA,IAAW,KAGN,OADF,KAAA,eAAe,OAAS,EACtB,KAAK,eACP,GAAI,KAAK,eAAe,GACvB,MAAA,IAAI,eAAe,kCACpB,CACC,MAAA,EAAyB,IAAI,EAAA,WAAW,KAAM,EAAQ,GASrD,OANF,KAAA,SAAS,IAAI,GAClB,EAAO,SAAS,IAAI,GAEhB,GACF,EAAO,QAAQ,MAEV,GAUJ,WAAW,EAAY,GAAW,GACnC,GAAA,IAAS,KAGJ,OADF,KAAA,eAAe,OAAS,EACtB,KAAK,eAGR,MAAA,EAA4B,MAAM,KAAK,KAAK,UAAU,OAC1D,GAAQ,EAAK,KAAO,GAGlB,GAAuB,IAAvB,EAAY,OACR,MAAA,IAAI,MAAM,uBAEZ,MAAA,EAAyB,EAAY,GAapC,OAVF,KAAA,SAAS,OAAO,GACrB,EAAW,GAAG,SAAS,OAAO,QAEF,IAAxB,EAAW,UAAkD,OAAxB,EAAW,UAClD,EAAW,SAAS,WAAW,GAE7B,GACF,EAAK,WAAW,MAGX,EAgBF,UACL,EACA,EAaI,IA7SR,IAAA,EAAA,EAAA,EA+SI,EAAQ,SAA2B,QAAnB,EAAG,EAAQ,gBAAQ,IAAA,EAAA,EAAI,EACvC,EAAQ,KAAmB,QAAf,EAAG,EAAQ,YAAI,IAAA,EAAA,EAAI,GAC/B,EAAQ,OAAuB,QAAjB,EAAG,EAAQ,cAAM,IAAA,GAAA,OAEhB,IAAX,GAAwB,OAAO,SAAS,GACrC,KAAA,oBAAsB,KAAK,eAAiB,EAAS,KAAK,YAE1D,KAAA,eAAiB,EACjB,KAAA,SAAS,QAAQ,IACf,KAAA,gBACH,EAAW,GAAG,oBACd,EAAW,OACX,EAAW,OAEV,KAAA,gBAAkB,KAAK,gBAEvB,KAAA,WAAa,EACb,KAAA,MAAM,QAAQ,IACb,IAAA,EAGF,EAFE,EAAW,GAAG,eAAe,WAAa,KAG1C,EAAW,GAAG,IAAM,EAAW,OAAS,EAAW,KAAK,WAE9C,EAAW,OAAS,EAAW,KAAK,WAG7C,KAAA,YAAc,EAAW,GAAG,oBAAsB,IAEpD,KAAA,YAAc,KAAK,gBAEnB,KAAA,oBAAsB,KAAK,eAAiB,KAAK,YAGnD,KAAA,SAAS,QAAQ,IAAa,IAAA,EAAA,EAE7B,IAAA,EAAmB,KAAK,eAAiB,EAAW,YACxD,EAAW,OAAO,QAChB,CAAC,EAAO,IAAS,GAAY,EAAI,oBAAsB,GAGzD,EAAW,oBACI,QAAb,EAAC,EAAQ,YAAI,IAAA,EAAA,EAAI,IAAO,EAAW,KAAK,KACtC,EAAQ,SACV,EAAW,oBACQ,QAAjB,EAAC,EAAQ,gBAAQ,IAAA,EAAA,EAAI,GAAK,EAAW,qBACvC,EAAW,QAAU,EAAW,kBAChC,EAAW,qBAAuB,EAAW,kBAC7C,EAAW,kBAAoB,KAI9B,KAAA,gBAAkB,EAAQ,KAAO,KAAK,oBACvC,EAAQ,SACL,KAAA,gBAAkB,EAAQ,SAAW,KAAK,kBAC1C,KAAA,MAAQ,KAAK,eACb,KAAA,kBAAoB,KAAK,eACzB,KAAA,eAAiB,GAgBnB,SAAS,EAAgB,GAAQ,GAClC,QAAU,IAAV,EACM,OAAA,KAAK,WAAa,EACrB,GAAI,KAAK,cACR,MAAA,IAAI,eAAe,6CAGvB,GAAA,EAAO,CACJ,KAAA,IAAM,KAAK,MAEX,KAAA,MACH,KAAK,eAAe,KAAO,KAAK,eAAe,OAAS,KAAK,MAC7D,KAAK,KAEF,KAAA,SAAS,QAAQ,IACf,KAAA,OAAS,EAAK,KAAK,WAAa,EAAK,OAAS,EAAK,OAGrD,KAAA,WAAa,KAAK,OAAO,KAAK,OAAO,GAAS,KAAK,KACnD,KAAA,gBAAkB,KAAK,OAAO,KAAK,OAAO,GAGzC,MAAA,EAAgB,GAChB,EAAuB,GAqDtB,OAlDF,KAAA,MAAM,QAAQ,IACjB,EAAW,KAAO,KAAK,WAGjB,MAAA,EAAgB,EAAM,QAAQ,EAAW,IAC3C,GAAS,EAEX,EAAW,IAAU,EAAW,OAAS,EAAW,KAAK,YAGzD,EAAM,KAAK,EAAW,IAClB,EAAW,GAAG,eAAe,WAAa,KAC5C,EAAW,KACT,EAAW,OAAS,EAAW,KAAK,WAAa,EAAW,GAAG,KAGjE,EAAW,KAAK,EAAW,OAAS,EAAW,KAAK,eAMrD,KAAA,SAAS,QAAQ,IAxa5B,IAAA,EAyaQ,EAAW,YACT,KAAK,eAAe,KAClB,KAAK,eAAe,OACpB,EAAW,YACb,EAAW,KAAK,WAAa,EAAW,KAErC,IAAA,IAAI,EAAI,EAAG,EAAI,EAAM,OAAQ,IAAK,CAC/B,MAAA,EAAa,EAAM,GACnB,EAAoB,EAAW,GAEjC,EAAW,OAAO,IAAI,GACxB,EAAW,OAAO,IAChB,EACA,EAAK,eAAe,KAClB,EAAK,eAAe,QACQ,QAA5B,EAAC,EAAW,OAAO,IAAI,UAAK,IAAA,EAAA,EAAI,GAChC,KAAK,gBAAkB,EAAW,YAAc,GAGpD,EAAW,OAAO,IAChB,EACA,KAAK,gBAAkB,EAAW,YAAc,MAMjD,KAAK,WAER,OAAA,KAAK,cAAuB,KAAK,WAAa,GAE7C,KAAA,MACH,KAAK,eAAe,KAAO,KAAK,eAAe,OAAS,KAAK,MAC7D,KAAK,KAEF,KAAA,SAAS,QACZ,GACG,KAAK,OACJ,EAAW,KAAK,WAAa,EAAW,OAAS,EAAW,MAG7D,KAAA,WAAa,KAAK,OAAO,KAAK,OAAO,GAGrC,KAAA,MAAM,QAAQ,GAAe,EAAW,KAAO,KAAK,YAElD,KAAK,YAST,SACE,MAAA,CACL,KAAM,KAAK,KACX,KAAM,KAAK,KACX,OAAQ,KAAK,OACb,KAAM,KAAK,KACX,MAAO,KAAK,OAOT,cACE,OAAA,KAAK,OAAS,EAAA,SAAS,MAMzB,eACE,OAAA,KAAK,OAAS,EAAA,SAAS,OAMzB,eACE,OAAA,KAAK,OAAS,EAAA,SAAS,OAQzB,QAAQ,GAEN,OADF,KAAA,KAAO,EACL,KAQF,kBAAkB,GAEhB,OADF,KAAA,OAAS,EACP,MAhhBX,QAAA,KAAA;;AChBA,aAAA,IAAY,EAAZ,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,gBAAA,EAAA,SAAY,GAIV,EAAA,EAAA,MAAA,GAAA,QAIA,EAAA,EAAA,KAAA,GAAA,OAIA,EAAA,EAAA,OAAA,GAAA,SAZF,CAAY,EAAA,QAAA,aAAA,QAAA,WAAU;;ACKtB,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,WAAA,EARA,MAAA,EAAA,QAAA,8BACA,EAAA,QAAA,0BAOA,MAAsB,EA0BpB,YAAsB,GACf,KAAA,WAAa,EACb,KAAA,MAAQ,GACR,KAAA,WAAa,IAAI,IACjB,KAAA,YAAc,IAAI,IAClB,KAAA,YAAc,GACd,KAAA,MAAQ,GAaD,eACZ,EACA,EACA,EAAiC,EAAA,eAAe,WAChD,EAAS,GAEL,GAAA,IAAmB,EAAA,eAAe,cAC9B,MAAA,IAAI,eACR,uDAIE,MAAA,EAAoB,MAAM,KAC9B,aAAgB,EAAQ,EAAK,YAAc,GAEvC,EAAkB,MAAM,KAC5B,aAAc,EAAQ,EAAG,WAAa,GAGpC,GAAmB,IAAnB,EAAQ,OACJ,MAAA,IAAI,eAAe,mCAEvB,GAAqB,IAArB,EAAU,OACN,MAAA,IAAI,eAAe,kCAGrB,MAAA,EAA4B,GAC9B,GAAA,IAAmB,EAAA,eAAe,WACpC,EAAU,QAAQ,IAChB,EAAQ,QAAQ,IACd,EAAY,KAAK,EAAS,QAAQ,EAAQ,aAGzC,GAAI,IAAmB,EAAA,eAAe,WAAY,CACnD,GAAA,EAAU,SAAW,EAAQ,OACzB,MAAA,IAAI,WACR,+GAGC,IAAA,IAAI,EAAI,EAAG,EAAI,EAAU,OAAQ,IACpC,EAAY,KAAK,EAAU,GAAG,QAAQ,EAAQ,GAAI,SAE/C,GAAI,IAAmB,EAAA,eAAe,QAAS,CAG9C,MAAA,EAAgB,EAAQ,OAAS,EAAU,OACjD,EAAY,QACP,EAAU,IAAI,CAAC,EAAM,IACtB,EAAK,QAAQ,EAAQ,KAAK,MAAM,EAAQ,IAAS,KAIhD,OAAA,EAYK,YACZ,EACA,EACA,GAEM,MAAA,EAAiC,GAC/B,OAAA,GACD,KAAA,EAAA,WAAW,MAAO,CAEf,MAAA,EAAkB,MAAM,KAC5B,IAAI,IAAI,EAAY,IAAI,GAAQ,EAAK,MAGlC,IAAA,IAAI,EAAI,EAAG,EAAI,EAAQ,OAAQ,IAAK,CACjC,MAAA,EAAa,EAAQ,GACrB,EAAiB,EAAM,EAAI,EAAM,QAEvC,EAAK,SAAS,QAAQ,IAChB,EAAY,SAAS,KACvB,EAAS,QAAQ,GACjB,EAAiB,KAAK,MAI5B,MAEG,KAAA,EAAA,WAAW,KAAM,CAEd,MAAA,EAAoB,MAAM,KAC9B,IAAI,IAAI,EAAY,IAAI,GAAQ,EAAK,QAGlC,IAAA,IAAI,EAAI,EAAG,EAAI,EAAU,OAAQ,IAChC,EAAY,SAAS,EAAU,GAAG,kBACpC,EAAM,EAAI,EAAM,QAAQ,QAAQ,EAAU,GAAG,gBAC7C,EAAiB,KAAK,EAAU,GAAG,iBAGvC,MAEG,KAAA,EAAA,WAAW,OAAQ,CAEhB,MAAA,EAAoB,MAAM,KAC9B,IAAI,IAAI,EAAY,IAAI,GAAQ,EAAK,QAElC,IAAA,IAAI,EAAI,EAAG,EAAI,EAAU,OAAQ,IAAK,CACnC,MAAA,EAAa,EAAU,GACvB,EAAiB,EAAM,EAAI,EAAM,QAEvC,EAAK,SAAS,QAAQ,IAChB,EAAY,SAAS,KACvB,EAAS,QAAQ,GACjB,EAAiB,KAAK,MAI5B,OAIG,OAAA,GAzKX,QAAA,MAAA;;ACAA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,kBAAA,EARA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,wBAEA,EAAA,QAAA,WAKA,MAAsB,UAAqB,EAAA,KACzC,cACQ,MAAA,EAAA,SAAS,QACV,KAAA,KAAO,EAUP,SAAS,GAblB,IAAA,EAAA,EAgBW,OAFF,KAAA,MAAkB,QAAb,EAAG,EAAK,aAAK,IAAA,EAAA,GAAK,EACvB,KAAA,OAAoB,QAAd,EAAG,EAAK,cAAM,IAAA,EAAA,EAAI,EAAA,UACtB,KA+CF,SACE,MAAA,CAAC,MAAO,KAAK,MAAO,OAAQ,KAAK,QAMnC,aACC,MAAA,IAAI,eAAe,8BAMpB,mBACC,MAAA,IAAI,eAAe,8BAMpB,UACC,MAAA,IAAI,eAAe,wCAMpB,aACC,MAAA,IAAI,eAAe,wCAMpB,UACC,MAAA,IAAI,eAAe,wCAnG7B,QAAA,aAAA;;ACDA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,eAAA,EAPA,MAAA,EAAA,QAAA,wBACA,EAAA,QAAA,qBACA,EAAA,QAAA,kBAKA,MAAa,UAAkB,EAAA,aAwB7B,YACE,EAkBI,IA3CR,IAAA,EA6CI,QACK,KAAA,UAA6B,QAApB,EAAG,EAAQ,iBAAS,IAAA,EAAA,EAAI,EAAA,cAAc,eAC/C,KAAA,QAAU,EAYV,WA3DT,IAAA,EAAA,EAAA,EAAA,EA4DS,KAAA,IAAM,KAAK,MAEV,MAAA,EAA2B,MAAM,KAAK,KAAK,UAAU,IACzD,GAAQ,EAAK,KAAK,WAAa,EAAK,OAAS,EAAK,MAG5C,OAAA,KAAK,WACN,KAAA,EAAA,cAAc,eACZ,KAAA,MACH,EAAA,IAAI,GACJ,EAAA,iBAC6B,QADb,EACO,QADP,EACd,KAAK,QAAQ,gBAAQ,IAAA,OAAA,EAAA,EAAE,YAAI,IAAA,EAAA,EAAI,EACC,QADA,EACX,QADW,EAChC,KAAK,QAAQ,gBAAQ,IAAA,OAAA,EAAA,EAAE,iBAAS,IAAA,EAAA,EAAI,GAExC,MACF,QACQ,MAAA,IAAI,eAAe,oCAMtB,OAHF,KAAA,WAAa,KAAK,OAAO,KAAK,OAAO,GAAS,KAAK,KACnD,KAAA,gBAAkB,KAAK,OAAO,KAAK,OAAO,GAExC,KAAK,WAaP,UACL,EACA,EAaI,IA9GR,IAAA,EAAA,EAAA,EAgHI,EAAQ,SAA2B,QAAnB,EAAG,EAAQ,gBAAQ,IAAA,EAAA,EAAI,EACvC,EAAQ,KAAmB,QAAf,EAAG,EAAQ,YAAI,IAAA,EAAA,EAAI,GAC/B,EAAQ,OAAuB,QAAjB,EAAG,EAAQ,cAAM,IAAA,GAAA,EAEzB,MAAA,EAA8B,MAAM,KAAK,KAAK,UAAU,IAC5D,GAAQ,EAAK,GAAG,oBAAsB,EAAK,OAAS,EAAK,MAEtD,KAAA,oBAAsB,KAAK,eAC9B,EAAA,IAAI,GAAqB,KAAK,gBAE3B,KAAA,SAAS,QAAQ,IAAa,IAAA,EAAA,EAE7B,IAAA,EAAmB,KAAK,eAAiB,EAAW,YACxD,EAAW,OAAO,QAAQ,CAAC,EAAO,KAChC,GAAY,EAAI,oBAAsB,IAGxC,EAAW,oBACI,QAAb,EAAC,EAAQ,YAAI,IAAA,EAAA,EAAI,IAAO,EAAW,KAAK,KACtC,EAAQ,SACV,EAAW,oBACQ,QAAjB,EAAC,EAAQ,gBAAQ,IAAA,EAAA,EAAI,GAAK,EAAW,qBACvC,EAAW,QAAU,EAAW,kBAChC,EAAW,qBAAuB,EAAW,kBAC7C,EAAW,kBAAoB,MAxIvC,QAAA,UAAA;;ACEA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,gBAAA,EATA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,iCACA,EAAA,QAAA,2BACA,EAAA,QAAA,yBACA,EAAA,QAAA,YAKA,MAAa,UAAmB,EAAA,MAC9B,YACE,EACA,EAaI,IAhBR,IAAA,EAkBU,MAAA,GAEA,MAAA,EAA+C,QAArC,EAAmB,EAAQ,kBAAU,IAAA,EAAA,EAAI,EAAA,UAEpD,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,WAAW,IACd,IAAI,EAAA,UAAU,CACZ,UAAW,EAAA,cAAc,eACzB,SAAU,IACT,kBAAkB,IAIpB,KAAA,YAAc,KAAK,WACnB,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,aAQ9B,mCACE,OAAA,EAAA,eAAe,WAUjB,wBAAwB,GACtB,OAAA,IAAS,EAAA,eAAe,YApDnC,QAAA,WAAA;;ACAA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,gBAAA,EATA,MAAA,EAAA,QAAA,iCACA,EAAA,QAAA,2BACA,EAAA,QAAA,cACA,EAAA,QAAA,YACA,EAAA,QAAA,6BAKA,MAAa,UAAmB,EAAA,MAC9B,YACE,EACA,EAKI,IAEE,MAAA,GAED,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IAAK,CAC7B,MAAA,EAAa,IAAI,EAAA,KAAK,EAAA,SAAS,OAChC,KAAA,MAAM,KAAK,GAGd,GAAA,EAAQ,MAAO,CACX,MAAA,EAAyB,IAAI,EAAA,WAAW,EAAQ,OACtD,EAAW,YAAY,QAAQ,GAAQ,KAAK,YAAY,IAAI,IACvD,KAAA,YAAY,QACZ,EAAA,MAAM,QACP,KAAK,MACL,EACA,EAAW,0CAIV,KAAA,MAAM,QAAQ,GAAQ,KAAK,YAAY,IAAI,IAS7C,mCACE,OAAA,EAAA,eAAe,cAUjB,wBAAwB,GACtB,OAAA,IAAS,EAAA,eAAe,eAjDnC,QAAA,WAAA;;ACAA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,iBAAA,EATA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,iCACA,EAAA,QAAA,2BACA,EAAA,QAAA,cACA,EAAA,QAAA,YAKA,MAAa,UAAoB,EAAA,MAC/B,YACE,EACA,EAKI,IARR,IAAA,EAUU,MAAA,GAEA,MAAA,EAA+C,QAArC,EAAmB,EAAQ,kBAAU,IAAA,EAAA,EAAI,EAAA,UACpD,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,WAAW,IACd,IAAI,EAAA,KAAK,EAAA,SAAS,QAAQ,kBAAkB,IAG3C,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,aAM9B,UACC,MAAA,IAAI,eAAe,qCAQpB,0BACE,OAAA,EAQF,mCACE,OAAA,EAAA,eAAe,YA3C1B,QAAA,YAAA;;ACiFa,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,WAAA,QAAA,UAAA,QAAA,SAAA,QAAA,SAAA,QAAA,SAAA,QAAA,QAAA,QAAA,WAAA,QAAA,QAAA,QAAA,aAAA,EA1Fb,MAAA,EAAA,QAAA,kBAIa,QAAA,QAAoB,SAC/B,EACA,GAEI,IAAA,EAAQ,EAIL,OAHP,EAAQ,QAAQ,CAAC,EAAO,KACtB,GAAS,KAAA,IAAC,EAAQ,GAAS,EAAU,KAEhC,EAAQ,EAAQ,QAEZ,QAAA,QAAoB,SAC/B,EACA,GAEI,IAAA,EAAQ,EAIL,OAHP,EAAQ,QAAQ,CAAC,EAAO,KACtB,GAAS,EAAQ,GAAS,IAErB,EAAQ,EAAQ,QAEZ,QAAA,WAAuB,SAClC,EACA,GAEI,IAAA,EAAQ,EAIL,OAHP,EAAQ,QAAQ,CAAC,EAAO,KACtB,GAAS,KAAK,MAAuB,EAAjB,EAAQ,MAAgB,KAAK,MAAc,EAAR,GAAa,EAAI,IAEnE,EAAQ,EAAQ,QAEZ,QAAA,QAAoB,SAC/B,EACA,GAEI,IAAA,EAAQ,EAIL,OAHP,EAAQ,QAAQ,CAAC,EAAO,KACtB,GAAS,KAAK,IAAI,EAAQ,GAAS,KAE9B,EAAQ,EAAQ,QAEZ,QAAA,SAAqB,SAChC,EACA,GAEI,IAAA,EAAQ,EAML,OALP,EAAQ,QAAQ,CAAC,EAAO,KACtB,GAAS,KAAK,KACX,EAAQ,EAAQ,IAAU,KAAK,IAAI,EAAQ,GAAQ,UAGjD,EAAQ,EAAQ,QAEZ,QAAA,SAAqB,SAChC,EACA,GAEI,IAAA,EAAQ,EAIL,OAHP,EAAQ,QAAQ,CAAC,EAAO,KACtB,GAAS,KAAK,IAAI,EAAQ,GAAS,KAE9B,EAAQ,EAAA,IAAI,IAER,QAAA,SAAqB,SAChC,EACA,GAEI,IAAA,EAAQ,EAML,OALP,EAAQ,QAAQ,CAAC,EAAO,KACtB,GACE,KAAK,IAAI,KAAK,IAAI,EAAQ,GAAQ,QAClC,KAAK,IAAI,KAAK,IAAI,EAAO,UAEtB,EAAQ,EAAQ,QAGZ,QAAA,UAAsB,SACjC,EACA,GAEI,IAAA,EAAQ,EAIL,OAHP,EAAQ,QAAQ,CAAC,EAAO,KACtB,GAAS,KAAK,IAAI,EAAG,EAAI,EAAQ,EAAQ,MAEpC,EAAQ,EAAQ,QAGZ,QAAA,WAyET,CACF,QAAA,QAAA,QACA,QAAA,QAAA,QACA,WAAA,QAAA,WACA,QAAA,QAAA,QACA,SAAA,QAAA,SACA,SAAA,QAAA,SACA,SAAA,QAAA,SACA,UAAA,QAAA;;AChBA,aAAA,IAAA,EAAA,MAAA,KAAA,kBAAA,OAAA,OAAA,SAAA,EAAA,EAAA,EAAA,QAAA,IAAA,IAAA,EAAA,GAAA,OAAA,eAAA,EAAA,EAAA,CAAA,YAAA,EAAA,IAAA,WAAA,OAAA,EAAA,OAAA,SAAA,EAAA,EAAA,EAAA,QAAA,IAAA,IAAA,EAAA,GAAA,EAAA,GAAA,EAAA,KAAA,EAAA,MAAA,KAAA,qBAAA,OAAA,OAAA,SAAA,EAAA,GAAA,OAAA,eAAA,EAAA,UAAA,CAAA,YAAA,EAAA,MAAA,KAAA,SAAA,EAAA,GAAA,EAAA,QAAA,IAAA,EAAA,MAAA,KAAA,cAAA,SAAA,GAAA,GAAA,GAAA,EAAA,WAAA,OAAA,EAAA,IAAA,EAAA,GAAA,GAAA,MAAA,EAAA,IAAA,IAAA,KAAA,EAAA,YAAA,GAAA,OAAA,eAAA,KAAA,EAAA,IAAA,EAAA,EAAA,EAAA,GAAA,OAAA,EAAA,EAAA,GAAA,GAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,oBAAA,QAAA,eAAA,QAAA,8BAAA,QAAA,eAAA,EA3JF,MAAA,EAAA,EAAA,QAAA,YAEA,EAAA,QAAA,kBAOA,MAAe,GA+Ib,QAAA,UAAA,EAhIF,MAAM,UAAsC,EAOnC,OAAO,GA4Hd,IAAA,EAAA,EAAA,EA3HM,IAAA,EAAe,EACf,EAAiB,EAChB,IAAA,MAAM,KAAU,EACnB,EAAiB,KAAK,IAAgB,QAAb,EAAC,EAAO,aAAK,IAAA,EAAA,EAAI,EAAgB,GAC1D,GAA4B,QAAhB,EAAI,EAAO,aAAK,IAAA,EAAA,EAAI,EAIlC,IADA,EAAiB,KAAK,IAAI,IACO,EAAW,OAEtC,MAAA,EAAiB,EAAA,WAAW,EAAG,GACjC,IAAA,EAAQ,EAEP,IAAA,MAAM,KAAU,EAEf,GAAA,GADJ,IAAsB,QAAb,EAAC,EAAO,aAAK,IAAA,EAAA,EAAI,GAAK,GAEtB,OAAA,EAIJ,OAAA,EAAA,WAAW,IAqGpB,QAAA,8BAAA,EA5FF,MAAM,UAAuB,EAU3B,YAAY,EAAQ,GAClB,QACK,KAAA,MAAQ,EASR,OAAO,GACL,OAAA,EACL,KAAK,MAAM,KAAA,IAAA,KAAK,SAAY,KAAK,OAAQ,EAAW,UAsExD,QAAA,eAAA,EA5DF,MAAM,UAA4B,EAehC,YAAY,EAAO,EAAG,EAAc,IAClC,QACK,KAAA,KAAO,EACP,KAAA,YAAc,EASd,OAAO,GACR,GAAA,KAAK,KAAO,EAAW,OACnB,MAAA,IAAI,MACR,kHAKE,MAAA,EAAyB,GAC1B,IAAA,IAAI,EAAI,EAAG,EAAI,KAAK,KAAM,IAC7B,EAAY,KAAK,EAAA,WAAW,IAI9B,EAAQ,KAAK,EAAa,CAAC,EAAY,SAClB,IAAZ,EAAE,YAAmC,IAAZ,EAAE,MAC9B,EACA,EAAE,MAAQ,EAAE,OAIb,IAAA,IAAI,EAAI,EAAG,EAAI,KAAK,KAAM,IACzB,GAAA,KAAK,SAAW,KAAK,aAAe,IAAM,KAAK,KAAO,EACjD,OAAA,EAAY,GAGhB,OAAA,EAAA,WAAW,IAQpB,QAAA,oBAAA;;AChJF,aAAA,IAAA,EAAA,MAAA,KAAA,iBAAA,SAAA,GAAA,OAAA,GAAA,EAAA,WAAA,EAAA,CAAA,QAAA,IAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,mBAAA,EAXA,MAAA,EAAA,QAAA,yBACA,EAAA,EAAA,QAAA,OACA,EAAA,QAAA,2BACA,EAAA,QAAA,mBACA,EAAA,QAAA,uBACA,EAAA,QAAA,wBAMA,MAAa,EACX,cAgDQ,KAAA,0BAA4B,EAgB5B,KAAA,IAAM,EAgBN,KAAA,IAAM,EAgBN,KAAA,IAAM,EAgBN,KAAA,WAAa,GA/Gd,KAAA,OAAS,EACT,KAAA,QAAU,EACV,KAAA,YAAc,EACd,KAAA,SAAW,EACX,KAAA,QAAS,EACT,KAAA,QAAS,EACT,KAAA,gBAAkB,GAClB,KAAA,cAAgB,GAChB,KAAA,gBAAkB,EAElB,KAAA,WAAa,IAAI,EAAA,8BACjB,KAAA,MAAQ,EAAA,QACR,KAAA,WAAa,EAAA,sBACb,KAAA,aAAe,OAAO,OAAO,EAAA,iBAC7B,KAAA,UAAY,IAAI,EAAA,QAAQ,KAAK,OAAQ,KAAK,SAC1C,KAAA,UAAY,EAAA,EACZ,KAAA,gBAAkB,EAAA,EAClB,KAAA,UAAY,EAAA,EACZ,KAAA,SAAW,EAAA,QAAG,OAAO,OACrB,KAAA,MAAQ,EACR,KAAA,YAAc,IACd,KAAA,OAAS,IACT,KAAA,eAAiB,EAUb,oBACF,OAAA,KAAK,eAOH,kBAAc,GAClB,KAAA,eAAiB,EAWb,+BACF,OAAA,KAAK,0BAMH,6BAAyB,GAC7B,KAAA,0BAA4B,EAQxB,SACF,OAAA,KAAK,IAMH,OAAG,GACP,KAAA,IAAM,EAQF,SACF,OAAA,KAAK,IAMH,OAAG,GACP,KAAA,IAAM,EAQF,SACF,OAAA,KAAK,IAMH,OAAG,GACP,KAAA,IAAM,EAQF,gBACF,OAAA,KAAK,WAMH,cAAU,GACd,KAAA,WAAa,EAWT,cACF,OAAA,KAAK,SAMH,YAAQ,GACZ,KAAA,SAAW,EAWP,YACF,OAAA,KAAK,OAMH,UAAM,GACV,KAAA,OAAS,EAWL,aACF,OAAA,KAAK,QAMH,WAAO,GACX,KAAA,QAAU,EAoBN,cAYF,OAAA,KAAK,SAMH,YACT,GAaK,KAAA,SAAW,EAWP,iBACF,OAAA,KAAK,YAMH,eAAW,GACf,KAAA,YAAc,EAWV,eACF,OAAA,KAAK,UAMH,aAAS,GACb,KAAA,UAAY,EAWR,eACF,OAAA,KAAK,UAMH,aAAS,GACb,KAAA,UAAY,EAWR,gBACF,OAAA,KAAK,WAMH,cAAU,GACd,KAAA,WAAa,EAWT,kBACF,OAAA,KAAK,aAMH,gBAAY,GAChB,KAAA,aAAe,EAWX,gBACF,OAAA,KAAK,WAMH,cAAU,GACd,KAAA,WAAa,EAWT,mBACF,OAAA,KAAK,cAMH,iBAAa,GACjB,KAAA,cAAgB,EAWZ,qBACF,OAAA,KAAK,gBAMH,mBAAe,GACnB,KAAA,gBAAkB,EAWd,cACF,OAAA,KAAK,SAMH,YAAQ,GACZ,KAAA,SAAW,EAWP,qBACF,OAAA,KAAK,gBAMH,mBAAe,GACnB,KAAA,gBAAkB,EA0Bd,sBAeF,OAAA,KAAK,iBAMH,oBACT,GAgBK,KAAA,iBAAmB,EAWf,WACF,OAAA,KAAK,MAMH,SAAK,GACT,KAAA,MAAQ,EAWJ,eACF,OAAA,KAAK,UAMH,aAAS,GACb,KAAA,UAAY,EAWR,qBACF,OAAA,KAAK,gBAMH,mBAAe,GACnB,KAAA,gBAAkB,EAWd,eACF,OAAA,KAAK,UAMH,aAAS,GACb,KAAA,UAAY,EAWR,YACF,OAAA,KAAK,OAMH,UAAM,GACV,KAAA,OAAS,EAWL,UACF,OAAA,KAAK,KAMH,QAAI,GACR,KAAA,KAAO,EAwBH,eAoBF,OAAA,KAAK,UAMH,aACT,GAqBK,KAAA,UAAY,EAWR,YACF,OAAA,KAAK,OAMH,UAAM,GACV,KAAA,OAAS,EAWL,iBACF,OAAA,KAAK,YAMH,eAAW,GACf,KAAA,YAAc,EAWV,YACF,OAAA,KAAK,OAMH,UAAM,GACV,KAAA,OAAS,GA5tBlB,QAAA,cAAA;;ACJA,aAAA,IAAA,EAAA,MAAA,KAAA,kBAAA,OAAA,OAAA,SAAA,EAAA,EAAA,EAAA,QAAA,IAAA,IAAA,EAAA,GAAA,OAAA,eAAA,EAAA,EAAA,CAAA,YAAA,EAAA,IAAA,WAAA,OAAA,EAAA,OAAA,SAAA,EAAA,EAAA,EAAA,QAAA,IAAA,IAAA,EAAA,GAAA,EAAA,GAAA,EAAA,KAAA,EAAA,MAAA,KAAA,qBAAA,OAAA,OAAA,SAAA,EAAA,GAAA,OAAA,eAAA,EAAA,UAAA,CAAA,YAAA,EAAA,MAAA,KAAA,SAAA,EAAA,GAAA,EAAA,QAAA,IAAA,EAAA,MAAA,KAAA,cAAA,SAAA,GAAA,GAAA,GAAA,EAAA,WAAA,OAAA,EAAA,IAAA,EAAA,GAAA,GAAA,MAAA,EAAA,IAAA,IAAA,KAAA,EAAA,YAAA,GAAA,OAAA,eAAA,KAAA,EAAA,IAAA,EAAA,EAAA,EAAA,GAAA,OAAA,EAAA,EAAA,GAAA,GAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,aAAA,EAPA,MAAA,EAAA,EAAA,QAAA,YACA,EAAA,QAAA,kBACA,EAAA,QAAA,aAKA,MAAa,EAoBX,YAAY,GACL,KAAA,eAAiB,EACjB,KAAA,eAAe,QAAU,KAEzB,KAAA,QAAU,IAAI,IACd,KAAA,QAAQ,IAAI,GAEZ,KAAA,OAAS,EACT,KAAA,UAAY,EACZ,KAAA,YAAc,EAYjB,YACK,OAAA,KAAK,OAYV,iBACK,OAAA,KAAK,YAWP,IACL,EACA,EACA,EACA,EACA,GAEI,OAAA,EAAQ,SAAS,KAAK,eAAgB,EAAI,EAAI,GAAM,IACjD,KAAA,SAAS,IACP,GAUJ,SAAS,QACE,IAAZ,IAGC,KAAA,QAAQ,IAAI,GACjB,EAAQ,QAAU,MAMb,gBACD,IAAA,EAAM,EACL,KAAA,QAAQ,QAAQ,IAAU,IAAA,EAAE,OAAA,GAAoB,QAAjB,EAAI,EAAQ,aAAK,IAAA,EAAA,EAAI,IACnD,MAAA,EAAgB,EAAM,KAAK,QAAQ,KACrC,KAAK,UAAY,EACd,KAAA,cAEA,KAAA,YAAc,EAEhB,KAAA,OAAS,EAMT,QACA,KAAA,eAAiB,EAAA,WAAW,KAAK,SACjC,KAAA,QAAQ,QAAQ,GAAW,EAAO,QAAU,MAC5C,KAAA,QAAQ,QACR,KAAA,QAAQ,IAAI,KAAK,gBACjB,KAAA,eAAe,QAAU,KACzB,KAAA,UAAY,KAAK,MACjB,KAAA,OAAS,EAOT,KAAK,GACJ,MAAA,EAAiB,MAAM,KAAK,KAAK,SACvC,EAAQ,KAAK,EAAK,CAAC,EAAY,SACV,IAAZ,EAAE,YAAmC,IAAZ,EAAE,MAC9B,EACA,EAAE,MAAQ,EAAE,OAGZ,MAAA,EAAiB,KAAK,MAAM,EAAa,KAAK,QAAQ,MACvD,IAAA,IAAI,EAAI,EAAG,EAAI,EAAQ,IACrB,KAAA,QAAQ,OAAO,EAAI,IACxB,EAAI,GAAG,QAAU,KAOd,QACE,OAAA,EAAA,QAAQ,UACb,EAAA,WAAW,KAAK,SAChB,EAAA,WAAW,KAAK,UAOb,OACE,OAAA,KAAK,QAAQ,KAMf,UACC,MAAA,EAAsB,MAAM,KAAK,KAAK,SACrC,OAAA,EACL,EAAA,cAAc,EAAS,IAAI,IAAS,IAAA,EAAA,OAAa,QAAb,EAAC,EAAO,aAAK,IAAA,EAAA,GAAK,EAAA,MAOnD,QACL,QAAQ,IACN,qBACE,KAAK,QAAQ,KACb,YACA,KAAK,OACL,iBACA,KAAK,WACL,MAlLR,QAAA,QAAA;;ACUA,aAAA,IAAA,EAAA,MAAA,KAAA,kBAAA,OAAA,OAAA,SAAA,EAAA,EAAA,EAAA,QAAA,IAAA,IAAA,EAAA,GAAA,OAAA,eAAA,EAAA,EAAA,CAAA,YAAA,EAAA,IAAA,WAAA,OAAA,EAAA,OAAA,SAAA,EAAA,EAAA,EAAA,QAAA,IAAA,IAAA,EAAA,GAAA,EAAA,GAAA,EAAA,KAAA,EAAA,MAAA,KAAA,qBAAA,OAAA,OAAA,SAAA,EAAA,GAAA,OAAA,eAAA,EAAA,UAAA,CAAA,YAAA,EAAA,MAAA,KAAA,SAAA,EAAA,GAAA,EAAA,QAAA,IAAA,EAAA,MAAA,KAAA,cAAA,SAAA,GAAA,GAAA,GAAA,EAAA,WAAA,OAAA,EAAA,IAAA,EAAA,GAAA,GAAA,MAAA,EAAA,IAAA,IAAA,KAAA,EAAA,YAAA,GAAA,OAAA,eAAA,KAAA,EAAA,IAAA,EAAA,EAAA,EAAA,GAAA,OAAA,EAAA,EAAA,GAAA,GAAA,EAAA,MAAA,KAAA,WAAA,SAAA,EAAA,EAAA,EAAA,GAAA,OAAA,IAAA,IAAA,EAAA,UAAA,SAAA,EAAA,GAAA,SAAA,EAAA,GAAA,IAAA,EAAA,EAAA,KAAA,IAAA,MAAA,GAAA,EAAA,IAAA,SAAA,EAAA,GAAA,IAAA,EAAA,EAAA,MAAA,IAAA,MAAA,GAAA,EAAA,IAAA,SAAA,EAAA,GAAA,IAAA,EAAA,EAAA,KAAA,EAAA,EAAA,QAAA,EAAA,EAAA,MAAA,aAAA,EAAA,EAAA,IAAA,EAAA,SAAA,GAAA,EAAA,MAAA,KAAA,EAAA,GAAA,GAAA,EAAA,EAAA,MAAA,EAAA,GAAA,KAAA,WAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,UAAA,EAjBA,MAAA,EAAA,EAAA,QAAA,YAEA,EAAA,QAAA,0BAEA,EAAA,QAAA,sBAMA,EAAA,QAAA,iBAOA,MAAa,EAgBX,YAAY,GACN,IAAC,EAAQ,gBACL,MAAA,IAAI,eAAe,8BAEtB,KAAA,SAAW,EACX,KAAA,WAAa,GACb,KAAA,QAAU,IAAI,IAEd,IAAA,IAAI,EAAI,EAAG,EAAI,KAAK,QAAQ,eAAgB,IAC1C,KAAA,WAAW,KAAK,KAAK,QAAQ,SAAS,QAYpC,cACF,OAAA,KAAK,SAMH,YAAQ,GACZ,KAAA,SAAW,EAQX,aAAa,GACZ,MAAA,EAAsB,KAAK,QAAQ,UAAU,OAAO,GAEtD,EAAO,YAAY,OAAS,EAAA,gBAAgB,YAAY,MACxD,EAAQ,MAAM,OAAS,KAAK,QAAQ,UACpC,EAAO,YAAY,OAAS,EAAA,sBAAsB,YAAY,MAC9D,EAAQ,YAAY,KAAO,KAAK,QAAQ,gBACxC,EAAO,YAAY,OAAS,EAAA,gBAAgB,YAAY,MACxD,EAAQ,MAAM,KAAO,KAAK,QAAQ,UAGtC,EAAQ,OAAO,EAAA,WAAW,GAAU,CAClC,mBAAoB,KAAK,QAAQ,cASxB,SA1Ef,OAAA,EAAA,UAAA,OAAA,EAAA,YAyFQ,GAdC,KAAA,mBAEC,KAAK,WACN,KAAA,OACA,KAAA,QAAQ,QAAQ,GAAW,EAAQ,iBAEnC,KAAA,KAAK,EAAI,KAAK,QAAQ,WACtB,KAAA,uBACA,KAAA,YAGA,KAAA,SAGD,KAAK,QAAQ,SACV,IAAA,MAAM,KAAU,KAAK,WACxB,EAAO,MAAM,KAAK,QAAQ,gBAKxB,KAAK,WAGN,KAAA,OAEC,MAAA,EAAmB,KAAK,WAAW,GAAG,OAI1C,GAHF,EAAQ,MAAQ,KAAK,WAAW,GAAG,MAGjC,KAAK,QAAQ,IAAM,GACnB,KAAK,QAAQ,WAAa,KAAK,QAAQ,KAAQ,EAC/C,CACA,QAAQ,IAAI,iCACZ,QAAQ,IACN,eACE,KAAK,QAAQ,WACb,cACA,KAAK,QAAQ,KACb,YACA,KAAK,WAAW,GAAG,OAElB,IAAA,MAAM,KAAW,KAAK,QACzB,EAAQ,QASL,OAJF,KAAA,WAAW,QAAQ,GAAW,EAAO,WAAQ,GAE7C,KAAA,QAAQ,aAEN,IAQF,OAAO,GAEP,KAAA,WACF,OAAO,IAAM,KAAK,UAAY,KAAK,QAAQ,cAC3C,QAAQ,IACF,IAAA,IAAI,EAAI,EAAG,EAAI,KAAK,QAAQ,eAAgB,IAC3C,EACF,EAAO,OAAO,GAET,KAAA,aAAa,KAWf,WA3Jf,IAAA,EAAA,EAAA,OAAA,EAAA,UAAA,OAAA,EAAA,YAoKW,OARH,KAAK,QAAQ,OACV,KAAA,WAAW,QAAQ,GAAU,EAAO,eAET,QAAlC,GAAM,EAAA,KAAK,SAAQ,uBAAe,IAAA,OAAA,EAAA,EAAA,KAAA,EAAG,KAAK,WAAY,KAAK,QAAQ,SAG9D,KAAA,OAEE,KAAK,WAAW,KAOlB,OACL,EAAQ,KAAK,KAAK,WAAY,CAAC,EAAY,SACtB,IAAZ,EAAE,YAAmC,IAAZ,EAAE,MAC9B,EACA,EAAE,MAAQ,EAAE,OASP,aAxLf,OAAA,EAAA,UAAA,OAAA,EAAA,YA8LW,YALmD,IAAtD,KAAK,WAAW,KAAK,WAAW,OAAS,GAAG,cACxC,KAAK,YAER,KAAA,OAEE,KAAK,WAAW,KAQZ,aAtMf,OAAA,EAAA,UAAA,OAAA,EAAA,iBAuM8D,IAAtD,KAAK,WAAW,KAAK,WAAW,OAAS,GAAG,cACxC,KAAK,YAET,IAAA,EAAQ,EAIL,OAHF,KAAA,WACF,IAAI,GAAU,EAAO,OACrB,QAAQ,GAAQ,GAAS,MAAA,EAAA,EAAO,GAC5B,EAAQ,KAAK,WAAW,SAO1B,kBAAkB,GAClB,KAAA,WAAa,EACb,KAAA,QAAQ,eAAiB,EAAQ,OAOhC,YACA,MAAA,EAAwB,MAAM,KAAK,KAAK,SAC1C,GAAsB,IAAtB,EAAW,OAGV,IAAA,IAAI,EAAI,EAAG,EAAI,KAAK,WAAW,OAAQ,IACtC,GAA+B,OAA/B,KAAK,WAAW,GAAG,QAAkB,CACjC,MAAA,EAA2B,KAAK,QAAQ,UAAU,OACtD,GAEG,KAAA,WAAW,GAAK,EAAgB,QACrC,EAAgB,SAAS,KAAK,WAAW,KASvC,uBACD,IAAA,MAAM,KAAW,MAAM,KAAK,KAAK,UAElC,EAAQ,QAAU,GAClB,EAAQ,WAAa,KAAK,QAAQ,iBAElC,EAAQ,QAAQ,QAAQ,GAAW,EAAO,QAAU,MAC/C,KAAA,QAAQ,OAAO,IAUlB,KAAK,GACN,KAAA,QAAQ,QAAQ,GAAW,EAAQ,KAAK,IAOvC,aACD,KAAA,QAAQ,QAAQ,GAAW,EAAQ,SACnC,KAAA,WACF,OAAO,GAA6B,OAAnB,EAAO,SACxB,QAAQ,IACH,IAAA,GAAQ,EACP,IAAA,MAAM,KAAW,MAAM,KAAK,KAAK,SAElC,GAAA,EAAQ,IACN,EACA,KAAK,QAAQ,GACb,KAAK,QAAQ,GACb,KAAK,QAAQ,GACb,KAAK,QAAQ,0BAEf,CACA,GAAQ,EACR,MAGC,GACE,KAAA,QAAQ,IAAI,IAAI,EAAA,QAAQ,OAhSvC,QAAA,KAAA;;ACgBA,aAAA,IAAA,EAAA,MAAA,KAAA,kBAAA,OAAA,OAAA,SAAA,EAAA,EAAA,EAAA,QAAA,IAAA,IAAA,EAAA,GAAA,OAAA,eAAA,EAAA,EAAA,CAAA,YAAA,EAAA,IAAA,WAAA,OAAA,EAAA,OAAA,SAAA,EAAA,EAAA,EAAA,QAAA,IAAA,IAAA,EAAA,GAAA,EAAA,GAAA,EAAA,KAAA,EAAA,MAAA,KAAA,qBAAA,OAAA,OAAA,SAAA,EAAA,GAAA,OAAA,eAAA,EAAA,UAAA,CAAA,YAAA,EAAA,MAAA,KAAA,SAAA,EAAA,GAAA,EAAA,QAAA,IAAA,EAAA,MAAA,KAAA,cAAA,SAAA,GAAA,GAAA,GAAA,EAAA,WAAA,OAAA,EAAA,IAAA,EAAA,GAAA,GAAA,MAAA,EAAA,IAAA,IAAA,KAAA,EAAA,YAAA,GAAA,OAAA,eAAA,KAAA,EAAA,IAAA,EAAA,EAAA,EAAA,GAAA,OAAA,EAAA,EAAA,GAAA,GAAA,EAAA,MAAA,KAAA,WAAA,SAAA,EAAA,EAAA,EAAA,GAAA,OAAA,IAAA,IAAA,EAAA,UAAA,SAAA,EAAA,GAAA,SAAA,EAAA,GAAA,IAAA,EAAA,EAAA,KAAA,IAAA,MAAA,GAAA,EAAA,IAAA,SAAA,EAAA,GAAA,IAAA,EAAA,EAAA,MAAA,IAAA,MAAA,GAAA,EAAA,IAAA,SAAA,EAAA,GAAA,IAAA,EAAA,EAAA,KAAA,EAAA,EAAA,QAAA,EAAA,EAAA,MAAA,aAAA,EAAA,EAAA,IAAA,EAAA,SAAA,GAAA,EAAA,MAAA,KAAA,EAAA,GAAA,GAAA,EAAA,EAAA,MAAA,EAAA,GAAA,KAAA,WAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,aAAA,EAhCA,MAAA,EAAA,QAAA,WACA,EAAA,QAAA,gBACA,QAAA,oBACA,MAAA,EAAA,EAAA,QAAA,YACA,EAAA,QAAA,qBAEA,EAAA,QAAA,+BAGA,EAAA,QAAA,mBACA,EAAA,QAAA,uBAEA,EAAA,QAAA,WACA,EAAA,QAAA,kBASA,EAAA,QAAA,UAUA,MAAa,EA8BX,YAAY,EAAmB,GACxB,KAAA,UAAY,EACZ,KAAA,WAAa,EAEb,KAAA,MAAQ,GACR,KAAA,YAAc,IAAI,IAClB,KAAA,MAAQ,IAAI,IACZ,KAAA,WAAQ,EACR,KAAA,QAAU,KAGV,IAAA,IAAI,EAAI,EAAG,EAAI,EAAW,IACxB,KAAA,MAAM,KAAK,IAAI,EAAA,KAAK,EAAA,SAAS,QAE/B,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,MAAM,KAAK,IAAI,EAAA,KAAK,EAAA,SAAS,SAI/B,IAAA,IAAI,EAAI,EAAG,EAAI,KAAK,UAAW,IAEhC,IAAA,IAAI,EAAY,KAAK,UACrB,EAAI,KAAK,WAAa,KAAK,UAC3B,IACA,CAEM,MAAA,GACH,KAAK,SAAW,IACjB,KAAK,UACL,KAAK,KAAK,EAAI,KAAK,WAChB,KAAA,QAAQ,KAAK,MAAM,GAAI,KAAK,MAAM,GAAI,IAYnC,gBAAS,GACf,MAAA,EAAmB,IAAI,EAAQ,EAAK,UAAW,EAAK,YAuBnD,OArBP,EAAQ,MAAQ,GAChB,EAAQ,YAAY,QAEpB,EAAK,MACF,IAAI,IAAY,IAAI,EAAA,MAAO,SAAS,IACpC,QAAQ,GAAS,EAAQ,MAAM,EAAK,OAAS,GAEhD,EAAK,YAAY,QAAQ,IACjB,MAAA,EAAyB,EAAQ,QACrC,EAAQ,MAAM,EAAe,WAC7B,EAAQ,MAAM,EAAe,SAC7B,EAAe,QAGoB,OAAjC,EAAe,eACjB,EAAQ,QACN,EAAQ,MAAM,EAAe,eAC7B,KAIC,EAeK,iBAAU,EAAmB,GA/G7C,IAAA,EAAA,EAiHM,GAAA,EAAS,YAAc,EAAS,WAChC,EAAS,aAAe,EAAS,WAE3B,MAAA,IAAI,MAAM,mDAIZ,MAAA,EAAqB,IAAI,EAC7B,EAAS,UACT,EAAS,YAEX,EAAU,YAAY,QACtB,EAAU,MAAQ,GAGZ,MAAA,EAA+B,QAAzB,EAAW,EAAS,aAAK,IAAA,EAAA,EAAI,EACnC,EAA+B,QAAzB,EAAW,EAAS,aAAK,IAAA,EAAA,EAAI,EAGrC,IAAA,EACA,GAAA,IAAW,EAAQ,CACf,MAAA,EAAc,KAAK,IACvB,EAAS,MAAM,OACf,EAAS,MAAM,QAEX,EAAc,KAAK,IACvB,EAAS,MAAM,OACf,EAAS,MAAM,QAEjB,EAAgB,EAAA,QAAQ,EAAK,EAAM,QAEnC,EADS,EAAS,EACF,EAAS,MAAM,OAEf,EAAS,MAAM,OAG3B,MAAA,EAAoB,EAAS,UAC7B,EAAqB,EAAS,WAG/B,IAAA,IAAI,EAAI,EAAG,EAAI,EAAS,MAAM,OAAQ,IACzC,EAAS,MAAM,GAAG,MAAQ,EAIvB,IAAA,IAAI,EAAI,EAAG,EAAI,EAAS,MAAM,OAAQ,IACzC,EAAS,MAAM,GAAG,MAAQ,EAIvB,IAAA,IAAI,EAAI,EAAG,EAAI,EAAe,IAAK,CAClC,IAAA,EACA,EAAkC,KAGlC,GAAA,EAAI,EAAW,CAEjB,EAAiB,EAAA,SAAS,MACpB,MAAA,EAAyB,EAAA,cAAgB,EAAW,EACtD,IAAA,GAAe,EACf,GAAK,EACF,KAAA,EAAc,GAAG,CAClB,GAAA,KAAO,EAAc,MAAM,OACvB,MAAA,WAAW,iDAEf,EAAc,MAAM,GAAG,eACzB,IAGJ,EAAa,EAAc,MAAM,QAC5B,GAAI,EAAI,EAAY,EAAY,CAErC,EAAiB,EAAA,SAAS,OACpB,MAAA,EAAyB,EAAA,cAAgB,EAAW,EACtD,IAAA,GAAgB,EAChB,GAAK,EACF,KAAA,EAAe,EAAI,GAAW,CAE/B,KADJ,GACS,EAAc,MAAM,OACrB,MAAA,WAAW,kDAEf,EAAc,MAAM,GAAG,gBACzB,IAGJ,EAAa,EAAc,MAAM,OAC5B,CAGD,IAAA,EADJ,EAAiB,EAAA,SAAS,OAGxB,EADE,GAAK,EAAS,MAAM,OACN,EACP,GAAK,EAAS,MAAM,OACb,EAEA,EAAA,cAAgB,EAAW,EAE7C,EAAa,EAAA,WAAW,EAAc,OAGlC,MAAA,EAAgB,IAAI,EAAA,KAAK,GAC/B,EAAQ,KAAO,EAAW,KAC1B,EAAQ,OAAS,EAAW,OAC5B,EAAU,MAAM,KAAK,GAIjB,MAAA,EAAgD,GAChD,EAAgD,GAGtD,EAAS,YAAY,QAAQ,IAC3B,EACE,EAAA,QAAQ,EAAW,KAAK,MAAO,EAAW,GAAG,QAC3C,EAAW,WAGjB,EAAS,YAAY,QAAQ,IAC3B,EACE,EAAA,QAAQ,EAAW,KAAK,MAAO,EAAW,GAAG,QAC3C,EAAW,WAIX,MAAA,EAA8C,GAC9C,EAAkB,OAAO,KAAK,GAC9B,EAAkB,OAAO,KAAK,GAC/B,IAAA,IAAI,EAAY,EAAM,OAAS,EAAG,GAAK,EAAG,SACH,IAAtC,EAAc,SAAS,EAAM,MAC/B,EAAY,KACV,EAAA,cACI,EAAc,SAAS,EAAM,KAC7B,EAAc,SAAS,EAAM,MAGnC,EAAc,SAAS,EAAM,UAAO,GAC3B,GAAU,GACnB,EAAY,KAAK,EAAc,SAAS,EAAM,MAwC3C,OAnCH,GAAU,GACZ,EACG,IAAI,GAAO,SAAS,IACpB,IAAI,GAAO,EAAc,IACzB,OAAO,QAAiB,IAAT,GACf,QAAQ,GAAQ,EAAY,KAAK,IAItC,EAAY,QAAQ,IAEhB,QAAmB,IAAnB,GACA,EAAe,QAAU,GACzB,EAAe,UAAY,EAC3B,CACM,MAAA,EAAa,EAAU,MAAM,EAAe,WAC5C,EAAW,EAAU,MAAM,EAAe,SAC1C,EAAyB,EAAU,QACvC,EACA,EACA,EAAe,QAIkB,OAAjC,EAAe,eACf,EAAe,cAAgB,GAE/B,EAAU,QACR,EAAU,MAAM,EAAe,eAC/B,MAMD,EAOF,OACE,OAAA,EAAQ,SAAS,KAAK,UAYxB,QAAQ,EAAY,EAAU,EAAS,GACtC,MAAA,EAAyB,EAAK,QAAQ,EAAI,GAEzC,OADF,KAAA,YAAY,IAAI,GACd,EAYF,SACL,EACA,EASI,IAhVR,IAAA,EAAA,EAkVQ,GAAA,EAAM,SAAW,KAAK,UAClB,MAAA,IAAI,WACR,6DAuBG,OAnBP,EAAQ,YAAiC,QAAtB,EAAG,EAAQ,mBAAW,IAAA,EAAA,EAAI,EAC7C,EAAQ,MAAqB,QAAhB,EAAG,EAAQ,aAAK,IAAA,GAAA,EAExB,KAAA,MACF,OAAO,GAAQ,EAAK,eACpB,QAAQ,CAAC,EAAY,IACpB,EAAK,SAAS,EAAM,GAAQ,EAAQ,QAGnC,KAAA,MACF,OAAO,GAAQ,EAAK,gBACpB,QAAS,IACJ,EAAQ,cACV,EAAK,KAAO,KAAK,UAAY,EAAQ,YAAc,EAAI,GAGzD,EAAK,cAAS,EAAW,EAAQ,SAG9B,KAAK,MACT,OAAO,GAAQ,EAAK,gBACpB,IAAK,GAAe,EAAK,cAAS,EAAW,EAAQ,QAWnD,UACL,EACA,EAaI,IAAE,IAAA,EAAA,EAAA,EAOF,GAJJ,EAAQ,KAAmB,QAAf,EAAG,EAAQ,YAAI,IAAA,EAAA,EAAI,GAC/B,EAAQ,SAA2B,QAAnB,EAAG,EAAQ,gBAAQ,IAAA,EAAA,EAAI,EACvC,EAAQ,OAAuB,QAAjB,EAAG,EAAQ,cAAM,IAAA,GAAA,EAE3B,EAAO,SAAW,KAAK,WACnB,MAAA,IAAI,MACR,2DAOC,KAAA,MACF,OAAO,GAAQ,EAAK,gBACpB,QAAQ,CAAC,EAAM,IAAU,EAAK,UAAU,EAAO,GAAQ,IAGrD,IAAA,IAAI,EAAY,KAAK,MAAM,OAAS,EAAG,GAAK,EAAG,IAC9C,KAAK,MAAM,GAAG,gBAEX,KAAA,MAAM,GAAG,eAAU,EAAW,GAKlC,KAAA,MACF,OAAO,GAAQ,EAAK,eACpB,QAAQ,GAAQ,EAAK,eAAU,EAAW,IAMxC,QACA,KAAA,MAAM,QAAQ,GAAQ,EAAK,SAS3B,WAAW,EAAY,GAWrB,OATF,KAAA,YAAY,QAAQ,IACnB,EAAK,OAAS,GAAQ,EAAK,KAAO,IACd,OAAlB,EAAK,UACF,KAAA,WAAW,GAEb,KAAA,YAAY,OAAO,MAIrB,EAAK,WAAW,GASlB,QAAQ,EAAY,GACrB,IAA8B,IAA9B,KAAK,MAAM,QAAQ,GACf,MAAA,IAAI,eAAe,yCACQ,OAAxB,EAAW,WAGtB,EAAK,QAAQ,GACR,KAAA,MAAM,IAAI,IAQV,WAAW,GACZ,IAAC,KAAK,MAAM,IAAI,GACZ,MAAA,IAAI,MAAM,iCAEb,KAAA,MAAM,OAAO,GACU,OAAxB,EAAW,UACb,EAAW,SAAS,WAAW,GAU5B,WACL,EACA,GAAqB,IAAI,EAAA,iBAAkB,WAEvC,IAAC,KAAK,MAAM,SAAS,GACjB,MAAA,IAAI,eAAe,4CAGtB,KAAA,WAAW,EAAM,GAEhB,MAAA,EAAiB,GACjB,EAAgB,GAChB,EAAkB,GAClB,EAA4B,GAsC3B,IAnCP,EAAK,SAAS,QAAQ,IAElB,GACwB,OAAxB,EAAW,UACX,EAAW,WAAa,GAExB,EAAM,KAAK,EAAW,UAExB,EAAO,KAAK,EAAW,MAClB,KAAA,WAAW,EAAW,KAAM,KAInC,EAAK,SAAS,QAAQ,IAElB,GACwB,OAAxB,EAAW,UACX,EAAW,WAAa,GAExB,EAAM,KAAK,EAAW,UAExB,EAAQ,KAAK,EAAW,IACnB,KAAA,WAAW,EAAM,EAAW,MAInC,EAAO,QAAQ,IACb,EAAQ,QAAQ,IACT,EAAM,eAAe,IACxB,EAAY,KAAK,KAAK,QAAQ,EAAO,QAMpC,EAAM,OAAS,GAAK,EAAY,OAAS,GAAG,CAC3C,MAAA,EAAyB,EAAM,QACjC,QAAS,IAAT,EACF,SAGI,MAAA,EAAyB,EAAA,WAAW,GACrC,KAAA,QAAQ,EAAM,GACnB,EAAA,gBAAgB,EAAa,GAI/B,EAAK,MAAM,QAAQ,KAAK,YAExB,EAAA,gBAAgB,KAAK,MAAO,GAYvB,OACL,EACA,GAmBA,EAAO,OAAO,KAAM,GAYf,aACL,EAA6B,EAAA,cAC7B,EAiBI,IAE0B,IAA1B,EAAe,QAId,KAAA,OAAO,EAAA,WAAW,GAAiB,GAUnC,MACL,GAgBE,GAAA,EAAQ,QAAQ,GAAG,MAAM,SAAW,KAAK,WACzC,EAAQ,QAAQ,GAAG,OAAO,SAAW,KAAK,WAEpC,MAAA,IAAI,MACR,0EAIE,MAAA,EAAgB,KAAK,MAEvB,GAAA,EAAQ,YAAc,GAAK,EAAQ,OAAS,EACxC,MAAA,IAAI,MACR,8EAKA,IAAA,EACA,EAUA,EAqBA,EAXA,EAAQ,sBAAwB,GAClC,EAAkB,KAAK,MACpB,EAAI,EAAQ,uBAAyB,EAAQ,QAAQ,QAExD,EAAc,EAAQ,QAAQ,MAAM,EAAG,GACvC,EAAU,EAAQ,QAAQ,MAAM,KAEhC,EAAc,EAAQ,QACtB,EAAU,IAIR,IAAA,EAAiB,EACjB,EAAQ,EAIV,KAAA,EAAQ,EAAQ,QACf,EAAQ,YAAc,GAAK,EAAiB,EAAQ,aAErD,IAGA,EAAsB,EAAQ,KAAK,KAAK,GAGxC,EAAQ,KAAK,WAAW,CACtB,QAAS,EACT,UAAW,EAAQ,UACnB,aAAc,EACd,SAAU,EAAQ,SAClB,KAAM,EAAQ,KACd,YAAa,EAAQ,UAGnB,EAAQ,OACL,KAAA,QAIH,EAAQ,sBAAwB,IAClC,EAAQ,KAAK,KAAK,EAAS,EAAQ,MAC/B,EAAQ,OACL,KAAA,SAIL,EAAQ,SACV,EAAA,QAAQ,EAAQ,SAGd,EAAQ,IAAM,GAAK,EAAiB,EAAQ,KAAQ,GACtD,QAAQ,IACN,mBACA,EACA,QACA,EACA,gBACA,GAKF,EAAQ,UACR,EAAiB,EAAQ,SAAS,YAAe,GAEjD,EAAQ,SAAS,SAAS,EAAO,GAQ9B,OAJH,EAAQ,OACL,KAAA,QAGA,CACL,MAAA,EACA,WAAY,EACZ,KAAM,KAAK,MAAQ,GAYhB,KACL,EAUA,EAAiB,EAAA,SAEb,IAAA,EAAQ,EAEP,IAAA,MAAM,KAAS,EAAS,CACrB,MAAA,EAAkB,EAAM,MAG9B,GAAS,EAFgB,EAAM,OACN,KAAK,SAAS,EAAO,CAAC,OAAO,KAIjD,OAAA,EAAQ,EAAQ,OAQlB,SACC,MAAA,EAAoB,CACxB,MAAO,GACP,YAAa,GACb,UAAW,KAAK,UAChB,WAAY,KAAK,YAId,IAAA,IAAI,EAAI,EAAG,EAAI,KAAK,MAAM,OAAQ,IAChC,KAAA,MAAM,GAAG,MAAQ,EAiBjB,OAbF,KAAA,MAAM,QAAQ,IACjB,EAAK,MAAM,KAAK,EAAK,UAEc,IAA/B,EAAK,eAAe,QAGtB,EAAK,YAAY,KAAK,EAAK,eAAe,YAIzC,KAAA,YAAY,QAAQ,IACvB,EAAK,YAAY,KAAK,EAAK,YAEtB,EAYI,OACX,EAAyB,IAAI,EAAA,eAh1BjC,OAAA,EAAA,UAAA,OAAA,EAAA,YAg2BM,IAAC,EAAQ,iBACT,EAAQ,UACP,EAAQ,QAAQ,GAAG,MAAM,SAAW,KAAK,WACxC,EAAQ,QAAQ,GAAG,OAAO,SAAW,KAAK,YAEtC,MAAA,IAAI,MACR,0EAKJ,EAAQ,MAAQ,KAAK,UACrB,EAAQ,OAAS,KAAK,WAEhB,MAAA,EAAgB,KAAK,MAGvB,IAAA,EAA+B,KAE/B,IAAC,EAAQ,gBAAiB,CAKtB,MAAA,EAA4B,KAAK,UAAU,EAAQ,SACnD,EAAoB,OAAO,OAAO,EAAA,YAAY,QAAQ,EAAQ,MAEpE,EAAa,EAAA,KACX,IAAM,EAAA,MAAkB,IAAI,EAAA,OAAO,iCACnC,EAAQ,SAEV,EAAQ,gBAAkB,SACxB,GAh4BR,OAAA,EAAA,UAAA,OAAA,EAAA,YAk4Ba,IAAA,MAAM,KAAU,EAEf,GACF,EAAW,MAAa,GAAoB,EAAA,UAAA,OAAA,EAAA,YACtC,QAAW,IAAX,EACI,MAAA,IAAI,eAGZ,EAAO,cAAgB,EACrB,EACA,KAAK,UAAU,EAAO,UACtB,OAMJ,UACI,EAAW,gBAIvB,EAAQ,SAAW,KAEb,MAAA,EAAa,IAAI,EAAA,KAAK,GAExB,IAAA,EACA,EAAc,EACd,EAA6B,KAG9B,EAAA,CACK,MAAA,QAAyB,EAAK,SAEhC,IAAC,EAAQ,MACL,MAAA,IAAI,eAGZ,EAAQ,EAAQ,OAEgB,IAA5B,EAAK,QAAQ,YAAoB,EAAQ,MAAQ,KACnD,EAAc,EAAQ,MACtB,EAAa,GAIb,EAAQ,UACR,EAAK,QAAQ,WAAa,EAAQ,SAAS,YAAe,GAE1D,EAAQ,SAAS,SACf,EAAQ,OACP,EACD,EAAK,QAAQ,kBAIjB,GAAS,EAAQ,QACO,IAAvB,EAAQ,YAAoB,EAAK,QAAQ,WAAa,EAAQ,aAkB1D,OAfH,IAEG,KAAA,MAAQ,EAAW,MACnB,KAAA,YAAc,EAAW,YACzB,KAAA,MAAQ,EAAW,MAEpB,EAAQ,OACL,KAAA,SAIU,OAAf,UACI,EAAW,aAGZ,CACL,OAAQ,EACR,WAAY,EAAK,QAAQ,WACzB,KAAM,KAAK,MAAQ,KAWhB,SAAS,EAAa,EAAY,EAAY,GAE9C,IAAA,IAAI,EAAI,EAAG,EAAI,KAAK,MAAM,OAAQ,IAChC,KAAA,MAAM,GAAG,MAAQ,EAInB,IAAA,IAAI,EAAI,EAAG,EAAI,EAAG,MAAM,OAAQ,IACnC,EAAG,MAAM,GAAG,MAAQ,EAGlB,IAAA,EAAU,EACV,EAAU,EAER,MAAA,EAA6B,MAAM,KAAK,KAAK,aAAa,OAC9D,QAAiB,IAAT,GAEJ,EAA6B,MAAM,KAAK,EAAG,aAAa,OAC5D,QAAiB,IAAT,GAiBN,GAdJ,EAAQ,KAAK,EAAc,CAAC,EAAe,IAClC,EAAE,kBAAoB,EAAE,mBAGjC,EAAQ,KAAK,EAAc,CAAC,EAAe,IAClC,EAAE,kBAAoB,EAAE,mBAGI,EACnC,EAAa,OAAS,GACtB,kBACmC,EACnC,EAAa,OAAS,GACtB,kBAEO,OAAA,EAAG,SAAS,KAAM,EAAI,EAAI,GAG/B,IAAA,EAAgB,EAChB,EAAkB,EAClB,EAAe,EAEZ,KAAA,EAAU,EAAa,QAAU,EAAU,EAAa,QAAQ,CAC/D,MAAA,EAAoB,EAAa,GACjC,EAAoB,EAAa,GAEnC,QAAU,IAAV,QAAiC,IAAV,EACnB,MAAA,MAAM,QAGM,EAAM,oBACN,EAAM,mBAIxB,IACA,IACA,GAAmB,KAAK,IAAI,EAAM,OAAS,EAAM,QACjD,KACS,EAAU,GAEnB,IACA,MAGA,IACA,KAGJ,GAAmB,EACb,MAAA,EAAsB,KAAK,YAAY,KAAO,EAEhD,IAAA,EAAY,KAAK,IAAI,KAAK,YAAY,KAAM,EAAG,YAAY,MAM5D,OALC,EAAI,KACN,EAAI,GAIH,EAAK,EAAe,EAAK,EAAK,EAAiB,EAAI,EAAK,EAWrD,WAAW,GAmCb,IAAA,EAAW,EACV,IAAA,IAAI,EAAI,EAAG,EAAI,EAAQ,QAAQ,OAAQ,IAAK,CACzC,MAAA,EAAkB,EAAQ,QAAQ,GAAG,MACrC,EAA0B,EAAQ,QAAQ,GAAG,OAE7C,GACH,EAAI,GAAK,EAAQ,WAAc,GAAK,EAAI,IAAM,EAAQ,QAAQ,OAE3D,EAAmB,KAAK,SAAS,EAAO,CAC5C,YAAa,EAAQ,cAElB,KAAA,UAAU,EAAe,CAC5B,KAAM,EAAQ,aACd,SAAU,EAAQ,SAClB,OAAA,IAGF,GAAY,EAAQ,KAAK,EAAe,GAEnC,OAAA,EAAW,EAAQ,QAAQ,QA3mCtC,QAAA,QAAA;;ACxBA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,eAAA,EARA,MAAA,EAAA,QAAA,kCACA,EAAA,QAAA,mCACA,EAAA,QAAA,kBACA,EAAA,QAAA,aAKA,MAAa,EAeX,cACO,KAAA,OAAS,GAUT,SACL,EACA,GAEM,MAAA,EACJ,MAAA,EAAA,EAA0B,EAAM,mCAE9B,IAAC,EAAM,wBAAwB,GAC3B,MAAA,IAAI,eACR,mBACE,EACA,4BACA,EAAM,YAAY,MAQjB,OAJF,KAAA,OAAO,KAAK,CACf,MAAA,EACA,uBAAwB,IAEnB,KAQF,aACD,KAAE,KAAK,OAAO,GAAG,iBAAiB,EAAA,YAC9B,MAAA,IAAI,eACR,qDACE,KAAK,OAAO,GAAG,MAAM,YAAY,MAGnC,KAAE,KAAK,OAAO,KAAK,OAAO,OAAS,GAAG,iBAAiB,EAAA,aACnD,MAAA,IAAI,eACR,qDACE,KAAK,OAAO,KAAK,OAAO,OAAS,GAAG,MAAM,YAAY,MAItD,MAAA,EAAoB,KAAK,OAAO,GAAG,MAAM,MAAM,OAC/C,EAAqB,KAAK,OAAO,KAAK,OAAO,OAAS,GAAG,MAAM,MAClE,OAEG,EAAmB,IAAI,EAAA,QAAQ,EAAW,GAChD,EAAQ,MAAQ,GAChB,EAAQ,YAAY,QAEf,IAAA,IAAI,EAAI,EAAG,EAAI,KAAK,OAAO,OAAS,EAAG,IAC1C,EAAA,MAAM,QACJ,KAAK,OAAO,GAAG,MACf,KAAK,OAAO,EAAI,GAAG,MACnB,KAAK,OAAO,EAAI,GAAG,wBACnB,QAAQ,GAAQ,EAAQ,YAAY,IAAI,IAE1C,EAAQ,MAAM,QAAQ,KAAK,OAAO,GAAG,MAAM,OACtC,KAAA,OAAO,GAAG,MAAM,YAAY,QAAQ,GACvC,EAAQ,YAAY,IAAI,IAErB,KAAA,OAAO,GAAG,MAAM,MAAM,QAAQ,GAAQ,EAAQ,MAAM,IAAI,IAGxD,OADP,EAAQ,MAAM,QAAQ,KAAK,OAAO,KAAK,OAAO,OAAS,GAAG,MAAM,OACzD,GA1FX,QAAA,UAAA;;ACHA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,oBAAA,EANA,MAAA,EAAA,QAAA,qBACA,EAAA,QAAA,kBAKA,MAAa,UAAuB,EAAA,aAClC,cACE,QAYK,WACA,KAAA,IAAM,KAAK,MAEV,MAAA,EAA2B,MAAM,KAAK,KAAK,UAAU,IACzD,GAAQ,EAAK,KAAK,WAAa,EAAK,OAAS,EAAK,MAGhD,GAA0B,IAA1B,EAAe,OACX,MAAA,IAAI,eAAe,2CAQpB,OALF,KAAA,MAAQ,EAAe,GAEvB,KAAA,WAAa,KAAK,OAAO,KAAK,OAAO,GAAS,KAAK,KACnD,KAAA,gBAAkB,KAAK,OAAO,KAAK,OAAO,GAExC,KAAK,WAaP,UACL,EACA,GA7CJ,IAAA,EAAA,EAAA,EA4DI,EAAQ,SAA2B,QAAnB,EAAG,EAAQ,gBAAQ,IAAA,EAAA,EAAI,EACvC,EAAQ,KAAmB,QAAf,EAAG,EAAQ,YAAI,IAAA,EAAA,EAAI,GAC/B,EAAQ,OAAuB,QAAjB,EAAG,EAAQ,cAAM,IAAA,GAAA,EAEzB,MAAA,EAA8B,MAAM,KAAK,KAAK,UAAU,IAC5D,GAAQ,EAAK,GAAG,oBAAsB,EAAK,OAAS,EAAK,MAEtD,KAAA,oBAAsB,KAAK,eAC9B,EAAA,IAAI,GAAqB,KAAK,gBAE3B,KAAA,SAAS,QAAQ,IAAa,IAAA,EAAA,EAE7B,IAAA,EAAmB,KAAK,eAAiB,EAAW,YACxD,EAAW,OAAO,QAAQ,CAAC,EAAO,KAChC,GAAY,EAAI,oBAAsB,IAGxC,EAAW,oBACI,QAAb,EAAC,EAAQ,YAAI,IAAA,EAAA,EAAI,IAAO,EAAW,KAAK,KACtC,EAAQ,SACV,EAAW,oBACQ,QAAjB,EAAC,EAAQ,gBAAQ,IAAA,EAAA,EAAI,GAAK,EAAW,qBACvC,EAAW,QAAU,EAAW,kBAChC,EAAW,qBAAuB,EAAW,kBAC7C,EAAW,kBAAoB,MApFvC,QAAA,eAAA;;ACEA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,qBAAA,EARA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,iCACA,EAAA,QAAA,8BACA,EAAA,QAAA,YAKA,MAAa,UAAwB,EAAA,MACnC,YACE,EACA,EAKI,IARR,IAAA,EAUU,MAAA,GAEA,MAAA,EAA+C,QAArC,EAAmB,EAAQ,kBAAU,IAAA,EAAA,EAAI,EAAA,SAEpD,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,WAAW,KAAI,IAAI,EAAA,gBAAiB,kBAAkB,IAGxD,KAAA,YAAc,KAAK,WACnB,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,aAU9B,wBAAwB,GACtB,OAAA,IAAS,EAAA,eAAe,WAQ1B,mCACE,OAAA,EAAA,eAAe,YAvC1B,QAAA,gBAAA;;ACCA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,gBAAA,EATA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,iCACA,EAAA,QAAA,2BACA,EAAA,QAAA,cACA,EAAA,QAAA,YAKA,MAAa,UAAmB,EAAA,MAC9B,YACE,EACA,EAKI,IARR,IAAA,EAUU,MAAA,GAEA,MAAA,EAAmD,QAAzC,EAAmB,EAAQ,sBAAc,IAAA,EAAA,EAAI,EAAA,SAExD,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,WAAW,IACd,IAAI,EAAA,KAAK,EAAA,SAAS,QAAQ,kBAAkB,IAI3C,KAAA,YAAc,KAAK,WACnB,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,aAQ9B,0BACE,OAAA,EAQF,mCACE,OAAA,EAAA,eAAe,YAvC1B,QAAA,WAAA;;ACDA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,iBAAA,EAPA,MAAA,EAAA,QAAA,qBAEA,EAAA,QAAA,kBAKA,MAAa,UAAoB,EAAA,aAU/B,YAAY,GACV,QACK,KAAA,YAAc,EACd,KAAA,YAAa,EAYb,WACD,GAAuB,IAAvB,KAAK,SAAS,KACV,MAAA,IAAI,WACR,6DAGE,MAAA,EAAiC,MAAM,KAAK,KAAK,UAAU,GAoB1D,OAjBH,EAAA,WAAW,EAAG,GAAK,KAAK,aAErB,KAAA,YAAa,EACb,KAAA,MAAQ,IAER,KAAA,YAAa,EACb,KAAA,MACH,EAAmB,KAAK,WACxB,EAAmB,OACnB,EAAmB,KAChB,KAAA,OAAS,GAAK,EAAI,KAAK,cAEzB,KAAA,WAAa,KAAK,OAAO,KAAK,OAAO,GAAS,KAAK,KAGnD,KAAA,MAAM,QAAQ,GAAS,EAAK,KAAO,KAAK,YAEtC,KAAK,WAaP,UACL,EACA,EAaI,IA/ER,IAAA,EAAA,EAAA,EAiFI,EAAQ,SAA2B,QAAnB,EAAG,EAAQ,gBAAQ,IAAA,EAAA,EAAI,EACvC,EAAQ,KAAmB,QAAf,EAAG,EAAQ,YAAI,IAAA,EAAA,EAAI,GAC/B,EAAQ,OAAuB,QAAjB,EAAG,EAAQ,cAAM,IAAA,GAAA,EAEzB,MAAA,EAA8B,MAAM,KAAK,KAAK,UAAU,IAC5D,GAAQ,EAAK,GAAG,oBAAsB,EAAK,OAAS,EAAK,MAKvD,GAHC,KAAA,oBAAsB,KAAK,eAC9B,EAAA,IAAI,IAAsB,EAAI,KAAK,aAEV,IAAvB,KAAK,SAAS,KACV,MAAA,IAAI,WACR,6DAGE,MAAA,EAAyB,MAAM,KAAK,KAAK,UAAU,GAGrD,IAAC,KAAK,WAAY,CAChB,IAAA,EAAmB,KAAK,eAAiB,EAAW,YAExD,EAAW,OAAO,QAAQ,CAAC,EAAO,KAChC,GAAY,EAAI,oBAAsB,IAGpC,EAAQ,SACV,EAAW,mBACT,EAAQ,KAAO,EAAW,KAAK,KAC/B,EAAQ,SAAW,EAAW,qBAChC,EAAW,QAAU,EAAW,kBAChC,EAAW,qBAAuB,EAAW,kBAC7C,EAAW,kBAAoB,IAY9B,SAAS,GAGP,OAFD,MAAA,SAAS,GACV,KAAA,YAAc,EAAK,YACjB,KAQF,SACE,OAAA,OAAO,OAAO,MAAM,SAAU,CACnC,YAAa,KAAK,eAzIxB,QAAA,YAAA;;ACAA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,kBAAA,EARA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,iCACA,EAAA,QAAA,2BACA,EAAA,QAAA,YAKA,MAAa,UAAqB,EAAA,MAChC,YACE,EACA,EASI,IAZR,IAAA,EAAA,EAcU,MAAA,GAEA,MAAA,EAA+C,QAArC,EAAmB,EAAQ,kBAAU,IAAA,EAAA,EAAI,EAAA,UACnD,EAAyC,QAA9B,EAAW,EAAQ,mBAAW,IAAA,EAAA,EAAI,GAE9C,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,WAAW,IACd,IAAI,EAAA,YAAY,GAAa,kBAAkB,IAI9C,KAAA,YAAc,KAAK,WACnB,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,aAQ9B,mCACE,OAAA,EAAA,eAAe,WAUjB,wBAAwB,GACtB,OAAA,IAAS,EAAA,eAAe,YA9CnC,QAAA,aAAA;;ACEA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,cAAA,EAVA,MAAA,EAAA,QAAA,wBAEA,EAAA,QAAA,qBAGA,EAAA,QAAA,kBAKA,MAAa,UAAiB,EAAA,aAU5B,YAAY,EAA4B,EAAA,aAAa,aACnD,QACK,KAAA,YAAc,EACd,KAAA,cAAgB,KAUhB,SAAS,GAGP,OAFD,MAAA,SAAS,GACV,KAAA,YAAc,EAAK,SACjB,KAYF,WACC,MAAA,EAA4B,MAAM,KAAK,KAAK,UAC5C,EAA2B,EAAY,IAC3C,GAAQ,EAAK,KAAK,WAAa,EAAK,OAAS,EAAK,MAGhD,GAAA,KAAK,cAAgB,EAAA,aAAa,YAAa,CAC3C,MAAA,EAAgB,EAAA,cAAc,GAC/B,KAAA,cAAgB,EAAY,GAAO,KACnC,KAAA,MAAQ,EAAe,QACvB,GAAI,KAAK,cAAgB,EAAA,aAAa,YACtC,KAAA,MAAQ,EAAA,IAAI,OACZ,CAAA,GAAI,KAAK,cAAgB,EAAA,aAAa,YAKrC,MAAA,IAAI,eACR,gCAAkC,KAAK,aANe,CAClD,MAAA,EAAgB,EAAA,cAAc,GAC/B,KAAA,cAAgB,EAAY,GAAO,KACnC,KAAA,MAAQ,EAAe,IAevB,OARF,KAAA,WAAa,KAAK,OAAO,KAAK,OAAO,GAAS,KAAK,KACpD,KAAK,cAAgB,EAAA,aAAa,cAC/B,KAAA,gBAAkB,KAAK,OAAO,KAAK,OAAO,IAI5C,KAAA,MAAM,QAAQ,GAAS,EAAK,KAAO,KAAK,YAEtC,KAAK,WAaP,UACL,EACA,EAaI,IAhGR,IAAA,EAAA,EAAA,EAkGI,EAAQ,SAA2B,QAAnB,EAAG,EAAQ,gBAAQ,IAAA,EAAA,EAAI,EACvC,EAAQ,KAAmB,QAAf,EAAG,EAAQ,YAAI,IAAA,EAAA,EAAI,GAC/B,EAAQ,OAAuB,QAAjB,EAAG,EAAQ,cAAM,IAAA,GAAA,EAEzB,MAAA,EAA8B,MAAM,KAAK,KAAK,UAAU,IAC5D,GAAQ,EAAK,GAAG,oBAAsB,EAAK,OAAS,EAAK,MAEtD,KAAA,oBAAsB,KAAK,eAC9B,EAAA,IAAI,GAAqB,KAAK,gBAC5B,KAAK,cAAgB,EAAA,aAAa,YAC/B,KAAA,SAAS,QAAQ,IAAa,IAAA,EAAA,EAE7B,IAAA,EAAmB,KAAK,eAAiB,EAAW,YACxD,EAAW,OAAO,QAAQ,CAAC,EAAO,KAChC,GAAY,EAAI,oBAAsB,IAGxC,EAAW,oBACI,QAAb,EAAC,EAAQ,YAAI,IAAA,EAAA,EAAI,IAAO,EAAW,KAAK,KACtC,EAAQ,SACV,EAAW,oBACQ,QAAjB,EAAC,EAAQ,gBAAQ,IAAA,EAAA,EAAI,GAAK,EAAW,qBACvC,EAAW,QAAU,EAAW,kBAChC,EAAW,qBAAuB,EAAW,kBAC7C,EAAW,kBAAoB,KAM9B,KAAA,SAAS,QAAQ,IACpB,EAAK,OAAS,KAAK,gBAAkB,EAAK,KAAO,EAAI,EACrD,EAAK,KAAO,KAAK,gBAAkB,EAAK,KAAO,EAAI,IAUlD,SACE,OAAA,OAAO,OAAO,MAAM,SAAU,CACnC,SAAU,KAAK,eA9IrB,QAAA,SAAA;;ACJA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,kBAAA,EANA,MAAA,EAAA,QAAA,iCACA,EAAA,QAAA,YAKA,MAAsB,UAAqB,EAAA,MACzC,YAAsB,GACd,MAAA,GAQD,mCACE,OAAA,EAAA,eAAe,QAQjB,0BACE,OAAA,GApBX,QAAA,aAAA;;ACEA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,uBAAA,EARA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,2BACA,EAAA,QAAA,wBACA,EAAA,QAAA,kBAKA,MAAa,UAA0B,EAAA,aACrC,YACE,EACA,EAKI,IARR,IAAA,EAUU,MAAA,GAEA,MAAA,EAAmD,QAArC,EAAmB,EAAQ,kBAAU,IAAA,EAAA,EAAI,EAAA,UAExD,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,WAAW,IACd,IAAI,EAAA,SAAS,EAAA,aAAa,aAAa,kBAAkB,IAIxD,KAAA,YAAc,KAAK,WACnB,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,cArBvC,QAAA,kBAAA;;ACFA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,6BAAA,EALA,MAAA,EAAA,QAAA,uBAKA,MAAa,UAAgC,EAAA,kBAC3C,YACE,EACA,EAKI,IAEE,MAAA,EAAG,IAVb,QAAA,wBAAA;;ACEA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,uBAAA,EARA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,2BACA,EAAA,QAAA,wBACA,EAAA,QAAA,kBAKA,MAAa,UAA0B,EAAA,aACrC,YACE,EACA,EAKI,IARR,IAAA,EAUU,MAAA,GAEA,MAAA,EAAmD,QAArC,EAAmB,EAAQ,kBAAU,IAAA,EAAA,EAAI,EAAA,UAExD,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,WAAW,IACd,IAAI,EAAA,SAAS,EAAA,aAAa,aAAa,kBAAkB,IAIxD,KAAA,YAAc,KAAK,WACnB,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,cArBvC,QAAA,kBAAA;;ACFA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,6BAAA,EALA,MAAA,EAAA,QAAA,uBAKA,MAAa,UAAgC,EAAA,kBAC3C,YACE,EACA,EAKI,IAEE,MAAA,EAAG,IAVb,QAAA,wBAAA;;ACEA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,uBAAA,EARA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,2BACA,EAAA,QAAA,wBACA,EAAA,QAAA,kBAKA,MAAa,UAA0B,EAAA,aACrC,YACE,EACA,EAKI,IARR,IAAA,EAUU,MAAA,GAEA,MAAA,EAAmD,QAArC,EAAmB,EAAQ,kBAAU,IAAA,EAAA,EAAI,EAAA,UAExD,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,WAAW,IACd,IAAI,EAAA,SAAS,EAAA,aAAa,aAAa,kBAAkB,IAIxD,KAAA,YAAc,KAAK,WACnB,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,cArBvC,QAAA,kBAAA;;ACFA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,6BAAA,EALA,MAAA,EAAA,QAAA,uBAKA,MAAa,UAAgC,EAAA,kBAC3C,YACE,EACA,EAKI,IAEE,MAAA,EAAG,IAVb,QAAA,wBAAA;;ACKA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,cAAA,EAXA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,iCACA,EAAA,QAAA,6BACA,EAAA,QAAA,2BAEA,EAAA,QAAA,cACA,EAAA,QAAA,YAKA,MAAa,UAAiB,EAAA,MAC5B,YACE,EACA,EAKI,IAEE,MAAA,GACA,MAAA,EAAqB,GACrB,EAA4B,GAC5B,EAAoB,GACpB,EAAqB,GACrB,EAAyB,GAE1B,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,WAAW,IAAI,IAAI,EAAA,KAAK,EAAA,SAAS,SACtC,EAAW,KAAK,IAAI,EAAA,KAAK,EAAA,SAAS,QAAQ,QAAQ,IAClD,EAAkB,KAChB,IAAI,EAAA,KAAK,EAAA,SAAS,QAAQ,QAAQ,GAAG,kBAAkB,EAAA,WAEzD,EAAU,KAAK,IAAI,EAAA,KAAK,EAAA,SAAS,QAAQ,QAAQ,IACjD,EAAW,KAAK,IAAI,EAAA,KAAK,EAAA,SAAS,QAAQ,kBAAkB,EAAA,OAC5D,EAAe,KACb,IAAI,EAAA,KAAK,EAAA,SAAS,QAAQ,QAAQ,GAAG,kBAAkB,EAAA,WAEpD,KAAA,YAAY,IAAI,IAAI,EAAA,KAAK,EAAA,SAAS,SAGpC,KAAA,YAAY,QACZ,EAAA,MAAM,QAAQ,KAAK,WAAY,EAAY,EAAA,eAAe,aAE1D,KAAA,YAAY,QACZ,EAAA,MAAM,QAAQ,KAAK,WAAY,EAAW,EAAA,eAAe,aAEzD,KAAA,YAAY,QACZ,EAAA,MAAM,QAAQ,KAAK,WAAY,EAAY,EAAA,eAAe,aAG1D,KAAA,YAAY,QACZ,EAAA,MAAM,QAAQ,EAAgB,EAAY,EAAA,eAAe,aAGzD,KAAA,YAAY,QACZ,EAAA,MAAM,QACP,EACA,EACA,EAAA,eAAe,WACf,IAIC,KAAA,YAAY,QACZ,EAAA,MAAM,QAAQ,EAAgB,EAAW,EAAA,eAAe,aAGvD,MAAA,EAAsB,EAAA,MAAM,QAChC,EACA,EACA,EAAA,eAAe,YAEZ,KAAA,YAAY,QAAQ,GACpB,KAAA,MAAM,QAAQ,EAAA,MAAM,KAAK,EAAW,EAAO,EAAA,WAAW,SAErD,MAAA,EAAuB,EAAA,MAAM,QACjC,EACA,KAAK,YACL,EAAA,eAAe,YAEX,EAA8B,EAAA,MAAM,QACxC,EACA,KAAK,YACL,EAAA,eAAe,YAEZ,KAAA,YAAY,QAAQ,GACpB,KAAA,YAAY,QAAQ,GAEpB,KAAA,MAAM,QAAQ,EAAA,MAAM,KAAK,EAAY,EAAQ,EAAA,WAAW,SACxD,KAAA,MAAM,QACN,EAAA,MAAM,KAAK,EAAmB,EAAe,EAAA,WAAW,SAGxD,KAAA,YAAY,QACZ,EAAA,MAAM,QACP,KAAK,YACL,EACA,EAAA,eAAe,WACf,IAIC,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,aAC9B,KAAA,MAAM,QAAQ,GACd,KAAA,MAAM,QAAQ,GACd,KAAA,MAAM,QAAQ,GACd,KAAA,MAAM,QAAQ,GACd,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,cAC9B,KAAA,MAAM,QAAQ,GAEd,KAAA,YAAY,QACf,IAAO,IAAA,EAAE,OAAA,EAAK,OAA2B,QAArB,EAAG,EAAQ,kBAAU,IAAA,EAAA,EAAI,EAAA,WAS1C,0BACE,OAAA,EAQF,mCACE,OAAA,EAAA,eAAe,YAzH1B,QAAA,SAAA;;ACFA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,mBAAA,EATA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,iCACA,EAAA,QAAA,2BACA,EAAA,QAAA,cACA,EAAA,QAAA,YAKA,MAAa,UAAsB,EAAA,MACjC,YAAY,GACJ,MAAA,GAED,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,WAAW,IAAI,IAAI,EAAA,KAAK,EAAA,SAAS,SACjC,KAAA,YAAY,IACf,IAAI,EAAA,KAAK,EAAA,SAAS,QAAQ,kBAAkB,EAAA,aAI3C,KAAA,YAAY,QACZ,EAAA,MAAM,QACP,KAAK,WACL,KAAK,YACL,EAAA,eAAe,aAGd,KAAA,YAAY,QACZ,EAAA,MAAM,QACP,KAAK,YACL,KAAK,WACL,EAAA,eAAe,aAId,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,aAC9B,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,cAQ9B,0BACE,OAAA,EAQF,mCACE,OAAA,EAAA,eAAe,YA7C1B,QAAA,cAAA;;ACEA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,eAAA,EAXA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,iCACA,EAAA,QAAA,6BACA,EAAA,QAAA,2BAEA,EAAA,QAAA,cACA,EAAA,QAAA,YAKA,MAAa,UAAkB,EAAA,MAC7B,YACE,EACA,EAKI,IAEE,MAAA,GAEA,MAAA,EAAoB,GACpB,EAAqB,GACrB,EAAqB,GACrB,EAAqB,GAEtB,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,WAAW,IAAI,IAAI,EAAA,KAAK,EAAA,SAAS,SACtC,EAAU,KAAK,IAAI,EAAA,KAAK,EAAA,SAAS,QAAQ,QAAQ,IACjD,EAAW,KACT,IAAI,EAAA,KAAK,EAAA,SAAS,QAAQ,QAAQ,GAAG,kBAAkB,EAAA,WAEzD,EAAW,KAAK,IAAI,EAAA,KAAK,EAAA,SAAS,SAClC,EAAW,KAAK,IAAI,EAAA,KAAK,EAAA,SAAS,QAAQ,QAAQ,IAC7C,KAAA,YAAY,IAAI,IAAI,EAAA,KAAK,EAAA,SAAS,SAGpC,KAAA,YAAY,QACZ,EAAA,MAAM,QAAQ,EAAY,EAAW,EAAA,eAAe,aAEpD,KAAA,YAAY,QACZ,EAAA,MAAM,QAAQ,EAAY,EAAY,EAAA,eAAe,aAErD,KAAA,YAAY,QACZ,EAAA,MAAM,QAAQ,EAAY,EAAY,EAAA,eAAe,aAEpD,MAAA,EAAsC,EAAA,MAAM,QAChD,EACA,EACA,EAAA,eAAe,YAEX,EAAsC,EAAA,MAAM,QAChD,EACA,KAAK,YACL,EAAA,eAAe,YAEZ,KAAA,YAAY,QAAQ,GACpB,KAAA,YAAY,QAAQ,GAEpB,KAAA,YAAY,QACZ,EAAA,MAAM,QAAQ,KAAK,WAAY,EAAY,EAAA,eAAe,aAE1D,KAAA,YAAY,QACZ,EAAA,MAAM,QAAQ,KAAK,WAAY,EAAY,EAAA,eAAe,aAE1D,KAAA,YAAY,QACZ,EAAA,MAAM,QAAQ,KAAK,WAAY,EAAY,EAAA,eAAe,aAEzD,MAAA,EAAqC,EAAA,MAAM,QAC/C,KAAK,WACL,EACA,EAAA,eAAe,YAEZ,KAAA,YAAY,QAAQ,GAEpB,KAAA,MAAM,QACN,EAAA,MAAM,KAAK,EAAY,EAAuB,EAAA,WAAW,OAEzD,KAAA,MAAM,QACN,EAAA,MAAM,KAAK,EAAY,EAAuB,EAAA,WAAW,SAEzD,KAAA,MAAM,QACN,EAAA,MAAM,KAAK,EAAW,EAAsB,EAAA,WAAW,QAGvD,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,aAC9B,KAAA,MAAM,QAAQ,GACd,KAAA,MAAM,QAAQ,GACd,KAAA,MAAM,QAAQ,GACd,KAAA,MAAM,QAAQ,GACd,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,cAE9B,KAAA,YAAY,QACf,IAAO,IAAA,EAAE,OAAA,EAAK,OAA2B,QAArB,EAAG,EAAQ,kBAAU,IAAA,EAAA,EAAI,EAAA,OAS1C,0BACE,OAAA,EAQF,mCACE,OAAA,EAAA,eAAe,YAvG1B,QAAA,UAAA;;ACFA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,iBAAA,EATA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,iCACA,EAAA,QAAA,2BACA,EAAA,QAAA,cACA,EAAA,QAAA,YAKA,MAAa,UAAoB,EAAA,MAC/B,YACE,EACA,EASI,IAZR,IAAA,EAcU,MAAA,GAED,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,WAAW,IAAI,IAAI,EAAA,KAAK,EAAA,SAAS,SAGpC,IAAA,EAAoB,MAAM,KAAK,KAAK,YAClC,MAAA,EAAgB,GACjB,IAAA,IAAI,EAAI,EAAG,GAAuB,QAAnB,EAAC,EAAQ,kBAAU,IAAA,EAAA,EAAI,GAAI,IAAK,CAC5C,MAAA,EAAgB,GACjB,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IAAK,CAC7B,MAAA,EAAa,IAAI,EAAA,KAAK,EAAA,SAAS,QACrC,EAAK,OAAS,EAAA,UACd,EAAK,KAAO,EACZ,EAAM,KAAK,GAGR,KAAA,YAAY,QACZ,EAAA,MAAM,QAAQ,EAAW,EAAO,EAAA,eAAe,aAEpD,EAAM,QAAQ,GACd,EAAY,EAGT,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,aAC9B,KAAA,MAAM,QAAQ,EAAM,WACzB,EAAU,QAAQ,GAAQ,KAAK,YAAY,IAAI,IAE1C,KAAA,YAAY,QACf,IAAO,IAAA,EAAE,OAAA,EAAK,OAA2B,QAArB,EAAG,EAAQ,kBAAU,IAAA,EAAA,EAAI,EAAA,WAS1C,0BACE,OAAA,EAQF,mCACE,OAAA,EAAA,eAAe,YA9D1B,QAAA,YAAA;;ACAA,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,cAAA,EATA,MAAA,EAAA,QAAA,yBACA,EAAA,QAAA,iCACA,EAAA,QAAA,2BACA,EAAA,QAAA,cACA,EAAA,QAAA,YAKA,MAAa,UAAiB,EAAA,MAC5B,YACE,EACA,EAKI,IARR,IAAA,EAUU,MAAA,GAED,IAAA,IAAI,EAAI,EAAG,EAAI,EAAY,IACzB,KAAA,WAAW,IACd,IAAI,EAAA,KAAK,EAAA,SAAS,QAAQ,kBACN,QADuB,EACzC,EAAQ,kBAAU,IAAA,EAAA,EAAI,EAAA,WAKvB,KAAA,YAAc,KAAK,WACnB,KAAA,MAAM,QAAQ,MAAM,KAAK,KAAK,aAG9B,KAAA,YAAY,QACZ,EAAA,MAAM,QAAQ,KAAK,MAAO,KAAK,MAAO,EAAA,eAAe,aASrD,0BACE,OAAA,EAQF,mCACE,OAAA,EAAA,eAAe,YA5C1B,QAAA,SAAA;;ACwJoD,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,YAAA,QAAA,gBAAA,QAAA,SAAA,QAAA,UAAA,QAAA,UAAA,EA1JpD,MAAe,EAUb,YAAY,GACL,KAAA,SAAW,GA+IZ,QAAA,KAAA,EA9HR,MAAM,UAAkB,EAMf,OACE,OAAA,KAAK,UAuHF,QAAA,UAAA,EA9Gd,MAAM,UAAiB,EAiBrB,YAAY,EAAkB,EAAQ,GAAK,EAAW,KAC9C,MAAA,GACD,KAAA,MAAQ,EACR,KAAA,SAAW,EASX,KAAK,GACH,OAAA,KAAK,SAAW,KAAA,IAAA,KAAK,MAAS,KAAK,MAAM,EAAY,KAAK,YAgF5C,QAAA,SAAA,EArEzB,MAAM,UAAwB,EAY5B,YAAY,EAAkB,EAAQ,MAC9B,MAAA,GACD,KAAA,MAAQ,EASR,KAAK,GACH,OAAA,KAAK,SAAW,KAAA,IAAA,KAAK,MAAS,IA6CN,QAAA,gBAAA,EAlCnC,MAAM,UAAoB,EAiBxB,YAAY,EAAkB,EAAQ,KAAO,EAAQ,GAC7C,MAAA,GACD,KAAA,MAAQ,EACR,KAAA,MAAQ,EASR,KAAK,GACH,OAAA,KAAK,SAAW,KAAA,IAAC,EAAI,KAAK,MAAQ,GAAe,KAAK,QAIb,QAAA,YAAA;;AC3JpD,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,kBAAA,EANA,MAAA,EAAA,QAAA,mBACA,EAAA,QAAA,mBAKA,MAAa,EACX,YACE,GAWK,KAAA,SAAW,EACX,KAAA,aAAe,EACf,KAAA,QAAU,EACV,KAAA,MAAQ,EAAA,QACR,KAAA,SAAW,EACX,KAAA,UAAY,EACZ,KAAA,WAAa,KAAK,QAAQ,OAC1B,KAAA,MAAQ,IAAI,EAAA,UAAU,IACtB,KAAA,MAAQ,EACR,KAAA,wBAA0B,EAC1B,KAAA,UAAW,EACX,KAAA,QAAS,EAoBL,cAUF,OAAA,KAAK,SAMH,YACT,GAWK,KAAA,SAAW,EAWP,cACF,OAAA,KAAK,SAMH,YAAQ,GACZ,KAAA,SAAW,EAWP,YACF,OAAA,KAAK,OAMH,UAAM,GACV,KAAA,OAAS,EAuBL,eAeF,OAAA,KAAK,UAMH,aACT,GAgBK,KAAA,UAAY,EAWR,4BACF,OAAA,KAAK,uBAMH,0BAAsB,GAC1B,KAAA,uBAAyB,EAWrB,WACF,OAAA,KAAK,MAMH,SAAK,GACT,KAAA,MAAQ,EAWJ,WACF,OAAA,KAAK,MAMH,SAAK,GACT,KAAA,MAAQ,EAWJ,iBACF,OAAA,KAAK,YAMH,eAAW,GACf,KAAA,YAAc,EAWV,YACF,OAAA,KAAK,OAMH,UAAM,GACV,KAAA,OAAS,EAWL,eACF,OAAA,KAAK,UAMH,aAAS,GACb,KAAA,UAAY,EAWR,cACF,OAAA,KAAK,SAMH,YAAQ,GACZ,KAAA,SAAW,EAWP,UACF,OAAA,KAAK,KAMH,QAAI,GACR,KAAA,KAAO,EAWH,gBACF,OAAA,KAAK,WAMH,cAAU,GACd,KAAA,WAAa,GAtVtB,QAAA,aAAA;;ACwLE,aAAA,OAAA,eAAA,QAAA,aAAA,CAAA,OAAA,IAAA,QAAA,iBAAA,QAAA,IAAA,QAAA,IAAA,QAAA,IAAA,QAAA,cAAA,QAAA,cAAA,QAAA,IAAA,QAAA,QAAA,QAAA,gBAAA,QAAA,YAAA,QAAA,WAAA,QAAA,QAAA,QAAA,WAAA,QAAA,oBAAA,QAAA,eAAA,QAAA,8BAAA,QAAA,UAAA,QAAA,YAAA,QAAA,gBAAA,QAAA,SAAA,QAAA,UAAA,QAAA,KAAA,QAAA,kBAAA,QAAA,0BAAA,QAAA,0BAAA,QAAA,0BAAA,QAAA,0BAAA,QAAA,gBAAA,QAAA,gBAAA,QAAA,sBAAA,QAAA,gBAAA,QAAA,kBAAA,QAAA,sBAAA,QAAA,sBAAA,QAAA,gBAAA,QAAA,gBAAA,QAAA,SAAA,QAAA,eAAA,QAAA,uBAAA,QAAA,sBAAA,QAAA,cAAA,QAAA,UAAA,QAAA,SAAA,QAAA,SAAA,QAAA,SAAA,QAAA,QAAA,QAAA,WAAA,QAAA,QAAA,QAAA,QAAA,QAAA,WAAA,QAAA,aAAA,QAAA,cAAA,QAAA,cAAA,QAAA,aAAA,QAAA,SAAA,QAAA,WAAA,QAAA,eAAA,QAAA,KAAA,QAAA,QAAA,QAAA,QAAA,QAAA,WAAA,QAAA,UAAA,QAAA,SAAA,QAAA,UAAA,QAAA,YAAA,QAAA,aAAA,QAAA,MAAA,QAAA,YAAA,QAAA,UAAA,QAAA,SAAA,QAAA,SAAA,QAAA,cAAA,QAAA,gBAAA,QAAA,aAAA,QAAA,wBAAA,QAAA,wBAAA,QAAA,wBAAA,QAAA,kBAAA,QAAA,kBAAA,QAAA,kBAAA,QAAA,WAAA,QAAA,YAAA,QAAA,WAAA,QAAA,aAAA,QAAA,gBAAA,EA9LF,MAAA,EAAA,QAAA,iCA8HE,OAAA,eAAA,QAAA,YAAA,CAAA,YAAA,EAAA,IAAA,WA9HM,OAAA,EAAA,aACR,MAAA,EAAA,QAAA,kCA8HE,OAAA,eAAA,QAAA,aAAA,CAAA,YAAA,EAAA,IAAA,WA9HM,OAAA,EAAA,cACR,MAAA,EAAA,QAAA,yDAiHE,OAAA,eAAA,QAAA,kBAAA,CAAA,YAAA,EAAA,IAAA,WAjHM,OAAA,EAAA,mBACR,MAAA,EAAA,QAAA,oDAoGE,OAAA,eAAA,QAAA,aAAA,CAAA,YAAA,EAAA,IAAA,WApGM,OAAA,EAAA,cACR,MAAA,EAAA,QAAA,sDAoGE,OAAA,eAAA,QAAA,eAAA,CAAA,YAAA,EAAA,IAAA,WApGM,OAAA,EAAA,gBACR,MAAA,EAAA,QAAA,oDAoGE,OAAA,eAAA,QAAA,aAAA,CAAA,YAAA,EAAA,IAAA,WApGM,OAAA,EAAA,cACR,MAAA,EAAA,QAAA,qDAoGE,OAAA,eAAA,QAAA,cAAA,CAAA,YAAA,EAAA,IAAA,WApGM,OAAA,EAAA,eACR,MAAA,EAAA,QAAA,oCAkHE,OAAA,eAAA,QAAA,QAAA,CAAA,YAAA,EAAA,IAAA,WAlHM,OAAA,EAAA,SACR,MAAA,EAAA,QAAA,qDAmGE,OAAA,eAAA,QAAA,aAAA,CAAA,YAAA,EAAA,IAAA,WAnGM,OAAA,EAAA,cACR,MAAA,EAAA,QAAA,8DAmGE,OAAA,eAAA,QAAA,oBAAA,CAAA,YAAA,EAAA,IAAA,WAnGM,OAAA,EAAA,qBACR,MAAA,EAAA,QAAA,oEAqGE,OAAA,eAAA,QAAA,0BAAA,CAAA,YAAA,EAAA,IAAA,WArGM,OAAA,EAAA,2BACR,MAAA,EAAA,QAAA,oEAsGE,OAAA,eAAA,QAAA,0BAAA,CAAA,YAAA,EAAA,IAAA,WAtGM,OAAA,EAAA,2BACR,MAAA,EAAA,QAAA,oEAoGE,OAAA,eAAA,QAAA,0BAAA,CAAA,YAAA,EAAA,IAAA,WApGM,OAAA,EAAA,2BACR,MAAA,EAAA,QAAA,8DAiGE,OAAA,eAAA,QAAA,oBAAA,CAAA,YAAA,EAAA,IAAA,WAjGM,OAAA,EAAA,qBACR,MAAA,EAAA,QAAA,8DA+FE,OAAA,eAAA,QAAA,oBAAA,CAAA,YAAA,EAAA,IAAA,WA/FM,OAAA,EAAA,qBACR,MAAA,EAAA,QAAA,yDAmGE,OAAA,eAAA,QAAA,eAAA,CAAA,YAAA,EAAA,IAAA,WAnGM,OAAA,EAAA,gBACR,MAAA,EAAA,QAAA,uDAsGE,OAAA,eAAA,QAAA,WAAA,CAAA,YAAA,EAAA,IAAA,WAtGM,OAAA,EAAA,YACR,MAAA,EAAA,QAAA,4DAmGE,OAAA,eAAA,QAAA,gBAAA,CAAA,YAAA,EAAA,IAAA,WAnGM,OAAA,EAAA,iBACR,MAAA,EAAA,QAAA,wDAqGE,OAAA,eAAA,QAAA,YAAA,CAAA,YAAA,EAAA,IAAA,WArGM,OAAA,EAAA,aACR,MAAA,EAAA,QAAA,0DAqGE,OAAA,eAAA,QAAA,cAAA,CAAA,YAAA,EAAA,IAAA,WArGM,OAAA,EAAA,eACR,MAAA,EAAA,QAAA,uDAiGE,OAAA,eAAA,QAAA,WAAA,CAAA,YAAA,EAAA,IAAA,WAjGM,OAAA,EAAA,YACR,MAAA,EAAA,QAAA,+BA2GE,OAAA,eAAA,QAAA,UAAA,CAAA,YAAA,EAAA,IAAA,WA3GM,OAAA,EAAA,WACR,MAAA,EAAA,QAAA,4BA4GE,OAAA,eAAA,QAAA,OAAA,CAAA,YAAA,EAAA,IAAA,WA5GM,OAAA,EAAA,QACR,MAAA,EAAA,QAAA,0CAmGE,OAAA,eAAA,QAAA,eAAA,CAAA,YAAA,EAAA,IAAA,WAnGM,OAAA,EAAA,gBACR,MAAA,EAAA,QAAA,yCAmGE,OAAA,eAAA,QAAA,cAAA,CAAA,YAAA,EAAA,IAAA,WAnGM,OAAA,EAAA,eACR,MAAA,EAAA,QAAA,uCAmGE,OAAA,eAAA,QAAA,YAAA,CAAA,YAAA,EAAA,IAAA,WAnGM,OAAA,EAAA,aACR,MAAA,EAAA,QAAA,sCAmGE,OAAA,eAAA,QAAA,WAAA,CAAA,YAAA,EAAA,IAAA,WAnGM,OAAA,EAAA,YACR,MAAA,EAAA,QAAA,+BAsGE,OAAA,eAAA,QAAA,UAAA,CAAA,YAAA,EAAA,IAAA,WAtGM,OAAA,EAAA,WACR,MAAA,EAAA,QAAA,+BAuGE,OAAA,eAAA,QAAA,iBAAA,CAAA,YAAA,EAAA,IAAA,WAvGM,OAAA,EAAA,kBACR,MAAA,EAAA,QAAA,2BAuGE,OAAA,eAAA,QAAA,aAAA,CAAA,YAAA,EAAA,IAAA,WAvGM,OAAA,EAAA,cACR,MAAA,EAAA,QAAA,yBAuGE,OAAA,eAAA,QAAA,WAAA,CAAA,YAAA,EAAA,IAAA,WAvGM,OAAA,EAAA,YAyGN,OAAA,eAAA,QAAA,gBAAA,CAAA,YAAA,EAAA,IAAA,WAzGgB,OAAA,EAAA,iBAwGhB,OAAA,eAAA,QAAA,eAAA,CAAA,YAAA,EAAA,IAAA,WAxG+B,OAAA,EAAA,gBAEjC,MAAA,EAAA,QAAA,mCAyGE,OAAA,eAAA,QAAA,gBAAA,CAAA,YAAA,EAAA,IAAA,WAzGM,OAAA,EAAA,iBAOR,MAAA,EAAA,QAAA,kCAuGE,OAAA,eAAA,QAAA,eAAA,CAAA,YAAA,EAAA,IAAA,WAvGM,OAAA,EAAA,gBACR,MAAA,EAAA,QAAA,uBAuGE,OAAA,eAAA,QAAA,aAAA,CAAA,YAAA,EAAA,IAAA,WAtGA,OAAA,EAAA,cAyGA,OAAA,eAAA,QAAA,aAAA,CAAA,YAAA,EAAA,IAAA,WAxGA,OAAA,EAAA,cA6GA,OAAA,eAAA,QAAA,YAAA,CAAA,YAAA,EAAA,IAAA,WA5GA,OAAA,EAAA,aAwGA,OAAA,eAAA,QAAA,UAAA,CAAA,YAAA,EAAA,IAAA,WAvGA,OAAA,EAAA,WAwGA,OAAA,eAAA,QAAA,WAAA,CAAA,YAAA,EAAA,IAAA,WAvGA,OAAA,EAAA,YAoGA,OAAA,eAAA,QAAA,UAAA,CAAA,YAAA,EAAA,IAAA,WAnGA,OAAA,EAAA,WAkGA,OAAA,eAAA,QAAA,UAAA,CAAA,YAAA,EAAA,IAAA,WAjGA,OAAA,EAAA,WAuGA,OAAA,eAAA,QAAA,WAAA,CAAA,YAAA,EAAA,IAAA,WAtGA,OAAA,EAAA,YAqGA,OAAA,eAAA,QAAA,WAAA,CAAA,YAAA,EAAA,IAAA,WApGA,OAAA,EAAA,YAEF,MAAA,EAAA,QAAA,2BAqHE,OAAA,eAAA,QAAA,4BAAA,CAAA,YAAA,EAAA,IAAA,WApHA,OAAA,EAAA,6BA2GA,OAAA,eAAA,QAAA,wBAAA,CAAA,YAAA,EAAA,IAAA,WA1GA,OAAA,EAAA,yBA+GA,OAAA,eAAA,QAAA,kBAAA,CAAA,YAAA,EAAA,IAAA,WA9GA,OAAA,EAAA,mBAuGA,OAAA,eAAA,QAAA,kBAAA,CAAA,YAAA,EAAA,IAAA,WAtGA,OAAA,EAAA,mBA+GA,OAAA,eAAA,QAAA,4BAAA,CAAA,YAAA,EAAA,IAAA,WA9GA,OAAA,EAAA,6BAgGA,OAAA,eAAA,QAAA,gBAAA,CAAA,YAAA,EAAA,IAAA,WA/FA,OAAA,EAAA,iBAgGA,OAAA,eAAA,QAAA,wBAAA,CAAA,YAAA,EAAA,IAAA,WA/FA,OAAA,EAAA,yBAyGA,OAAA,eAAA,QAAA,wBAAA,CAAA,YAAA,EAAA,IAAA,WAxGA,OAAA,EAAA,yBAuGA,OAAA,eAAA,QAAA,kBAAA,CAAA,YAAA,EAAA,IAAA,WAtGA,OAAA,EAAA,mBAqGA,OAAA,eAAA,QAAA,oBAAA,CAAA,YAAA,EAAA,IAAA,WApGA,OAAA,EAAA,qBA+FA,OAAA,eAAA,QAAA,WAAA,CAAA,YAAA,EAAA,IAAA,WA9FA,OAAA,EAAA,YA4FA,OAAA,eAAA,QAAA,yBAAA,CAAA,YAAA,EAAA,IAAA,WA3FA,OAAA,EAAA,0BA4FA,OAAA,eAAA,QAAA,iBAAA,CAAA,YAAA,EAAA,IAAA,WA3FA,OAAA,EAAA,kBAyGA,OAAA,eAAA,QAAA,4BAAA,CAAA,YAAA,EAAA,IAAA,WAxGA,OAAA,EAAA,6BA+FA,OAAA,eAAA,QAAA,wBAAA,CAAA,YAAA,EAAA,IAAA,WA9FA,OAAA,EAAA,yBAmGA,OAAA,eAAA,QAAA,kBAAA,CAAA,YAAA,EAAA,IAAA,WAlGA,OAAA,EAAA,mBA2FA,OAAA,eAAA,QAAA,kBAAA,CAAA,YAAA,EAAA,IAAA,WA1FA,OAAA,EAAA,mBAmGA,OAAA,eAAA,QAAA,4BAAA,CAAA,YAAA,EAAA,IAAA,WAlGA,OAAA,EAAA,6BAqGA,OAAA,eAAA,QAAA,oBAAA,CAAA,YAAA,EAAA,IAAA,WApGA,OAAA,EAAA,qBAEF,MAAA,EAAA,QAAA,uBAsGE,OAAA,eAAA,QAAA,kBAAA,CAAA,YAAA,EAAA,IAAA,WArGA,OAAA,EAAA,mBAmGA,OAAA,eAAA,QAAA,YAAA,CAAA,YAAA,EAAA,IAAA,WAlGA,OAAA,EAAA,aAqGA,OAAA,eAAA,QAAA,cAAA,CAAA,YAAA,EAAA,IAAA,WApGA,OAAA,EAAA,eAgGA,OAAA,eAAA,QAAA,OAAA,CAAA,YAAA,EAAA,IAAA,WA/FA,OAAA,EAAA,QAiGA,OAAA,eAAA,QAAA,WAAA,CAAA,YAAA,EAAA,IAAA,WAhGA,OAAA,EAAA,YAEF,MAAA,EAAA,QAAA,4BAkGE,OAAA,eAAA,QAAA,gCAAA,CAAA,YAAA,EAAA,IAAA,WAjGA,OAAA,EAAA,iCAkGA,OAAA,eAAA,QAAA,iBAAA,CAAA,YAAA,EAAA,IAAA,WAjGA,OAAA,EAAA,kBA+FA,OAAA,eAAA,QAAA,YAAA,CAAA,YAAA,EAAA,IAAA,WA9FA,OAAA,EAAA,aAiGA,OAAA,eAAA,QAAA,sBAAA,CAAA,YAAA,EAAA,IAAA,WAhGA,OAAA,EAAA,uBAEF,MAAA,EAAA,QAAA,sBA0GE,OAAA,eAAA,QAAA,MAAA,CAAA,YAAA,EAAA,IAAA,WAzGA,OAAA,EAAA,OA0GA,OAAA,eAAA,QAAA,mBAAA,CAAA,YAAA,EAAA,IAAA,WAzGA,OAAA,EAAA,oBAmGA,OAAA,eAAA,QAAA,MAAA,CAAA,YAAA,EAAA,IAAA,WAlGA,OAAA,EAAA,OAmGA,OAAA,eAAA,QAAA,gBAAA,CAAA,YAAA,EAAA,IAAA,WAlGA,OAAA,EAAA,iBAoGA,OAAA,eAAA,QAAA,MAAA,CAAA,YAAA,EAAA,IAAA,WAnGA,OAAA,EAAA,OAkGA,OAAA,eAAA,QAAA,gBAAA,CAAA,YAAA,EAAA,IAAA,WAjGA,OAAA,EAAA,iBAyFA,OAAA,eAAA,QAAA,aAAA,CAAA,YAAA,EAAA,IAAA,WAxFA,OAAA,EAAA,cA2FA,OAAA,eAAA,QAAA,cAAA,CAAA,YAAA,EAAA,IAAA,WA1FA,OAAA,EAAA,eAyFA,OAAA,eAAA,QAAA,aAAA,CAAA,YAAA,EAAA,IAAA,WAxFA,OAAA,EAAA,cAuFA,OAAA,eAAA,QAAA,UAAA,CAAA,YAAA,EAAA,IAAA,WAtFA,OAAA,EAAA,WAyFA,OAAA,eAAA,QAAA,kBAAA,CAAA,YAAA,EAAA,IAAA,WAxFA,OAAA,EAAA,mBAyFA,OAAA,eAAA,QAAA,UAAA,CAAA,YAAA,EAAA,IAAA,WAxFA,OAAA,EAAA,WA6FA,OAAA,eAAA,QAAA,MAAA,CAAA,YAAA,EAAA,IAAA,WA5FA,OAAA,EAAA","file":"index.min.js","sourceRoot":"..\\build\\scripts","sourcesContent":["/**\n * The type of a connection.\n */\nexport enum ConnectionType {\n  /**\n   * No connection used for exceptions.\n   */\n  NO_CONNECTION,\n  /**\n   * Connect all input to all output nodes\n   */\n  ALL_TO_ALL,\n  /**\n   * Connect one input to one output node\n   */\n  ONE_TO_ONE,\n  /**\n   * Connect with pooling\n   */\n  POOLING,\n}\n","/**\n * The type of node.\n */\nexport enum NodeType {\n  /**\n   * Node is an input node.\n   */\n  INPUT,\n  /**\n   * Node is a hidden node.\n   */\n  HIDDEN,\n  /**\n   * Node is a output node.\n   */\n  OUTPUT,\n}\n\n/**\n * The type of pool node.\n */\nexport enum PoolNodeType {\n  /**\n   * Maximum pooling node.\n   */\n  MAX_POOLING,\n  /**\n   * Average pooling node.\n   */\n  AVG_POOLING,\n  /**\n   * Minimum pooling node.\n   */\n  MIN_POOLING,\n}\n\n/**\n * The type of noise node.\n */\nexport enum NoiseNodeType {\n  /**\n   * Gaussian noise node\n   */\n  GAUSSIAN_NOISE,\n}\n","/**\n * Returns an random element from the given array.\n *\n * @param arr the array to pick from\n * @returns the random picked element\n */\nfunction pickRandom<T>(arr: T[] | Set<T>): T {\n  if (Array.isArray(arr)) {\n    if (arr.length === 0) {\n      throw new RangeError('Cannot pick from an empty array');\n    }\n    return arr[randInt(0, arr.length)];\n  } else {\n    return pickRandom(Array.from(arr));\n  }\n}\n\n/**\n * Returns a random integer in the range [min,max)\n *\n * @param min bound\n * @param max bound\n * @returns random integer in [min,max)\n */\nfunction randInt(min: number, max: number): number {\n  return Math.floor(Math.random() * (max - min) + min);\n}\n\n/**\n * Returns a random double in the range [min,max)\n *\n * @param min bound\n * @param max bound\n * @returns random double in [min,max)\n */\nfunction randDouble(min: number, max: number): number {\n  return Math.random() * (max - min) + min;\n}\n\n/**\n * Returns a random boolean\n *\n * @returns random boolean\n */\nfunction randBoolean(): boolean {\n  return Math.random() >= 0.5;\n}\n\n/**\n * Removes an element from an array.\n *\n * @param arr the array\n * @param elem the element which will be removed\n * @returns false -> element does not exists on array; true -> element removed from array\n */\nfunction removeFromArray<T>(arr: T[], elem: T): boolean {\n  const index: number = arr.indexOf(elem);\n  if (index === -1) {\n    return false;\n  } else {\n    arr.splice(index, 1);\n    return true;\n  }\n}\n\n/**\n * Shuffles an array\n * @param array the array\n * @returns the shuffled array\n */\nfunction shuffle<T>(array: T[]): void {\n  // While there are elements in the array\n  for (let counter: number = array.length - 1; counter > 0; counter--) {\n    // Pick a random index\n    const index: number = randInt(0, counter);\n\n    // And swap the last element with it\n    const temp: T = array[counter];\n    array[counter] = array[index];\n    array[index] = temp;\n  }\n}\n\n/**\n * Finds the maximum value of an number array\n *\n * @param array\n */\nfunction max(array: number[]): number {\n  if (array.length === 0) {\n    throw new RangeError();\n  }\n  let maxValue: number = array[0];\n  for (let i = 1; i < array.length; i++) {\n    if (array[i] > maxValue) {\n      maxValue = array[i];\n    }\n  }\n  return maxValue;\n}\n\n/**\n * Finds the maximum value index of an number array\n *\n * @param array\n */\nfunction maxValueIndex(array: number[]): number {\n  if (array.length === 0) {\n    throw new RangeError();\n  }\n  let maxValue: number = array[0];\n  let maxValueIndex = 0;\n  for (let i = 1; i < array.length; i++) {\n    if (array[i] > maxValue) {\n      maxValue = array[i];\n      maxValueIndex = i;\n    }\n  }\n  return maxValueIndex;\n}\n\n/**\n * Finds the minimum value index of an number array\n *\n * @param array\n */\nfunction minValueIndex(array: number[]): number {\n  if (array.length === 0) {\n    throw new RangeError();\n  }\n  let minValue: number = array[0];\n  let minValueIndex = 0;\n  for (let i = 1; i < array.length; i++) {\n    if (array[i] < minValue) {\n      minValue = array[i];\n      minValueIndex = i;\n    }\n  }\n  return minValueIndex;\n}\n\n/**\n * Finds the minimum value of an number array\n *\n * @param array\n */\nfunction min(array: number[]): number {\n  if (array.length === 0) {\n    throw new RangeError();\n  }\n  let minValue: number = array[0];\n  for (let i = 1; i < array.length; i++) {\n    if (array[i] < minValue) {\n      minValue = array[i];\n    }\n  }\n  return minValue;\n}\n\n/**\n * Calculates the average value of an array\n *\n * @param array\n */\nfunction avg(array: number[]): number {\n  return sum(array) / array.length;\n}\n\n/**\n * Calculates the sum of all values of an array\n *\n * @param array\n */\nfunction sum(array: number[]): number {\n  if (array.length === 0) {\n    throw new RangeError();\n  }\n  let sum = 0;\n  for (const value of array) {\n    sum += value;\n  }\n  return sum;\n}\n\n/**\n * Generates a random number with the gaussian distribution.\n *\n * @see https://en.wikipedia.org/wiki/Normal_distribution\n *\n * @param mean the mean value\n * @param deviation the standard deviation\n */\nfunction generateGaussian(mean = 0, deviation = 2): number {\n  let sum = 0;\n  const numSamples = 10;\n  for (let i = 0; i < numSamples; i++) {\n    sum += Math.random();\n  }\n\n  return (deviation * sum) / numSamples + mean - 0.5 * deviation;\n}\n\n/**\n * Pairing two numbers\n *\n * @see {@link https://en.wikipedia.org/wiki/Pairing_function (Cantor pairing function)|Pairing function (Cantor pairing function)}\n *\n * @param a - A [natural number](https://en.wikipedia.org/wiki/Natural_number), which is an integer greater than or equal to zero\n * @param b - A [natural number](https://en.wikipedia.org/wiki/Natural_number), which is an integer greater than or equal to zero\n *\n * @return An Integer that uniquely represents a pair of Integers\n */\nfunction pairing(a: number, b: number): number {\n  return (1 / 2) * (a + b) * (a + b + 1) + b;\n}\n\nexport {\n  pickRandom,\n  randInt,\n  randDouble,\n  randBoolean,\n  removeFromArray,\n  shuffle,\n  max,\n  maxValueIndex,\n  minValueIndex,\n  min,\n  sum,\n  avg,\n  generateGaussian,\n  pairing,\n};\n","import {ActivationType} from 'activations/build/src';\nimport {Connection} from '../architecture/Connection';\nimport {Network} from '../architecture/Network';\nimport {Node} from '../architecture/Node';\nimport {NodeType} from '../enums/NodeType';\nimport {pickRandom, randBoolean, randDouble} from '../utils/Utils';\n\n/**\n *\n * Genetic algorithm mutation methods. Creates variations (mutations) in neural networks which are then selected for better performance.\n *\n * @see {@link https://en.wikipedia.org/wiki/mutation_(genetic_algorithm)|Mutation (genetic algorithms) on Wikipedia}\n * @see {@link https://en.wikipedia.org/wiki/Genetic_algorithm#Selection|Selection (genetic algorithms) on Wikipedia}\n */\nabstract class Mutation {\n  /**\n   * Mutates a given network.\n   *\n   * @param network the network to mutate\n   * @param options you can set the max amount of nodes, connections and gates\n   */\n  public abstract mutate(\n    network: Network,\n    options?: {\n      /**\n       * Maximum allowed nodes.\n       */\n      maxNodes?: number;\n      /**\n       * Maximum allowed connections.\n       */\n      maxConnections?: number;\n      /**\n       * Maximum allowed gates.\n       */\n      maxGates?: number;\n      /**\n       * All allowed activations.\n       */\n      allowedActivations?: ActivationType[];\n    }\n  ): void;\n}\n\n/**\n * Add node mutation.\n *\n * Adds a hidden node to the network.\n */\nclass AddNodeMutation extends Mutation {\n  /**\n   * If enabled, sets a random activation function on the newly created node\n   */\n  public readonly randomActivation: boolean;\n\n  /**\n   * Constructs a AddNodeMutation object\n   * @param randomActivation Should choose a random activation for a new node?\n   */\n  constructor(randomActivation = true) {\n    super();\n    this.randomActivation = randomActivation;\n  }\n\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   * @param options\n   */\n  public mutate(\n    network: Network,\n    options: {\n      /**\n       * Maximum amount of nodes.\n       */\n      maxNodes?: number;\n    } = {}\n  ): void {\n    // check if max nodes is already reached\n    if (\n      options.maxNodes !== undefined &&\n      network.nodes.length >= options.maxNodes\n    ) {\n      return;\n    }\n    // create a new hidden node\n    const node: Node = new Node(NodeType.HIDDEN);\n    if (this.randomActivation) {\n      node.mutateActivation(); // choose random activation\n    }\n    // take a random connection\n    const connection: Connection = pickRandom(Array.from(network.connections));\n    const from: Node = connection.from;\n    const to: Node = connection.to;\n    network.disconnect(from, to); // disconnect it\n\n    // put the node in between the connection\n    const minBound: number = Math.max(\n      network.inputSize,\n      1 + network.nodes.indexOf(from)\n    );\n    network.nodes.splice(minBound, 0, node);\n    const newConnection1: Connection = network.connect(from, node, 1);\n    const newConnection2: Connection = network.connect(\n      node,\n      to,\n      connection.weight\n    );\n\n    if (connection.gateNode !== null) {\n      // if connection had a gate node\n      // choose randomly which new connection should get this gate node\n      if (randBoolean()) {\n        network.addGate(connection.gateNode, newConnection1);\n      } else {\n        network.addGate(connection.gateNode, newConnection2);\n      }\n    }\n  }\n}\n\n/**\n * Sub node mutation.\n *\n * Removes a random node from the network.\n */\nclass SubNodeMutation extends Mutation {\n  /**\n   * Ensures replacement node has gated connections if the removed node did.\n   */\n  public readonly keepGates: boolean;\n\n  constructor(keepGates = true) {\n    super();\n    this.keepGates = keepGates;\n  }\n\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   */\n  public mutate(network: Network): void {\n    const possible: Node[] = network.nodes.filter(\n      node => node !== undefined && node.isHiddenNode()\n    ); // hidden nodes\n    if (possible.length > 0) {\n      network.removeNode(pickRandom(possible), this.keepGates); // remove a random node from the filtered array\n    }\n  }\n}\n\n/**\n * Add connections mutation.\n *\n * Adds a connection to the network.\n */\nclass AddConnectionMutation extends Mutation {\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   * @param options\n   */\n  public mutate(\n    network: Network,\n    options: {\n      /**\n       * Maximum allowed connections.\n       */\n      maxConnections?: number;\n    } = {}\n  ): void {\n    // check if max connections is already reached\n    if (\n      options.maxConnections !== undefined &&\n      network.connections.size >= options.maxConnections\n    ) {\n      return;\n    }\n    const possible: Node[][] = [];\n\n    for (let i = 0; i < network.nodes.length - network.outputSize; i++) {\n      const from: Node = network.nodes[i];\n      for (\n        let j: number = Math.max(i + 1, network.inputSize);\n        j < network.nodes.length;\n        j++\n      ) {\n        const to: Node = network.nodes[j];\n        if (!from.isProjectingTo(to)) {\n          possible.push([from, to]);\n        }\n      }\n    }\n\n    if (possible.length > 0) {\n      const pair: Node[] = pickRandom(possible);\n      network.connect(pair[0], pair[1]);\n    }\n  }\n}\n\n/**\n * Sub connection mutation.\n *\n * Removes a random connection from the network.\n */\nclass SubConnectionMutation extends Mutation {\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   */\n  public mutate(network: Network): void {\n    const possible: Connection[] = Array.from(network.connections)\n      .filter(conn => conn.from.outgoing.size > 1) // do not deactivate a neuron\n      .filter(conn => conn.to.incoming.size > 1) // do not deactivate a neuron\n      .filter(\n        conn =>\n          network.nodes.indexOf(conn.to) > network.nodes.indexOf(conn.from)\n      ); // look for forward pointing connections\n    if (possible.length > 0) {\n      const randomConnection: Connection = pickRandom(possible); // pick a random connection from the filtered array\n      network.disconnect(randomConnection.from, randomConnection.to); // remove the connection from the network\n    }\n  }\n}\n\n/**\n * Mod weight mutation.\n *\n * Modifies the weight of a random connection.\n */\nclass ModWeightMutation extends Mutation {\n  /**\n   * lower bound for weight modification\n   */\n  public readonly min: number;\n  /**\n   * higher bound for weight modification\n   */\n  public readonly max: number;\n\n  /**\n   * Constructs a ModWeightMutation object\n   * @param min The minimum weight.\n   * @param max The maximum weight.\n   */\n  constructor(min = -1, max = 1) {\n    super();\n    this.min = min;\n    this.max = max;\n  }\n\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   */\n  public mutate(network: Network): void {\n    // pick random connection and mutate it's weight\n    pickRandom(Array.from(network.connections)).weight += randDouble(\n      this.min,\n      this.max\n    );\n  }\n}\n\n/**\n * Mod bias mutation.\n *\n * Modifies the bias value of a random hidden or output node\n */\nclass ModBiasMutation extends Mutation {\n  /**\n   * lower bound for modification of a neuron's bias\n   */\n  public readonly min: number;\n  /**\n   * higher bound for modification of a neuron's bias\n   */\n  public readonly max: number;\n\n  /**\n   * Constructs a ModBiasMutation object\n   * @param min The minimum bias.\n   * @param max The maximum bias.\n   */\n  constructor(min = -1, max = 1) {\n    super();\n    this.min = min;\n    this.max = max;\n  }\n\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   */\n  public mutate(network: Network): void {\n    pickRandom(network.nodes.filter(node => !node.isInputNode())) // pick random hidden or output node\n      .mutateBias(this); // mutate it's bias\n  }\n}\n\n/**\n * Mod activation mutation.\n *\n * Modifies the activation function of a random node\n */\nclass ModActivationMutation extends Mutation {\n  /**\n   * Change activation function of network output neurons. Enable this to let the network experiment with its output.\n   */\n  public readonly mutateOutput: boolean;\n\n  /**\n   * Constructs a ModActivationMutation object\n   * @param mutateOutput Can the output be mutated?\n   */\n  constructor(mutateOutput = false) {\n    super();\n    this.mutateOutput = mutateOutput;\n  }\n\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   * @param options\n   */\n  public mutate(\n    network: Network,\n    options: {\n      /**\n       * All allowed activations.\n       */\n      allowedActivations?: ActivationType[];\n    } = {}\n  ): void {\n    const possible: Node[] = this.mutateOutput\n      ? network.nodes.filter(node => !node.isInputNode()) // hidden and output nodes\n      : network.nodes.filter(node => node.isHiddenNode()); // hidden nodes\n    if (possible.length > 0) {\n      pickRandom(possible).mutateActivation(options.allowedActivations); // mutate the activation of the node\n    }\n  }\n}\n\n/**\n * Add self connection.\n *\n * Adds a connection from a node to itself.\n */\nclass AddSelfConnectionMutation extends Mutation {\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   */\n  public mutate(network: Network): void {\n    const possible: Node[] = network.nodes\n      .filter(node => !node.isInputNode()) // no input nodes\n      .filter(node => node.selfConnection.weight === 0); // only nodes that doesn't have an self connection already\n    if (possible.length > 0) {\n      const node: Node = pickRandom(possible); // pick a random node from the filtered array\n      network.connect(node, node); // connection the node to itself\n    }\n  }\n}\n\n/**\n * Sub self connection.\n *\n * Removes a connection from a node to itself.\n */\nclass SubSelfConnectionMutation extends Mutation {\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   */\n  public mutate(network: Network): void {\n    const possible: Connection[] = Array.from(network.connections).filter(\n      conn => conn.from === conn.to\n    );\n    if (possible.length > 0) {\n      const randomConnection: Connection = pickRandom(possible);\n      network.disconnect(randomConnection.from, randomConnection.to);\n    }\n  }\n}\n\n/**\n * Add gate mutation.\n *\n * Adds a gate to the network.\n */\nclass AddGateMutation extends Mutation {\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   * @param options\n   */\n  public mutate(\n    network: Network,\n    options: {\n      /**\n       * Maximum allowed gates.\n       */\n      maxGates?: number;\n    } = {}\n  ): void {\n    // check if max gates isn't reached already\n    if (\n      options.maxGates !== undefined &&\n      network.gates.size >= options.maxGates\n    ) {\n      return;\n    }\n\n    // use only connections that aren't already gated\n    const possible: Connection[] = Array.from(network.connections).filter(\n      conn => conn.gateNode === null\n    );\n    if (possible.length > 0) {\n      const node: Node = pickRandom(\n        network.nodes.filter(node => !node.isInputNode())\n      ); // hidden or output node\n      const connection: Connection = pickRandom(possible); // random connection from filtered array\n\n      network.addGate(node, connection); // use the node to gate the connection\n    }\n  }\n}\n\n/**\n * Sub gate mutation.\n *\n * Removes a gate from the network.\n */\nclass SubGateMutation extends Mutation {\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   */\n  public mutate(network: Network): void {\n    if (network.gates.size > 0) {\n      network.removeGate(pickRandom(Array.from(network.gates)));\n    }\n  }\n}\n\n/**\n * Add back connection mutation.\n *\n * Adds a backward pointing connection to the network.\n */\nclass AddBackConnectionMutation extends Mutation {\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   */\n  public mutate(network: Network): void {\n    const possible: Node[][] = [];\n    for (let i: number = network.inputSize; i < network.nodes.length; i++) {\n      const from: Node = network.nodes[i];\n      for (let j: number = network.inputSize; j < i; j++) {\n        const to: Node = network.nodes[j];\n        if (!from.isProjectingTo(to)) {\n          possible.push([from, to]);\n        }\n      }\n    }\n    if (possible.length > 0) {\n      const pair: Node[] = pickRandom(possible);\n      network.connect(pair[0], pair[1]);\n    }\n  }\n}\n\n/**\n * Sub back connection mutation.\n *\n * Removes a backward pointing connection to the network.\n */\nclass SubBackConnectionMutation extends Mutation {\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   */\n  public mutate(network: Network): void {\n    const possible: Connection[] = Array.from(network.connections)\n      .filter(conn => conn.from.outgoing.size > 1)\n      .filter(conn => conn.to.incoming.size > 1)\n      .filter(\n        conn =>\n          network.nodes.indexOf(conn.from) > network.nodes.indexOf(conn.to)\n      );\n    if (possible.length > 0) {\n      const randomConnection: Connection = pickRandom(possible);\n      network.disconnect(randomConnection.from, randomConnection.to);\n    }\n  }\n}\n\n/**\n * Swap nodes mutation.\n *\n * Swaps the values of two randomly picked nodes.\n */\nclass SwapNodesMutation extends Mutation {\n  /**\n   * Swap bias and activation function of network output neurons too. Disable this to keep output of a neural network normalized.\n   */\n  public readonly mutateOutput: boolean;\n\n  /**\n   * Constructs a SwapNodeMutation object\n   * @param mutateOutput Can the output be mutated?\n   */\n  constructor(mutateOutput = false) {\n    super();\n    this.mutateOutput = mutateOutput;\n  }\n\n  /**\n   * Mutates the network.\n   *\n   * @param network The network which gets mutated\n   */\n  public mutate(network: Network): void {\n    const possible: Node[] = this.mutateOutput\n      ? network.nodes.filter(node => node !== undefined && !node.isInputNode()) // hidden or output nodes\n      : network.nodes.filter(node => node !== undefined && node.isHiddenNode()); // only hidden nodes\n\n    if (possible.length >= 2) {\n      // select two different nodes from the filtered array\n      const node1: Node = pickRandom(possible);\n      const node2: Node = pickRandom(possible.filter(node => node !== node1));\n\n      // change there parameters\n      const biasTemp: number = node1.bias;\n      const squashTemp: ActivationType = node1.squash;\n\n      node1.bias = node2.bias;\n      node1.squash = node2.squash;\n      node2.bias = biasTemp;\n      node2.squash = squashTemp;\n    }\n  }\n}\n\n/**\n * Array of all mutation methods\n */\nconst ALL_MUTATIONS: Mutation[] = [\n  new AddNodeMutation(),\n  new SubNodeMutation(),\n  new AddConnectionMutation(),\n  new SubConnectionMutation(),\n  new ModWeightMutation(),\n  new ModBiasMutation(),\n  new ModActivationMutation(),\n  new AddGateMutation(),\n  new SubGateMutation(),\n  new AddSelfConnectionMutation(),\n  new SubSelfConnectionMutation(),\n  new AddBackConnectionMutation(),\n  new SubBackConnectionMutation(),\n  new SwapNodesMutation(),\n];\n/**\n * Array of all feed forward mutation methods\n */\nconst FEEDFORWARD_MUTATIONS: Mutation[] = [\n  new AddNodeMutation(),\n  new SubNodeMutation(),\n  new AddConnectionMutation(),\n  new SubConnectionMutation(),\n  new ModWeightMutation(),\n  new ModBiasMutation(),\n  new ModActivationMutation(),\n  new SwapNodesMutation(),\n];\n\nconst NO_STRUCTURE_MUTATIONS: Mutation[] = [\n  new ModWeightMutation(),\n  new ModBiasMutation(),\n  new ModActivationMutation(),\n];\nconst ONLY_STRUCTURE: Mutation[] = [\n  new AddNodeMutation(),\n  new SubNodeMutation(),\n  new AddConnectionMutation(),\n  new SubConnectionMutation(),\n  new AddGateMutation(),\n  new SubGateMutation(),\n  new AddSelfConnectionMutation(),\n  new SubSelfConnectionMutation(),\n  new AddBackConnectionMutation(),\n  new SubBackConnectionMutation(),\n  new SwapNodesMutation(),\n];\n\nexport {\n  ALL_MUTATIONS,\n  FEEDFORWARD_MUTATIONS,\n  NO_STRUCTURE_MUTATIONS,\n  ONLY_STRUCTURE,\n  Mutation,\n  AddNodeMutation,\n  SubNodeMutation,\n  AddConnectionMutation,\n  SubConnectionMutation,\n  ModWeightMutation,\n  ModBiasMutation,\n  ModActivationMutation,\n  AddGateMutation,\n  SubGateMutation,\n  AddSelfConnectionMutation,\n  SubSelfConnectionMutation,\n  AddBackConnectionMutation,\n  SubBackConnectionMutation,\n  SwapNodesMutation,\n};\n","import {ConnectionJSON} from '../interfaces/ConnectionJSON';\nimport {pairing} from '../utils/Utils';\nimport {Node} from './Node';\n\n/**\n * A connection instance describes the connection between two nodes.\n */\nexport class Connection {\n  /**\n   * eligibility\n   */\n  public eligibility: number;\n  /**\n   * Used for gating, gets multiplied with weight\n   */\n  public gain: number;\n  /**\n   * Weight of the connection\n   */\n  public weight: number;\n  /**\n   * Connection origin node (neuron)\n   */\n  public readonly from: Node;\n  /**\n   * Connection destination node (neuron)\n   */\n  public readonly to: Node;\n\n  /**\n   * X Trace\n   */\n  public xTrace: Map<Node, number>;\n\n  /**\n   * The node gating this connection\n   */\n  public gateNode: Node | null;\n  /**\n   * Tracks [momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html) - _for [batch training](https://www.quora.com/What-is-the-difference-between-batch-online-and-mini-batch-training-in-neural-networks-Which-one-should-I-use-for-a-small-to-medium-sized-dataset-for-prediction-purposes)_\n   */\n  public deltaWeightsTotal: number;\n  /**\n   * Tracks [momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html)\n   */\n  public deltaWeightsPrevious: number;\n\n  constructor(from: Node, to: Node, weight?: number, gateNode?: Node) {\n    this.from = from;\n    this.to = to;\n    this.weight = weight ?? 0;\n    this.gain = 1;\n    this.eligibility = 0;\n    this.deltaWeightsPrevious = 0;\n    this.deltaWeightsTotal = 0;\n    this.xTrace = new Map<Node, number>();\n\n    if (gateNode) {\n      this.gateNode = gateNode;\n      gateNode.addGate(this);\n    } else {\n      this.gateNode = null;\n    }\n  }\n\n  /**\n   * Returns the connection as a JSON\n   *\n   * @return Connection as a JSON\n   */\n  public toJSON(): ConnectionJSON {\n    return {\n      fromIndex: this.from.index,\n      toIndex: this.to.index,\n      gateNodeIndex: this.gateNode === null ? null : this.gateNode.index,\n      weight: this.weight,\n    };\n  }\n\n  /**\n   * Get the innovation ID for this connection\n   */\n  public getInnovationID(): number {\n    return pairing(this.from.index, this.to.index);\n  }\n}\n","import {ActivationType, ALL_ACTIVATIONS, Logistic} from 'activations/build/src';\nimport {NodeType} from '../enums/NodeType';\nimport {NodeJSON} from '../interfaces/NodeJSON';\nimport {ModBiasMutation} from '../methods/Mutation';\nimport {pickRandom, randDouble} from '../utils/Utils';\nimport {Connection} from './Connection';\n\n/**\n * Creates a new neuron/node\n *\n * Neurons are the basic unit of the neural network. They can be connected together, or used to gate connections between other neurons. A Neuron can perform basically 4 operations: form connections, gate connections, activate and [propagate](https://www.youtube.com/watch?v=Ilg3gGewQ5U).\n *\n * For more information check:\n * - [BecomingHuman](https://becominghuman.ai/what-is-an-artificial-neuron-8b2e421ce42e)\n * - [Wikipedia](https://en.wikipedia.org/wiki/Artificial_neuron)\n * - [Neataptic](https://wagenaartje.github.io/neataptic/docs/architecture/node/)\n * - [Synaptic](https://github.com/cazala/synaptic/wiki/Neural-Networks-101)\n * - [Keras](https://keras.io/backend/#bias_add)\n */\nexport class Node {\n  /**\n   * The type of this node.\n   */\n  public type: NodeType;\n  /**\n   * Used for dropout. This is either 0 (ignored) or 1 (included) during training and is used to avoid [overfit](https://www.kdnuggets.com/2015/04/preventing-overfitting-neural-networks.html).\n   */\n  public mask: number;\n  /**\n   * Incoming connections to this node\n   */\n  public incoming: Set<Connection>;\n  /**\n   * Outgoing connections from this node\n   */\n  public outgoing: Set<Connection>;\n  /**\n   * Connections this node gates\n   */\n  public gated: Set<Connection>;\n  /**\n   * A self connection\n   */\n  public selfConnection: Connection;\n  /**\n   * Neuron's bias [here](https://becominghuman.ai/what-is-an-artificial-neuron-8b2e421ce42e)\n   */\n  public bias: number;\n  /**\n   * [Activation function](https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0)\n   */\n  public squash: ActivationType;\n  /**\n   * index\n   */\n  public index: number;\n  /**\n   * derivative state\n   */\n  public derivativeState: number;\n  /**\n   * delta bias previous\n   */\n  public deltaBiasPrevious: number;\n  /**\n   * delta bias total\n   */\n  public deltaBiasTotal: number;\n  /**\n   * Output value\n   */\n  public activation: number;\n  /**\n   * state\n   */\n  public state: number;\n  /**\n   * old state\n   */\n  public old: number;\n  /**\n   * error responsibility\n   */\n  public errorResponsibility: number;\n  /**\n   * error projected\n   */\n  public errorProjected: number;\n  /**\n   * error gated\n   */\n  public errorGated: number;\n\n  constructor(type: NodeType = NodeType.HIDDEN) {\n    this.type = type;\n    this.bias = randDouble(-1, 1);\n    this.squash = Logistic;\n    this.activation = 0;\n    this.derivativeState = 1;\n    this.state = 0;\n    this.old = 0;\n    this.mask = 1;\n    this.deltaBiasPrevious = 0;\n    this.deltaBiasTotal = 0;\n    this.incoming = new Set<Connection>();\n    this.outgoing = new Set<Connection>();\n    this.gated = new Set<Connection>();\n    this.selfConnection = new Connection(this, this, 0);\n    this.errorResponsibility = 0;\n    this.errorProjected = 0;\n    this.errorGated = 0;\n    this.index = NaN;\n  }\n\n  /**\n   * Convert a json object to a node\n   *\n   * @param json A node represented as a JSON object\n   *\n   * @returns itself\n   */\n  public fromJSON(json: NodeJSON): Node {\n    this.bias = json.bias ?? randDouble(-1, 1);\n    this.type = json.type as NodeType;\n    this.squash = json.squash ?? Logistic;\n    this.mask = json.mask ?? 1;\n    this.index = json.index ?? NaN;\n    return this;\n  }\n\n  /**\n   * Clears this node's state information - _i.e. resets node and its connections to \"factory settings\"_\n   *\n   * `node.clear()` is useful for predicting time series.\n   */\n  public clear(): void {\n    this.incoming.forEach(connection => {\n      connection.eligibility = 0;\n      connection.xTrace.clear();\n    });\n\n    this.gated.forEach(conn => (conn.gain = 0));\n\n    this.errorResponsibility = this.errorProjected = this.errorGated = 0;\n    this.old = this.state = this.activation = 0;\n  }\n\n  /**\n   * Mutates the node's bias\n   *\n   * @param method The method is needed for the min and max value of the node's bias otherwise a range of [-1,1] is chosen\n   */\n  public mutateBias(method: ModBiasMutation = new ModBiasMutation()): void {\n    this.bias += randDouble(method.min, method.max); // add a random value in range [min,max)\n  }\n\n  /**\n   * Mutates the node's activation function\n   */\n  public mutateActivation(\n    allowedActivations: ActivationType[] = Object.values(ALL_ACTIVATIONS)\n  ): void {\n    // pick a random activation from allowed activations except the current activation\n    const possible: ActivationType[] = allowedActivations.filter(\n      activation => activation !== this.squash\n    );\n    if (possible.length > 0) {\n      this.squash = pickRandom(possible);\n    }\n  }\n\n  /**\n   * Checks if the given node(s) are have outgoing connections to this node\n   *\n   * @param node Checks if `node(s)` have outgoing connections into this node\n   *\n   * @return Returns true, if every node(s) has an outgoing connection into this node\n   */\n  public isProjectedBy(node: Node): boolean {\n    if (node === this) {\n      // self connection\n      return this.selfConnection.weight !== 0; // is projected, if weight of self connection is unequal 0\n    } else {\n      return Array.from(this.incoming)\n        .map(conn => conn.from)\n        .includes(node); // check every incoming connection for node\n    }\n  }\n\n  /**\n   * Checks if this node has an outgoing connection(s) into the given node(s)\n   *\n   * @param node Checks if this node has outgoing connection(s) into `node(s)`\n   *\n   * @returns Returns true, if this node has an outgoing connection into every node(s)\n   */\n  public isProjectingTo(node: Node): boolean {\n    if (node === this) {\n      // self connection\n      return this.selfConnection.weight !== 0; // is projected, if weight of self connection is unequal 0\n    } else {\n      return Array.from(this.outgoing)\n        .map(conn => conn.to)\n        .includes(node); // check every outgoing connection for node\n    }\n  }\n\n  /**\n   * This node gates (influences) the given connection\n   *\n   * @param connection Connection to be gated (influenced) by a neuron\n   */\n  public addGate(connection: Connection): void {\n    this.gated.add(connection);\n    connection.gateNode = this;\n  }\n\n  /**\n   * Stops this node from gating (manipulating) the given connection(s)\n   *\n   * @param connection Connections to remove gate - _i.e. remove this node from_\n   */\n  public removeGate(connection: Connection): void {\n    this.gated.delete(connection);\n    connection.gateNode = null;\n    connection.gain = 1;\n  }\n\n  /**\n   * Connects this node to the given node(s)\n   *\n   * @param target Node(s) to project connection(s) to\n   * @param weight Initial connection(s) [weight](https://en.wikipedia.org/wiki/Synaptic_weight)\n   * @param twoSided If `true` connect nodes to each other\n   */\n  public connect(target: Node, weight = 1, twoSided = false): Connection {\n    if (target === this) {\n      // self connection\n      this.selfConnection.weight = weight;\n      return this.selfConnection;\n    } else if (this.isProjectingTo(target)) {\n      throw new ReferenceError('There is already a connection!'); // already connected\n    } else {\n      const connection: Connection = new Connection(this, target, weight); // create new connection\n\n      // add it to the arrays\n      this.outgoing.add(connection);\n      target.incoming.add(connection);\n\n      if (twoSided) {\n        target.connect(this); // connect in the other direction\n      }\n      return connection;\n    }\n  }\n\n  /**\n   * Disconnects this node from the given node(s)\n   *\n   * @param node Node(s) to remove connection(s) to\n   * @param twoSided=false If `true` disconnects nodes from each other (i.e. both sides)\n   */\n  public disconnect(node: Node, twoSided = false): Connection {\n    if (node === this) {\n      // self connection\n      this.selfConnection.weight = 0; // set weight to 0\n      return this.selfConnection;\n    }\n\n    const connections: Connection[] = Array.from(this.outgoing).filter(\n      conn => conn.to === node\n    );\n\n    if (connections.length === 0) {\n      throw new Error('No Connection found');\n    }\n    const connection: Connection = connections[0];\n\n    // remove it from the arrays\n    this.outgoing.delete(connection);\n    connection.to.incoming.delete(connection);\n\n    if (connection.gateNode !== undefined && connection.gateNode !== null) {\n      connection.gateNode.removeGate(connection); // if connection is gated -> remove gate\n    }\n    if (twoSided) {\n      node.disconnect(this); // disconnect the other direction\n    }\n\n    return connection;\n  }\n\n  /**\n   * Backpropagate the error (a.k.a. learn).\n   *\n   * After an activation, you can teach the node what should have been the correct output (a.k.a. train). This is done by backpropagating. [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html) adds a fraction of the previous weight update to the current one. When the gradient keeps pointing in the same direction, this will increase the size of the steps taken towards the minimum.\n   *\n   * If you combine a high learning rate with a lot of momentum, you will rush past the minimum (of the error function) with huge steps. It is therefore often necessary to reduce the global learning rate µ when using a lot of momentum (m close to 1).\n   *\n   * @param target The target value (i.e. \"the value the network SHOULD have given\")\n   * @param options More options for propagation\n   *\n   * @see [Regularization Neataptic](https://wagenaartje.github.io/neataptic/docs/methods/regularization/)\n   * @see [What is backpropagation | YouTube](https://www.youtube.com/watch?v=Ilg3gGewQ5U)\n   */\n  public propagate(\n    target?: number,\n    options: {\n      /**\n       * [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html) adds a fraction of the previous weight update to the current one.\n       */\n      momentum?: number;\n      /**\n       * [Learning rate](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10)\n       */\n      rate?: number;\n      /**\n       * When set to false weights won't update, but when set to true after being false the last propagation will include the delta weights of the first \"update:false\" propagations too.\n       */\n      update?: boolean;\n    } = {}\n  ): void {\n    options.momentum = options.momentum ?? 0;\n    options.rate = options.rate ?? 0.3;\n    options.update = options.update ?? true;\n\n    if (target !== undefined && Number.isFinite(target)) {\n      this.errorResponsibility = this.errorProjected = target - this.activation;\n    } else {\n      this.errorProjected = 0;\n      this.outgoing.forEach(connection => {\n        this.errorProjected +=\n          connection.to.errorResponsibility *\n          connection.weight *\n          connection.gain;\n      });\n      this.errorProjected *= this.derivativeState;\n\n      this.errorGated = 0;\n      this.gated.forEach(connection => {\n        let influence: number;\n        if (connection.to.selfConnection.gateNode === this) {\n          // self connection is gated with this node\n          influence =\n            connection.to.old + connection.weight * connection.from.activation;\n        } else {\n          influence = connection.weight * connection.from.activation;\n        }\n\n        this.errorGated += connection.to.errorResponsibility * influence;\n      });\n      this.errorGated *= this.derivativeState;\n\n      this.errorResponsibility = this.errorProjected + this.errorGated;\n    }\n\n    this.incoming.forEach(connection => {\n      // calculate gradient\n      let gradient: number = this.errorProjected * connection.eligibility;\n      connection.xTrace.forEach(\n        (value, key) => (gradient += key.errorResponsibility * value)\n      );\n\n      connection.deltaWeightsTotal +=\n        (options.rate ?? 0.3) * gradient * this.mask;\n      if (options.update) {\n        connection.deltaWeightsTotal +=\n          (options.momentum ?? 0) * connection.deltaWeightsPrevious;\n        connection.weight += connection.deltaWeightsTotal;\n        connection.deltaWeightsPrevious = connection.deltaWeightsTotal;\n        connection.deltaWeightsTotal = 0;\n      }\n    });\n\n    this.deltaBiasTotal += options.rate * this.errorResponsibility;\n    if (options.update) {\n      this.deltaBiasTotal += options.momentum * this.deltaBiasPrevious;\n      this.bias += this.deltaBiasTotal;\n      this.deltaBiasPrevious = this.deltaBiasTotal;\n      this.deltaBiasTotal = 0;\n    }\n  }\n\n  /**\n   * Actives the node.\n   *\n   * When a neuron activates, it computes its state from all its input connections and 'squashes' it using its activation function, and returns the output (activation).\n   *\n   * You can also provide the activation (a float between 0 and 1) as a parameter, which is useful for neurons in the input layer.\n   *\n   * @param [input] Environment signal (i.e. optional numerical value passed to the network as input)  - _should only be passed in input neurons_\n   * @param [trace] Controls whether traces are created when activation happens (a trace is meta information left behind for different uses, e.g. backpropagation).\n   *\n   * @returns A neuron's ['Squashed'](https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0) output value\n   */\n  public activate(input?: number, trace = true): number {\n    if (input !== undefined) {\n      return (this.activation = input);\n    } else if (this.isInputNode()) {\n      throw new ReferenceError('There is no input given to an input node!');\n    }\n\n    if (trace) {\n      this.old = this.state;\n\n      this.state =\n        this.selfConnection.gain * this.selfConnection.weight * this.state +\n        this.bias;\n\n      this.incoming.forEach(conn => {\n        this.state += conn.from.activation * conn.weight * conn.gain;\n      });\n\n      this.activation = this.squash(this.state, false) * this.mask;\n      this.derivativeState = this.squash(this.state, true);\n\n      // store traces\n      const nodes: Node[] = [];\n      const influences: number[] = [];\n\n      // Adjust 'gain' (to gated connections) & Build traces\n      this.gated.forEach(connection => {\n        connection.gain = this.activation;\n\n        // Build traces\n        const index: number = nodes.indexOf(connection.to);\n        if (index > -1) {\n          // Node & influence exist\n          influences[index] += connection.weight * connection.from.activation;\n        } else {\n          // Add node & corresponding influence\n          nodes.push(connection.to);\n          if (connection.to.selfConnection.gateNode === this) {\n            influences.push(\n              connection.weight * connection.from.activation + connection.to.old\n            );\n          } else {\n            influences.push(connection.weight * connection.from.activation);\n          }\n        }\n      });\n\n      // Forwarding 'xTrace' (to incoming connections)\n      this.incoming.forEach(connection => {\n        connection.eligibility =\n          this.selfConnection.gain *\n            this.selfConnection.weight *\n            connection.eligibility +\n          connection.from.activation * connection.gain;\n\n        for (let i = 0; i < nodes.length; i++) {\n          const node: Node = nodes[i];\n          const influence: number = influences[i];\n\n          if (connection.xTrace.has(node)) {\n            connection.xTrace.set(\n              node,\n              node.selfConnection.gain *\n                node.selfConnection.weight *\n                (connection.xTrace.get(node) ?? 0) +\n                this.derivativeState * connection.eligibility * influence\n            );\n          } else {\n            connection.xTrace.set(\n              node,\n              this.derivativeState * connection.eligibility * influence\n            );\n          }\n        }\n      });\n\n      return this.activation;\n    } else {\n      if (this.isInputNode()) return (this.activation = 0);\n\n      this.state =\n        this.selfConnection.gain * this.selfConnection.weight * this.state +\n        this.bias;\n\n      this.incoming.forEach(\n        connection =>\n          (this.state +=\n            connection.from.activation * connection.weight * connection.gain)\n      );\n\n      this.activation = this.squash(this.state, false);\n\n      // Adjust gain\n      this.gated.forEach(connection => (connection.gain = this.activation));\n\n      return this.activation;\n    }\n  }\n\n  /**\n   * Converts the node to a json object that can later be converted back\n   *\n   * @returns A node representing json object\n   */\n  public toJSON(): NodeJSON {\n    return {\n      bias: this.bias,\n      type: this.type,\n      squash: this.squash,\n      mask: this.mask,\n      index: this.index,\n    };\n  }\n\n  /**\n   * Is this a input Node?\n   */\n  public isInputNode(): boolean {\n    return this.type === NodeType.INPUT;\n  }\n\n  /**\n   * Is this a hidden Node?\n   */\n  public isHiddenNode(): boolean {\n    return this.type === NodeType.HIDDEN;\n  }\n\n  /**\n   * Is this a output Node?\n   */\n  public isOutputNode(): boolean {\n    return this.type === NodeType.OUTPUT;\n  }\n\n  /**\n   * Set bias.\n   *\n   * @param bias the new bias value\n   */\n  public setBias(bias: number): Node {\n    this.bias = bias;\n    return this;\n  }\n\n  /**\n   * Set activation type\n   *\n   * @param activation the new activation type\n   */\n  public setActivationType(activation: ActivationType): Node {\n    this.squash = activation;\n    return this;\n  }\n}\n","/**\n * The type of gating.\n */\nexport enum GatingType {\n  /**\n   * Gate incoming connections.\n   */\n  INPUT,\n  /**\n   * Gate self connections.\n   */\n  SELF,\n  /**\n   * Gate outgoing connections.\n   */\n  OUTPUT,\n}\n","import {ConnectionType} from '../../enums/ConnectionType';\nimport {GatingType} from '../../enums/GatingType';\nimport {Connection} from '../Connection';\nimport {Node} from '../Node';\n\n/**\n * Parent class for layers.\n */\nexport abstract class Layer {\n  /**\n   * The output size of the layer.\n   */\n  public readonly outputSize: number;\n  /**\n   * The nodes which gets connected to the previous layer.\n   */\n  public readonly inputNodes: Set<Node>;\n  /**\n   * The nodes which gets connected to the next layer.\n   */\n  public outputNodes: Set<Node>;\n  /**\n   * All nodes in this layer.\n   */\n  public readonly nodes: Node[];\n  /**\n   * All connections in this layer.\n   */\n  public readonly connections: Connection[];\n  /**\n   * All gates in this layer.\n   */\n  public readonly gates: Connection[];\n\n  protected constructor(outputSize: number) {\n    this.outputSize = outputSize;\n    this.nodes = [];\n    this.inputNodes = new Set<Node>();\n    this.outputNodes = new Set<Node>();\n    this.connections = [];\n    this.gates = [];\n  }\n\n  /**\n   * Connect two Layers or sets of Nodes.\n   *\n   * @param from origin Nodes / Layer\n   * @param to destination Nodes / Layer\n   * @param connectionType The type of connection\n   * @param weight the initial weights for all new connections\n   *\n   * @returns all created connections\n   */\n  public static connect(\n    from: Layer | Set<Node> | Node[],\n    to: Layer | Set<Node> | Node[],\n    connectionType: ConnectionType = ConnectionType.ALL_TO_ALL,\n    weight = 1\n  ): Connection[] {\n    if (connectionType === ConnectionType.NO_CONNECTION) {\n      throw new ReferenceError(\n        \"Cannot connect with 'NO_CONNECTION' connection type\"\n      );\n    }\n\n    const fromNodes: Node[] = Array.from(\n      from instanceof Layer ? from.outputNodes : from\n    );\n    const toNodes: Node[] = Array.from(\n      to instanceof Layer ? to.inputNodes : to\n    );\n\n    if (toNodes.length === 0) {\n      throw new ReferenceError('Target from has no input nodes!');\n    }\n    if (fromNodes.length === 0) {\n      throw new ReferenceError('This from has no output nodes!');\n    }\n\n    const connections: Connection[] = [];\n    if (connectionType === ConnectionType.ALL_TO_ALL) {\n      fromNodes.forEach(fromNode => {\n        toNodes.forEach(toNode => {\n          connections.push(fromNode.connect(toNode, weight)); // connect every \"from node\" to every \"to node\"\n        });\n      });\n    } else if (connectionType === ConnectionType.ONE_TO_ONE) {\n      if (fromNodes.length !== toNodes.length) {\n        throw new RangeError(\n          \"Can't connect one to one! Number of output nodes from are unequal number of incoming nodes from next layer!\"\n        );\n      }\n      for (let i = 0; i < fromNodes.length; i++) {\n        connections.push(fromNodes[i].connect(toNodes[i], weight)); // connect every nodes with same indices\n      }\n    } else if (connectionType === ConnectionType.POOLING) {\n      // connect the same amount of input nodes to every output node\n      // every input node has only one connection available\n      const ratio: number = toNodes.length / fromNodes.length;\n      connections.push(\n        ...fromNodes.map((node, index) =>\n          node.connect(toNodes[Math.floor(index * ratio)], weight)\n        )\n      );\n    }\n    return connections;\n  }\n\n  /**\n   * Gate nodes and connections.\n   *\n   * @param nodes the nodes which function as gateNodes\n   * @param connections the connections which will be gated\n   * @param gateType The type of gating\n   *\n   * @returns all gated connections\n   */\n  public static gate(\n    nodes: Node[],\n    connections: Connection[],\n    gateType: GatingType\n  ): Connection[] {\n    const gatedConnections: Connection[] = [];\n    switch (gateType) {\n      case GatingType.INPUT: {\n        // gate incoming connections\n        const toNodes: Node[] = Array.from(\n          new Set(connections.map(conn => conn.to))\n        );\n\n        for (let i = 0; i < toNodes.length; i++) {\n          const node: Node = toNodes[i];\n          const gateNode: Node = nodes[i % nodes.length];\n\n          node.incoming.forEach(conn => {\n            if (connections.includes(conn)) {\n              gateNode.addGate(conn);\n              gatedConnections.push(conn);\n            }\n          });\n        }\n        break;\n      }\n      case GatingType.SELF: {\n        // gate self connections\n        const fromNodes: Node[] = Array.from(\n          new Set(connections.map(conn => conn.from))\n        );\n\n        for (let i = 0; i < fromNodes.length; i++) {\n          if (connections.includes(fromNodes[i].selfConnection)) {\n            nodes[i % nodes.length].addGate(fromNodes[i].selfConnection);\n            gatedConnections.push(fromNodes[i].selfConnection);\n          }\n        }\n        break;\n      }\n      case GatingType.OUTPUT: {\n        // gate outgoing connections\n        const fromNodes: Node[] = Array.from(\n          new Set(connections.map(conn => conn.from))\n        );\n        for (let i = 0; i < fromNodes.length; i++) {\n          const node: Node = fromNodes[i];\n          const gateNode: Node = nodes[i % nodes.length];\n\n          node.outgoing.forEach(conn => {\n            if (connections.includes(conn)) {\n              gateNode.addGate(conn);\n              gatedConnections.push(conn);\n            }\n          });\n        }\n        break;\n      }\n    }\n\n    return gatedConnections;\n  }\n\n  /**\n   * Gets the default connection type for a incoming connection to this layer.\n   *\n   * @returns the default incoming connection\n   */\n  public abstract getDefaultIncomingConnectionType(): ConnectionType;\n\n  /**\n   * Checks if a given connection type is allowed on this layer.\n   *\n   * @param type the type to check\n   *\n   * @return Is this connection type allowed?\n   */\n  public abstract connectionTypeisAllowed(type: ConnectionType): boolean;\n}\n","import {Identitiy} from 'activations/build/src';\nimport {NodeType} from '../../enums/NodeType';\nimport {NodeJSON} from '../../interfaces/NodeJSON';\nimport {Node} from '../Node';\n\n/**\n * Constant node\n */\nexport abstract class ConstantNode extends Node {\n  protected constructor() {\n    super(NodeType.HIDDEN);\n    this.bias = 1;\n  }\n\n  /**\n   * Create a constant node from json object.\n   *\n   * @param json the json object representing the node\n   *\n   * @returns the created node\n   */\n  public fromJSON(json: NodeJSON): Node {\n    this.index = json.index ?? -1;\n    this.squash = json.squash ?? Identitiy;\n    return this;\n  }\n\n  /**\n   * Actives the node.\n   *\n   * When a neuron activates, it computes its state from all its input connections and 'squashes' it using its activation function, and returns the output (activation).\n   *\n   * You can also provide the activation (a float between 0 and 1) as a parameter, which is useful for neurons in the input layer.\n   *\n   * @returns A neuron's output value\n   */\n  public abstract activate(): number;\n\n  /**\n   * Backpropagate the error (a.k.a. learn).\n   *\n   * After an activation, you can teach the node what should have been the correct output (a.k.a. train). This is done by backpropagating. [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html) adds a fraction of the previous weight update to the current one. When the gradient keeps pointing in the same direction, this will increase the size of the steps taken towards the minimum.\n   *\n   * If you combine a high learning rate with a lot of momentum, you will rush past the minimum (of the error function) with huge steps. It is therefore often necessary to reduce the global learning rate µ when using a lot of momentum (m close to 1).\n   *\n   * @param target The target value (i.e. \"the value the network SHOULD have given\")\n   * @param options More options for propagation\n   */\n  public abstract propagate(\n    target?: number,\n    options?: {\n      /**\n       * [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html) adds a fraction of the previous weight update to the current one.\n       */\n      momentum?: number;\n      /**\n       * [Learning rate](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10)\n       */\n      rate?: number;\n      /**\n       * When set to false weights won't update, but when set to true after being false the last propagation will include the delta weights of the first \"update:false\" propagations too.\n       */\n      update?: boolean;\n    }\n  ): void;\n\n  /**\n   * Convert this node into a json object.\n   *\n   * @returns the json object representing this node\n   */\n  public toJSON(): NodeJSON {\n    return {index: this.index, squash: this.squash};\n  }\n\n  /**\n   * Bias mutations aren't allowed for a constant node.\n   */\n  public mutateBias(): void {\n    throw new ReferenceError('Cannot mutate a pool node!');\n  }\n\n  /**\n   * Activation mutations aren't allowed for a constant node.\n   */\n  public mutateActivation(): void {\n    throw new ReferenceError('Cannot mutate a pool node!');\n  }\n\n  /**\n   * Constant nodes can't gate a connection.\n   */\n  public addGate(): void {\n    throw new ReferenceError(\"A pool node can't gate a connection!\");\n  }\n\n  /**\n   * Constant nodes can't gate a connection.\n   */\n  public removeGate(): void {\n    throw new ReferenceError(\"A pool node can't gate a connection!\");\n  }\n\n  /**\n   * Can't set the bias of a constant node.\n   */\n  public setBias(): Node {\n    throw new ReferenceError('Cannot set the bias of a pool node!');\n  }\n}\n","import {NoiseNodeType} from '../../enums/NodeType';\nimport {avg, generateGaussian, sum} from '../../utils/Utils';\nimport {ConstantNode} from './ConstantNode';\n\n/**\n * Noise node\n */\nexport class NoiseNode extends ConstantNode {\n  /**\n   * The type of noise\n   */\n  private readonly noiseType: NoiseNodeType;\n  /**\n   * More options for applying noise\n   */\n  private readonly options: {\n    /**\n     * Options for gaussian noise\n     */\n    gaussian?: {\n      /**\n       * Mean value\n       */\n      mean?: number;\n      /**\n       * Standard deviation\n       */\n      deviation?: number;\n    };\n  };\n\n  constructor(\n    options: {\n      /**\n       * The type of noise\n       */\n      noiseType?: NoiseNodeType;\n      /**\n       * Options for gaussian noise\n       */\n      gaussian?: {\n        /**\n         * Mean value\n         */\n        mean?: number;\n        /**\n         * Standard deviation\n         */\n        deviation?: number;\n      };\n    } = {}\n  ) {\n    super();\n    this.noiseType = options.noiseType ?? NoiseNodeType.GAUSSIAN_NOISE;\n    this.options = options;\n  }\n\n  /**\n   * Actives the node.\n   *\n   * When a neuron activates, it computes its state from all its input connections and 'squashes' it using its activation function, and returns the output (activation).\n   *\n   * You can also provide the activation (a float between 0 and 1) as a parameter, which is useful for neurons in the input layer.\n   *\n   * @returns A neuron's output value\n   */\n  public activate(): number {\n    this.old = this.state;\n\n    const incomingStates: number[] = Array.from(this.incoming).map(\n      conn => conn.from.activation * conn.weight * conn.gain\n    );\n\n    switch (this.noiseType) {\n      case NoiseNodeType.GAUSSIAN_NOISE:\n        this.state =\n          avg(incomingStates) +\n          generateGaussian(\n            this.options.gaussian?.mean ?? 0,\n            this.options.gaussian?.deviation ?? 2\n          );\n        break;\n      default:\n        throw new ReferenceError('Cannot activate this noise type!');\n    }\n\n    this.activation = this.squash(this.state, false) * this.mask;\n    this.derivativeState = this.squash(this.state, true);\n\n    return this.activation;\n  }\n\n  /**\n   * Backpropagate the error (a.k.a. learn).\n   *\n   * After an activation, you can teach the node what should have been the correct output (a.k.a. train). This is done by backpropagating. [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html) adds a fraction of the previous weight update to the current one. When the gradient keeps pointing in the same direction, this will increase the size of the steps taken towards the minimum.\n   *\n   * If you combine a high learning rate with a lot of momentum, you will rush past the minimum (of the error function) with huge steps. It is therefore often necessary to reduce the global learning rate µ when using a lot of momentum (m close to 1).\n   *\n   * @param target The target value (i.e. \"the value the network SHOULD have given\")\n   * @param options More options for propagation\n   */\n  public propagate(\n    target?: number,\n    options: {\n      /**\n       * [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html) adds a fraction of the previous weight update to the current one.\n       */\n      momentum?: number;\n      /**\n       * [Learning rate](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10)\n       */\n      rate?: number;\n      /**\n       * When set to false weights won't update, but when set to true after being false the last propagation will include the delta weights of the first \"update:false\" propagations too.\n       */\n      update?: boolean;\n    } = {}\n  ): void {\n    options.momentum = options.momentum ?? 0;\n    options.rate = options.rate ?? 0.3;\n    options.update = options.update ?? true;\n\n    const connectionsStates: number[] = Array.from(this.outgoing).map(\n      conn => conn.to.errorResponsibility * conn.weight * conn.gain\n    );\n    this.errorResponsibility = this.errorProjected =\n      sum(connectionsStates) * this.derivativeState;\n\n    this.incoming.forEach(connection => {\n      // calculate gradient\n      let gradient: number = this.errorProjected * connection.eligibility;\n      connection.xTrace.forEach((value, key) => {\n        gradient += key.errorResponsibility * value;\n      });\n\n      connection.deltaWeightsTotal +=\n        (options.rate ?? 0.3) * gradient * this.mask;\n      if (options.update) {\n        connection.deltaWeightsTotal +=\n          (options.momentum ?? 0) * connection.deltaWeightsPrevious;\n        connection.weight += connection.deltaWeightsTotal;\n        connection.deltaWeightsPrevious = connection.deltaWeightsTotal;\n        connection.deltaWeightsTotal = 0;\n      }\n    });\n  }\n}\n","import {ActivationType, Identitiy} from 'activations/build/src';\nimport {ConnectionType} from '../../../enums/ConnectionType';\nimport {NoiseNodeType} from '../../../enums/NodeType';\nimport {NoiseNode} from '../../Nodes/NoiseNode';\nimport {Layer} from '../Layer';\n\n/**\n * Noise layer\n */\nexport class NoiseLayer extends Layer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n      /**\n       * The mean value for gaussian noise\n       */\n      mean?: number;\n      /**\n       * The standard deviation for gaussian noise\n       */\n      deviation?: number;\n    } = {}\n  ) {\n    super(outputSize);\n\n    const activation: ActivationType = options.activation ?? Identitiy;\n\n    for (let i = 0; i < outputSize; i++) {\n      this.inputNodes.add(\n        new NoiseNode({\n          noiseType: NoiseNodeType.GAUSSIAN_NOISE,\n          gaussian: options,\n        }).setActivationType(activation)\n      );\n    }\n\n    this.outputNodes = this.inputNodes;\n    this.nodes.push(...Array.from(this.inputNodes));\n  }\n\n  /**\n   * Gets the default connection type for a incoming connection to this layer.\n   *\n   * @returns the default incoming connection\n   */\n  public getDefaultIncomingConnectionType(): ConnectionType {\n    return ConnectionType.ONE_TO_ONE;\n  }\n\n  /**\n   * Checks if a given connection type is allowed on this layer.\n   *\n   * @param type the type to check\n   *\n   * @return Is this connection type allowed?\n   */\n  public connectionTypeisAllowed(type: ConnectionType): boolean {\n    return type === ConnectionType.ONE_TO_ONE;\n  }\n}\n","import {ConnectionType} from '../../../enums/ConnectionType';\nimport {NodeType, NoiseNodeType} from '../../../enums/NodeType';\nimport {Node} from '../../Node';\nimport {Layer} from '../Layer';\nimport {NoiseLayer} from '../NoiseLayers/NoiseLayer';\n\n/**\n * Input layer\n */\nexport class InputLayer extends Layer {\n  public constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The noise type\n       */\n      noise?: NoiseNodeType;\n    } = {}\n  ) {\n    super(outputSize);\n\n    for (let i = 0; i < outputSize; i++) {\n      const node: Node = new Node(NodeType.INPUT);\n      this.nodes.push(node);\n    }\n\n    if (options.noise) {\n      const noiseLayer: NoiseLayer = new NoiseLayer(options.noise);\n      noiseLayer.outputNodes.forEach(node => this.outputNodes.add(node));\n      this.connections.push(\n        ...Layer.connect(\n          this.nodes,\n          noiseLayer,\n          noiseLayer.getDefaultIncomingConnectionType()\n        )\n      );\n    } else {\n      this.nodes.forEach(node => this.outputNodes.add(node));\n    }\n  }\n\n  /**\n   * Gets the default connection type for a incoming connection to this layer.\n   *\n   * @returns the default incoming connection\n   */\n  public getDefaultIncomingConnectionType(): ConnectionType {\n    return ConnectionType.NO_CONNECTION;\n  }\n\n  /**\n   * Checks if a given connection type is allowed on this layer.\n   *\n   * @param type the type to check\n   *\n   * @return Is this connection type allowed?\n   */\n  public connectionTypeisAllowed(type: ConnectionType): boolean {\n    return type === ConnectionType.NO_CONNECTION;\n  }\n}\n","import {ActivationType, Identitiy} from 'activations/build/src';\nimport {ConnectionType} from '../../../enums/ConnectionType';\nimport {NodeType} from '../../../enums/NodeType';\nimport {Node} from '../../Node';\nimport {Layer} from '../Layer';\n\n/**\n * Output layer\n */\nexport class OutputLayer extends Layer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n    } = {}\n  ) {\n    super(outputSize);\n\n    const activation: ActivationType = options.activation ?? Identitiy;\n    for (let i = 0; i < outputSize; i++) {\n      this.inputNodes.add(\n        new Node(NodeType.OUTPUT).setActivationType(activation)\n      );\n    }\n    this.nodes.push(...Array.from(this.inputNodes));\n  }\n\n  /**\n   * A outgoing connection is not allowed for an output layer!\n   */\n  public connect(): void {\n    throw new ReferenceError('Could not connect an OutputLayer!');\n  }\n\n  /**\n   * Checks if a given connection type is allowed on this layer.\n   *\n   * @return Is this connection type allowed?\n   */\n  public connectionTypeisAllowed(): boolean {\n    return true;\n  }\n\n  /**\n   * Gets the default connection type for a incoming connection to this layer.\n   *\n   * @returns the default incoming connection\n   */\n  public getDefaultIncomingConnectionType(): ConnectionType {\n    return ConnectionType.ALL_TO_ALL;\n  }\n}\n","import {sum} from '../utils/Utils';\n\nexport type lossType = (targets: number[], outputs: number[]) => number;\n\nexport const MSELoss: lossType = function (\n  targets: number[],\n  outputs: number[]\n): number {\n  let error = 0;\n  outputs.forEach((value, index) => {\n    error += (targets[index] - value) ** 2;\n  });\n  return error / outputs.length;\n};\nexport const MBELoss: lossType = function (\n  targets: number[],\n  outputs: number[]\n): number {\n  let error = 0;\n  outputs.forEach((value, index) => {\n    error += targets[index] - value;\n  });\n  return error / outputs.length;\n};\nexport const BinaryLoss: lossType = function (\n  targets: number[],\n  outputs: number[]\n): number {\n  let error = 0;\n  outputs.forEach((value, index) => {\n    error += Math.round(targets[index] * 2) !== Math.round(value * 2) ? 1 : 0;\n  });\n  return error / outputs.length;\n};\nexport const MAELoss: lossType = function (\n  targets: number[],\n  outputs: number[]\n): number {\n  let error = 0;\n  outputs.forEach((value, index) => {\n    error += Math.abs(targets[index] - value);\n  });\n  return error / outputs.length;\n};\nexport const MAPELoss: lossType = function (\n  targets: number[],\n  outputs: number[]\n): number {\n  let error = 0;\n  outputs.forEach((value, index) => {\n    error += Math.abs(\n      (value - targets[index]) / Math.max(targets[index], 1e-15)\n    );\n  });\n  return error / outputs.length;\n};\nexport const WAPELoss: lossType = function (\n  targets: number[],\n  outputs: number[]\n): number {\n  let error = 0;\n  outputs.forEach((value, index) => {\n    error += Math.abs(targets[index] - value);\n  });\n  return error / sum(targets);\n};\nexport const MSLELoss: lossType = function (\n  targets: number[],\n  outputs: number[]\n): number {\n  let error = 0;\n  outputs.forEach((value, index) => {\n    error +=\n      Math.log(Math.max(targets[index], 1e-15)) -\n      Math.log(Math.max(value, 1e-15));\n  });\n  return error / outputs.length;\n};\n\nexport const HINGELoss: lossType = function (\n  targets: number[],\n  outputs: number[]\n): number {\n  let error = 0;\n  outputs.forEach((value, index) => {\n    error += Math.max(0, 1 - value * targets[index]);\n  });\n  return error / outputs.length;\n};\n\nexport const ALL_LOSSES: {\n  /**\n   * Mean Squared Error\n   *\n   * @param targets Ideal value\n   * @param outputs Actual values\n   *\n   * @return [Mean squared error](https://medium.freecodecamp.org/machine-learning-mean-squared-error-regression-line-c7dde9a26b93)\n   */\n  MSELoss: lossType;\n  /**\n   * Binary Error\n   *\n   * @param targets Ideal value\n   * @param outputs Actual values\n   *\n   * @return misses The amount of times targets value was missed\n   */\n  BinaryLoss: lossType;\n  /**\n   * Mean Squared Logarithmic Error\n   *\n   * @param targets Ideal value\n   * @param outputs Actual values\n   *\n   * @return - [Mean squared logarithmic error](https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error)\n   */\n  MSLELoss: lossType;\n  /**\n   * Mean Bias Error\n   *\n   * @param targets Ideal value\n   * @param outputs Actual values\n   *\n   * @return [Mean bias error](https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23)\n   */\n  MBELoss: lossType;\n  /**\n   * Weighted Absolute Percentage Error (WAPE)\n   *\n   * @param targets Ideal value\n   * @param outputs Actual values\n   *\n   * @return - [Weighted absolute percentage error](https://help.sap.com/doc/saphelp_nw70/7.0.31/en-US/76/487053bbe77c1ee10000000a174cb4/content.htm?no_cache=true)\n   */\n  WAPELoss: lossType;\n  /**\n   * Hinge loss, for classifiers\n   *\n   * @param targets Ideal value\n   * @param outputs Actual values\n   *\n   * @return - [Hinge loss](https://towardsdatascience.com/support-vector-machines-intuitive-understanding-part-1-3fb049df4ba1)\n   */\n  HINGELoss: lossType;\n  /**\n   * Mean Absolute Error\n   *\n   * @param targets Ideal value\n   * @param outputs Actual values\n   *\n   * @return [Mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error)\n   */\n  MAELoss: lossType;\n  /**\n   * Mean Absolute Percentage Error\n   *\n   * @param targets Ideal value\n   * @param outputs Actual values\n   *\n   * @return [Mean absolute percentage error](https://en.wikipedia.org/wiki/Mean_absolute_percentage_error)\n   */\n  MAPELoss: lossType;\n} = {\n  MSELoss,\n  MBELoss,\n  BinaryLoss,\n  MAELoss,\n  MAPELoss,\n  WAPELoss,\n  MSLELoss,\n  HINGELoss,\n};\n","import * as TimSort from 'timsort';\nimport {Species} from '../architecture/Species';\nimport {pickRandom, randDouble} from '../utils/Utils';\n\n/**\n * Genetic Algorithm Selection Methods (Genetic Operator)\n *\n * @see [Genetic Algorithm - Selection]{@link https://en.wikipedia.org/wiki/Selection_(genetic_algorithm)}\n */\nabstract class Selection {\n  /**\n   * Selects a genome from the population according to the Selection method.\n   *\n   * @param population the pool of networks\n   * @returns the selected genome\n   */\n  public abstract select(population: Species[]): Species;\n}\n\n/**\n * Fitness proportionate selection\n *\n * [Fitness Proportionate / Roulette Wheel Selection on Wikipedia](https://en.wikipedia.org/wiki/Fitness_proportionate_selection)\n */\nclass FitnessProportionateSelection extends Selection {\n  /**\n   * Selects a genome from the population according to the Selection method.\n   *\n   * @param population the pool of networks\n   * @returns the selected genome\n   */\n  public select(population: Species[]): Species {\n    let totalFitness = 0;\n    let minimalFitness = 0;\n    for (const genome of population) {\n      minimalFitness = Math.min(genome.score ?? minimalFitness, minimalFitness);\n      totalFitness += genome.score ?? 0;\n    }\n\n    minimalFitness = Math.abs(minimalFitness);\n    totalFitness += minimalFitness * population.length;\n\n    const random: number = randDouble(0, totalFitness);\n    let value = 0;\n\n    for (const genome of population) {\n      value += (genome.score ?? 0) + minimalFitness;\n      if (random < value) {\n        return genome;\n      }\n    }\n\n    return pickRandom(population);\n  }\n}\n\n/**\n * Power selection\n *\n * A random decimal value between 0 and 1 will be generated (e.g. 0.5) then this value will get an exponential value (power, default is 4). So 0.5**4 = 0.0625. This is converted into an index for the array of the current population, sorted from fittest to worst.\n */\nclass PowerSelection extends Selection {\n  /**\n   * Probability of picking better networks.\n   */\n  public readonly power: number;\n\n  /**\n   * Constructs a power selection.\n   * @param power Probability of picking better networks.\n   */\n  constructor(power = 4) {\n    super();\n    this.power = power;\n  }\n\n  /**\n   * Selects a genome from the population according to the Selection method.\n   *\n   * @param population the pool of networks\n   * @returns the selected genome\n   */\n  public select(population: Species[]): Species {\n    return population[\n      Math.floor(Math.random() ** this.power * population.length)\n    ];\n  }\n}\n\n/**\n * Tournament selection\n *\n * [Tournament Selection on Wikipedia](https://en.wikipedia.org/wiki/Tournament_selection)\n */\nclass TournamentSelection extends Selection {\n  /**\n   * The size of a tournament.\n   */\n  public readonly size: number;\n  /**\n   * The probability of just picking the best network.\n   */\n  public readonly probability: number;\n\n  /**\n   * Constructs a tournament selection.\n   * @param size the size of a tournament\n   * @param probability Selects the best individual (when probability = 1).\n   */\n  constructor(size = 5, probability = 0.5) {\n    super();\n    this.size = size;\n    this.probability = probability;\n  }\n\n  /**\n   * Selects a genome from the population according to the Selection method.\n   *\n   * @param population the pool of networks\n   * @returns the selected genome\n   */\n  public select(population: Species[]): Species {\n    if (this.size > population.length) {\n      throw new Error(\n        'Your tournament size should be lower than the population size, please change methods.selection.TOURNAMENT.size'\n      );\n    }\n\n    // Create a tournament\n    const individuals: Species[] = [];\n    for (let i = 0; i < this.size; i++) {\n      individuals.push(pickRandom(population));\n    }\n\n    // Sort the tournament individuals by score\n    TimSort.sort(individuals, (a: Species, b: Species) => {\n      return b.score === undefined || a.score === undefined\n        ? 0\n        : b.score - a.score;\n    });\n\n    // Select an individual\n    for (let i = 0; i < this.size; i++) {\n      if (Math.random() < this.probability || i === this.size - 1) {\n        return individuals[i];\n      }\n    }\n    return pickRandom(population);\n  }\n}\n\nexport {\n  Selection,\n  FitnessProportionateSelection,\n  PowerSelection,\n  TournamentSelection,\n};\n","import {ActivationType, ALL_ACTIVATIONS} from 'activations/build/src';\nimport os from 'os';\nimport {Network} from '../architecture/Network';\nimport {lossType, MSELoss} from '../methods/Loss';\nimport {FEEDFORWARD_MUTATIONS, Mutation} from '../methods/Mutation';\nimport {FitnessProportionateSelection, Selection} from '../methods/Selection';\nimport {TrainOptions} from './TrainOptions';\n\n/**\n * Options used to evolve network\n */\nexport class EvolveOptions {\n  constructor() {\n    this._input = 1;\n    this._output = 1;\n    this._generation = 0;\n    this._elitism = 1;\n    this._equal = true;\n    this._clear = false;\n    this._populationSize = 50;\n    this._mutationRate = 0.6;\n    this._mutationAmount = 5;\n\n    this._selection = new FitnessProportionateSelection();\n    this._loss = MSELoss;\n    this._mutations = FEEDFORWARD_MUTATIONS;\n    this._activations = Object.values(ALL_ACTIVATIONS);\n    this._template = new Network(this._input, this._output);\n    this._maxNodes = Infinity;\n    this._maxConnections = Infinity;\n    this._maxGates = Infinity;\n    this._threads = os.cpus().length;\n    this._log = -1;\n    this._iterations = 1000;\n    this._error = 0.05;\n    this._maxStagnation = 3;\n  }\n\n  /**\n   * Maximum amount of episodes without improvement before removing a species\n   */\n  private _maxStagnation: number;\n  /**\n   * Getter\n   */\n  public get maxStagnation(): number {\n    return this._maxStagnation;\n  }\n\n  /**\n   * Setter\n   * @param value\n   */\n  public set maxStagnation(value: number) {\n    this._maxStagnation = value;\n  }\n\n  /**\n   * How big could the distance be between a network and the represent of a species?\n   */\n  private _speciesDistanceThreshold = 4;\n\n  /**\n   * Getter\n   */\n  public get speciesDistanceThreshold(): number {\n    return this._speciesDistanceThreshold;\n  }\n\n  /**\n   * Setter\n   */\n  public set speciesDistanceThreshold(value: number) {\n    this._speciesDistanceThreshold = value;\n  }\n\n  private _c1 = 1;\n\n  /**\n   * Getter\n   */\n  public get c1(): number {\n    return this._c1;\n  }\n\n  /**\n   * Setter\n   */\n  public set c1(value: number) {\n    this._c1 = value;\n  }\n\n  private _c2 = 1;\n\n  /**\n   * Getter\n   */\n  public get c2(): number {\n    return this._c2;\n  }\n\n  /**\n   * Setter\n   */\n  public set c2(value: number) {\n    this._c2 = value;\n  }\n\n  private _c3 = 1;\n\n  /**\n   * Getter\n   */\n  public get c3(): number {\n    return this._c3;\n  }\n\n  /**\n   * Setter\n   */\n  public set c3(value: number) {\n    this._c3 = value;\n  }\n\n  private _survivors = 0.8;\n\n  /**\n   * Getter\n   */\n  public get survivors(): number {\n    return this._survivors;\n  }\n\n  /**\n   * Setter\n   */\n  public set survivors(value: number) {\n    this._survivors = value;\n  }\n\n  /**\n   * Specify the amount of threads to use. Default value is the amount of cores in your CPU.\n   */\n  private _threads: number;\n\n  /**\n   * Getter\n   */\n  public get threads(): number {\n    return this._threads;\n  }\n\n  /**\n   * Setter\n   */\n  public set threads(value: number) {\n    this._threads = value;\n  }\n\n  /**\n   * The input size of the network.\n   */\n  private _input: number;\n\n  /**\n   * Getter\n   */\n  public get input(): number {\n    return this._input;\n  }\n\n  /**\n   * Setter\n   */\n  public set input(value: number) {\n    this._input = value;\n  }\n\n  /**\n   * The output size of the network.\n   */\n  private _output: number;\n\n  /**\n   * Getter\n   */\n  public get output(): number {\n    return this._output;\n  }\n\n  /**\n   * Setter\n   */\n  public set output(value: number) {\n    this._output = value;\n  }\n\n  /**\n   * A set of input values and ideal output values to evaluate a genome's fitness with. Must be included to use `NEAT.evaluate` without passing a dataset.\n   */\n  private _dataset?: {\n    /**\n     * The input values\n     */\n    input: number[];\n    /**\n     * The target output values\n     */\n    output: number[];\n  }[];\n\n  /**\n   * Getter\n   */\n  public get dataset():\n    | {\n        /**\n         * The input values\n         */\n        input: number[];\n        /**\n         * The target output values\n         */\n        output: number[];\n      }[]\n    | undefined {\n    return this._dataset;\n  }\n\n  /**\n   * Setter\n   */\n  public set dataset(\n    value:\n      | {\n          /**\n           * The input values\n           */\n          input: number[];\n          /**\n           * The target output values\n           */\n          output: number[];\n        }[]\n      | undefined\n  ) {\n    this._dataset = value;\n  }\n\n  /**\n   * Num of generations already done.\n   */\n  private _generation: number;\n\n  /**\n   * Getter\n   */\n  public get generation(): number {\n    return this._generation;\n  }\n\n  /**\n   * Setter\n   */\n  public set generation(value: number) {\n    this._generation = value;\n  }\n\n  /**\n   * Train options used for training in between two evolution steps\n   */\n  private _training?: TrainOptions;\n\n  /**\n   * Getter\n   */\n  public get training(): TrainOptions | undefined {\n    return this._training;\n  }\n\n  /**\n   * Setter\n   */\n  public set training(value: TrainOptions | undefined) {\n    this._training = value;\n  }\n\n  /**\n   * A template network to create the population from.\n   */\n  private _template: Network;\n\n  /**\n   * Getter\n   */\n  public get template(): Network {\n    return this._template;\n  }\n\n  /**\n   * Setter\n   */\n  public set template(value: Network) {\n    this._template = value;\n  }\n\n  /**\n   * Sets allowed [mutation methods](Mutation) for evolution, a random mutation method will be chosen from the array when mutation occurs. Optional, but default methods are non-recurrent.\n   */\n  private _mutations: Mutation[];\n\n  /**\n   * Getter\n   */\n  public get mutations(): Mutation[] {\n    return this._mutations;\n  }\n\n  /**\n   * Setter\n   */\n  public set mutations(value: Mutation[]) {\n    this._mutations = value;\n  }\n\n  /**\n   * Sets allowed activations for evolution, a random activation method will be chosen from the array when activation mutation occurs.\n   */\n  private _activations: ActivationType[];\n\n  /**\n   * Getter\n   */\n  public get activations(): ActivationType[] {\n    return this._activations;\n  }\n\n  /**\n   * Setter\n   */\n  public set activations(value: ActivationType[]) {\n    this._activations = value;\n  }\n\n  /**\n   * [Selection method](selection) for evolution (e.g. methods.Selection.FITNESS_PROPORTIONATE).\n   */\n  private _selection: Selection;\n\n  /**\n   * Getter\n   */\n  public get selection(): Selection {\n    return this._selection;\n  }\n\n  /**\n   * Setter\n   */\n  public set selection(value: Selection) {\n    this._selection = value;\n  }\n\n  /**\n   * Sets the mutation rate. If set to 0.3, 30% of the new population will be mutated.\n   */\n  private _mutationRate: number;\n\n  /**\n   * Getter\n   */\n  public get mutationRate(): number {\n    return this._mutationRate;\n  }\n\n  /**\n   * Setter\n   */\n  public set mutationRate(value: number) {\n    this._mutationRate = value;\n  }\n\n  /**\n   * If mutation occurs (randomNumber < mutationRate), sets amount of times a mutation method will be applied to the network.\n   */\n  private _mutationAmount: number;\n\n  /**\n   * Getter\n   */\n  public get mutationAmount(): number {\n    return this._mutationAmount;\n  }\n\n  /**\n   * Setter\n   */\n  public set mutationAmount(value: number) {\n    this._mutationAmount = value;\n  }\n\n  /**\n   * Elitism of every evolution loop. [Elitism in genetic algorithms.](https://www.researchgate.net/post/What_is_meant_by_the_term_Elitism_in_the_Genetic_Algorithm)\n   */\n  private _elitism: number;\n\n  /**\n   * Getter\n   */\n  public get elitism(): number {\n    return this._elitism;\n  }\n\n  /**\n   * Setter\n   */\n  public set elitism(value: number) {\n    this._elitism = value;\n  }\n\n  /**\n   * Population size of each generation.\n   */\n  private _populationSize: number;\n\n  /**\n   * Getter\n   */\n  public get populationSize(): number {\n    return this._populationSize;\n  }\n\n  /**\n   * Setter\n   */\n  public set populationSize(value: number) {\n    this._populationSize = value;\n  }\n\n  /**\n   * A fitness function to evaluate the networks. Takes a `genome`, i.e. a [network](Network), and a `dataset` and sets the genome's score property\n   *\n   * @param population The population which needs to be evaluated\n   * @param dataset The dataset to test the networks.\n   */\n  private _fitnessFunction?: (\n    population: Network[],\n    dataset?: {\n      /**\n       * The input values\n       */\n      input: number[];\n      /**\n       * The target output values\n       */\n      output: number[];\n    }[]\n  ) => Promise<void>;\n\n  /**\n   * Getter\n   */\n  public get fitnessFunction():\n    | ((\n        population: Network[],\n        dataset?: {\n          /**\n           * The input values\n           */\n          input: number[];\n          /**\n           * The target output values\n           */\n          output: number[];\n        }[]\n      ) => Promise<void>)\n    | undefined {\n    return this._fitnessFunction;\n  }\n\n  /**\n   * Setter\n   */\n  public set fitnessFunction(\n    value:\n      | ((\n          population: Network[],\n          dataset?: {\n            /**\n             * The input values\n             */\n            input: number[];\n            /**\n             * The target output values\n             */\n            output: number[];\n          }[]\n        ) => Promise<void>)\n      | undefined\n  ) {\n    this._fitnessFunction = value;\n  }\n\n  /**\n   * Specify the loss function for the evolution, this tells a genome in the population how well it's performing. Default: methods.loss.MSE (recommended).\n   */\n  private _loss: lossType;\n\n  /**\n   * Getter\n   */\n  public get loss(): lossType {\n    return this._loss;\n  }\n\n  /**\n   * Setter\n   */\n  public set loss(value: lossType) {\n    this._loss = value;\n  }\n\n  /**\n   * Maximum nodes for a potential network\n   */\n  private _maxNodes: number;\n\n  /**\n   * Getter\n   */\n  public get maxNodes(): number {\n    return this._maxNodes;\n  }\n\n  /**\n   * Setter\n   */\n  public set maxNodes(value: number) {\n    this._maxNodes = value;\n  }\n\n  /**\n   * Maximum connections for a potential network\n   */\n  private _maxConnections: number;\n\n  /**\n   * Getter\n   */\n  public get maxConnections(): number {\n    return this._maxConnections;\n  }\n\n  /**\n   * Setter\n   */\n  public set maxConnections(value: number) {\n    this._maxConnections = value;\n  }\n\n  /**\n   * Maximum gates for a potential network\n   */\n  private _maxGates: number;\n\n  /**\n   * Getter\n   */\n  public get maxGates(): number {\n    return this._maxGates;\n  }\n\n  /**\n   * Setter\n   */\n  public set maxGates(value: number) {\n    this._maxGates = value;\n  }\n\n  /**\n   * If set to true when [Network.crossOver](Network.crossOver) runs it will assume both genomes are equally fit.\n   */\n  private _equal: boolean;\n\n  /**\n   * Getter\n   */\n  public get equal(): boolean {\n    return this._equal;\n  }\n\n  /**\n   * Setter\n   */\n  public set equal(value: boolean) {\n    this._equal = value;\n  }\n\n  /**\n   * If set to n, outputs training status every n iterations. Setting `log` to 1 will log the status every iteration\n   */\n  private _log: number;\n\n  /**\n   * Getter\n   */\n  public get log(): number {\n    return this._log;\n  }\n\n  /**\n   * Setter\n   */\n  public set log(value: number) {\n    this._log = value;\n  }\n\n  /**\n   * You can schedule tasks to happen every n iterations. Paired with `options.schedule.function`\n   */\n  private _schedule?: {\n    /**\n     * You can schedule tasks to happen every n iterations. Paired with `options.schedule.function`\n     */\n    iterations: number;\n    /**\n     * A function to run every n iterations as set by `options.schedule.iterations`. Passed as an object with a \"function\" property that contains the function to run.\n     *\n     * @param fitness the fitness value of the best genome\n     * @param error the current network error\n     * @param iteration the current iteration count\n     */\n    function: (fitness: number, error: number, iteration: number) => undefined;\n  };\n\n  /**\n   * Getter\n   */\n  public get schedule():\n    | {\n        /**\n         * You can schedule tasks to happen every n iterations. Paired with `options.schedule.function`\n         */\n        iterations: number;\n        /**\n         * A function to run every n iterations as set by `options.schedule.iterations`. Passed as an object with a \"function\" property that contains the function to run.\n         *\n         * @param fitness the fitness value of the best genome\n         * @param error the current network error\n         * @param iteration the current iteration count\n         */\n        function: (\n          fitness: number,\n          error: number,\n          iteration: number\n        ) => undefined;\n      }\n    | undefined {\n    return this._schedule;\n  }\n\n  /**\n   * Setter\n   */\n  public set schedule(\n    value:\n      | {\n          /**\n           * You can schedule tasks to happen every n iterations. Paired with `options.schedule.function`\n           */\n          iterations: number;\n          /**\n           * A function to run every n iterations as set by `options.schedule.iterations`. Passed as an object with a \"function\" property that contains the function to run.\n           *\n           * @param fitness the fitness value of the best genome\n           * @param error the current network error\n           * @param iteration the current iteration count\n           */\n          function: (\n            fitness: number,\n            error: number,\n            iteration: number\n          ) => undefined;\n        }\n      | undefined\n  ) {\n    this._schedule = value;\n  }\n\n  /**\n   * If set to true, will clear the network after every activation. This is useful for evolving recurrent networks, more importantly for time series prediction.\n   */\n  private _clear: boolean;\n\n  /**\n   * Getter\n   */\n  public get clear(): boolean {\n    return this._clear;\n  }\n\n  /**\n   * Setter\n   */\n  public set clear(value: boolean) {\n    this._clear = value;\n  }\n\n  /**\n   * Set the maximum amount of iterations/generations for the algorithm to run.\n   */\n  private _iterations: number;\n\n  /**\n   * Getter\n   */\n  public get iterations(): number {\n    return this._iterations;\n  }\n\n  /**\n   * Setter\n   */\n  public set iterations(value: number) {\n    this._iterations = value;\n  }\n\n  /**\n   * Set the target error. The algorithm will stop once this target error has been reached.\n   */\n  private _error: number;\n\n  /**\n   * Getter\n   */\n  public get error(): number {\n    return this._error;\n  }\n\n  /**\n   * Setter\n   */\n  public set error(value: number) {\n    this._error = value;\n  }\n}\n","import * as TimSort from 'timsort';\nimport {maxValueIndex, pickRandom} from '../utils/Utils';\nimport {Network} from './Network';\n\n/**\n * A class holding a species\n */\nexport class Species {\n  /**\n   * The representative network of this species\n   * @private\n   */\n  public representative: Network;\n\n  /**\n   * The member networks in this species\n   * @private\n   */\n  public readonly members: Set<Network>;\n\n  /**\n   * The last score of this species.\n   * Used for stagnation checking.\n   * @private\n   */\n  private lastScore: number;\n\n  constructor(representative: Network) {\n    this.representative = representative;\n    this.representative.species = this;\n\n    this.members = new Set<Network>();\n    this.members.add(representative);\n\n    this._score = 0;\n    this.lastScore = 0;\n    this._stagnation = 0;\n  }\n\n  /**\n   * The score of this species\n   * @private\n   */\n  private _score: number;\n\n  /**\n   * Getter\n   */\n  get score(): number {\n    return this._score;\n  }\n\n  /**\n   * Indicates how man episodes without improvements.\n   * @private\n   */\n  private _stagnation: number;\n\n  /**\n   * Getter\n   */\n  get stagnation(): number {\n    return this._stagnation;\n  }\n\n  /**\n   * Puts a network to the species, after checking the distance\n   * @param network\n   * @param c1\n   * @param c2\n   * @param c3\n   * @param distanceThreshold\n   */\n  public put(\n    network: Network,\n    c1: number,\n    c2: number,\n    c3: number,\n    distanceThreshold: number\n  ): boolean {\n    if (network.distance(this.representative, c1, c2, c3) < distanceThreshold) {\n      this.forcePut(network);\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n  /**\n   * Puts a network to the species without checking the distance\n   * @param network\n   */\n  public forcePut(network: Network): void {\n    if (network === undefined) {\n      return;\n    }\n    this.members.add(network);\n    network.species = this;\n  }\n\n  /**\n   * Calculate the score of this species\n   */\n  public evaluateScore(): void {\n    let sum = 0;\n    this.members.forEach(network => (sum += network.score ?? 0));\n    const score: number = sum / this.members.size;\n    if (this.lastScore < score) {\n      this._stagnation++;\n    } else {\n      this._stagnation = 0;\n    }\n    this._score = score;\n  }\n\n  /**\n   * Reset this object\n   */\n  public reset(): void {\n    this.representative = pickRandom(this.members);\n    this.members.forEach(genome => (genome.species = null));\n    this.members.clear();\n    this.members.add(this.representative);\n    this.representative.species = this;\n    this.lastScore = this.score;\n    this._score = 0;\n  }\n\n  /**\n   * Kill a specific percentage of networks\n   * @param percentage\n   */\n  public kill(percentage: number): void {\n    const arr: Network[] = Array.from(this.members);\n    TimSort.sort(arr, (a: Network, b: Network) => {\n      return a.score === undefined || b.score === undefined\n        ? 0\n        : a.score - b.score;\n    });\n\n    const amount: number = Math.floor(percentage * this.members.size);\n    for (let i = 0; i < amount; i++) {\n      this.members.delete(arr[i]);\n      arr[i].species = null;\n    }\n  }\n\n  /**\n   * Create offspring\n   */\n  public breed(): Network {\n    return Network.crossOver(\n      pickRandom(this.members),\n      pickRandom(this.members)\n    );\n  }\n\n  /**\n   * The size of this species\n   */\n  public size(): number {\n    return this.members.size;\n  }\n\n  /**\n   * Returns the best genome from this species\n   */\n  public getBest(): Network {\n    const networks: Network[] = Array.from(this.members);\n    return networks[\n      maxValueIndex(networks.map(genome => genome.score ?? -Infinity))\n    ];\n  }\n\n  /**\n   * to string\n   */\n  public print(): void {\n    console.log(\n      'Species={Members: ' +\n        this.members.size +\n        '; Score: ' +\n        this._score +\n        '; Stagnation: ' +\n        this.stagnation +\n        '}'\n    );\n  }\n}\n","import * as TimSort from 'timsort';\nimport {Network} from './architecture/Network';\nimport {Species} from './architecture/Species';\nimport {EvolveOptions} from './interfaces/EvolveOptions';\nimport {\n  AddConnectionMutation,\n  AddGateMutation,\n  AddNodeMutation,\n  Mutation,\n} from './methods/Mutation';\nimport {pickRandom} from './utils/Utils';\n\n/**\n * Runs the NEAT algorithm on group of neural networks.\n *\n * @constructs Neat\n */\nexport class NEAT {\n  /**\n   * population The current population for the neat instance. Accessible through `neat.population`.\n   */\n  private population: Network[];\n\n  /**\n   * Species\n   */\n  private readonly species: Set<Species>;\n\n  /**\n   * Constructs a NEAT object.\n   *\n   * @param options\n   */\n  constructor(options: EvolveOptions) {\n    if (!options.fitnessFunction) {\n      throw new ReferenceError('No fitness function given!');\n    }\n    this._options = options;\n    this.population = [];\n    this.species = new Set<Species>();\n\n    for (let i = 0; i < this.options.populationSize; i++) {\n      this.population.push(this.options.template.copy());\n    }\n  }\n\n  /**\n   * Class holding all options for the Evolution process\n   */\n  private _options: EvolveOptions;\n\n  /**\n   * Getter\n   */\n  public get options(): EvolveOptions {\n    return this._options;\n  }\n\n  /**\n   * Setter\n   */\n  public set options(value: EvolveOptions) {\n    this._options = value;\n  }\n\n  /**\n   * Mutate a network with a random mutation from the allowed array.\n   *\n   * @param network The network which will be mutated.\n   */\n  public mutateRandom(network: Network): void {\n    const allowed: Mutation[] = this.options.mutations.filter(method => {\n      return (\n        method.constructor.name !== AddNodeMutation.constructor.name ||\n        network.nodes.length < this.options.maxNodes ||\n        method.constructor.name !== AddConnectionMutation.constructor.name ||\n        network.connections.size < this.options.maxConnections ||\n        method.constructor.name !== AddGateMutation.constructor.name ||\n        network.gates.size < this.options.maxGates\n      );\n    });\n    network.mutate(pickRandom(allowed), {\n      allowedActivations: this.options.activations,\n    });\n  }\n\n  /**\n   * Evaluates, selects, breeds and mutates population\n   *\n   * @returns {Network} Fittest network\n   */\n  public async evolve(): Promise<Network> {\n    this.genSpecies();\n\n    await this.evaluate();\n    this.sort();\n    this.species.forEach(species => species.evaluateScore());\n\n    this.kill(1 - this.options.survivors);\n    this.removeExtinctSpecies();\n    this.reproduce();\n\n    // const elitists: Network[] = this.population.splice(0, this.options.elitism);\n    this.mutate();\n    // this.population.splice(0, 0, ...elitists);\n\n    if (this.options.training) {\n      for (const genome of this.population) {\n        genome.train(this.options.training);\n      }\n    }\n\n    // evaluate the population\n    await this.evaluate();\n\n    // Sort in order of fitness (fittest first)\n    this.sort();\n\n    const fittest: Network = this.population[0].copy();\n    fittest.score = this.population[0].score;\n\n    if (\n      this.options.log > 0 &&\n      this.options.generation % this.options.log === 0\n    ) {\n      console.log('\\n---------------------------');\n      console.log(\n        'Generation: ' +\n          this.options.generation +\n          '; Species: ' +\n          this.species.size +\n          '; Score: ' +\n          this.population[0].score\n      );\n      for (const species of this.species) {\n        species.print();\n      }\n    }\n\n    // Reset the scores\n    this.population.forEach(genome => (genome.score = undefined));\n\n    this.options.generation++;\n\n    return fittest;\n  }\n\n  /**\n   * Mutates the given (or current) population\n   *\n   * @param {Mutation} [method] A mutation method to mutate the population with. When not specified will pick a random mutation from the set allowed mutations.\n   */\n  public mutate(method?: Mutation | undefined): void {\n    // Elitist genomes should not be included\n    this.population\n      .filter(() => Math.random() <= this.options.mutationRate)\n      .forEach(genome => {\n        for (let i = 0; i < this.options.mutationAmount; i++) {\n          if (method) {\n            genome.mutate(method);\n          } else {\n            this.mutateRandom(genome);\n          }\n        }\n      });\n  }\n\n  /**\n   * Evaluates the current population, basically sets their `.score` property\n   *\n   * @return {Network} Fittest Network\n   */\n  public async evaluate(): Promise<Network> {\n    if (this.options.clear) {\n      this.population.forEach(genome => genome.clear());\n    }\n    await this.options.fitnessFunction?.(this.population, this.options.dataset);\n\n    // Sort the population in order of fitness\n    this.sort();\n\n    return this.population[0];\n  }\n\n  /**\n   * Sorts the population by score (descending)\n   * @todo implement a quicksort algorithm in utils\n   */\n  public sort(): void {\n    TimSort.sort(this.population, (a: Network, b: Network) => {\n      return a.score === undefined || b.score === undefined\n        ? 0\n        : b.score - a.score;\n    });\n  }\n\n  /**\n   * Returns the fittest genome of the current population\n   *\n   * @returns {Network} Current population's fittest genome\n   */\n  public async getFittest(): Promise<Network> {\n    if (this.population[this.population.length - 1].score === undefined) {\n      await this.evaluate();\n    }\n    this.sort();\n\n    return this.population[0];\n  }\n\n  /**\n   * Returns the average fitness of the current population\n   *\n   * @returns {number} Average fitness of the current population\n   */\n  public async getAverage(): Promise<number> {\n    if (this.population[this.population.length - 1].score === undefined) {\n      await this.evaluate();\n    }\n    let score = 0;\n    this.population\n      .map(genome => genome.score)\n      .forEach(val => (score += val ?? 0));\n    return score / this.population.length;\n  }\n\n  /**\n   * Replace the whole population with the new genomes\n   * @param genomes the genomes which replace the population\n   */\n  public replacePopulation(genomes: Network[]): void {\n    this.population = genomes;\n    this.options.populationSize = genomes.length;\n  }\n\n  /**\n   * Reproduce the population, by replacing the killed networks\n   * @private\n   */\n  private reproduce(): void {\n    const speciesArr: Species[] = Array.from(this.species);\n    if (speciesArr.length === 0) {\n      return;\n    }\n    for (let i = 0; i < this.population.length; i++) {\n      if (this.population[i].species === null) {\n        const selectedSpecies: Species = this.options.selection.select(\n          speciesArr\n        );\n        this.population[i] = selectedSpecies.breed();\n        selectedSpecies.forcePut(this.population[i]);\n      }\n    }\n  }\n\n  /**\n   * Remove empty species\n   * @private\n   */\n  private removeExtinctSpecies(): void {\n    for (const species of Array.from(this.species)) {\n      if (\n        species.size() <= 1 ||\n        species.stagnation > this.options.maxStagnation\n      ) {\n        species.members.forEach(member => (member.species = null));\n        this.species.delete(species);\n      }\n    }\n  }\n\n  /**\n   * Kill bad networks\n   * @param killRate\n   * @private\n   */\n  private kill(killRate: number): void {\n    this.species.forEach(species => species.kill(killRate));\n  }\n\n  /**\n   * Generate species\n   * @private\n   */\n  private genSpecies(): void {\n    this.species.forEach(species => species.reset());\n    this.population\n      .filter(genome => genome.species === null)\n      .forEach(genome => {\n        let found = false;\n        for (const species of Array.from(this.species)) {\n          if (\n            species.put(\n              genome,\n              this.options.c1,\n              this.options.c2,\n              this.options.c3,\n              this.options.speciesDistanceThreshold\n            )\n          ) {\n            found = true;\n            break;\n          }\n        }\n        if (!found) {\n          this.species.add(new Species(genome));\n        }\n      });\n  }\n}\n","import {ActivationType} from 'activations/build/src';\nimport {spawn, Worker} from 'threads';\nimport {Pool} from 'threads/dist';\nimport 'threads/register';\nimport * as TimSort from 'timsort';\nimport {NodeType} from '../enums/NodeType';\nimport {ConnectionJSON} from '../interfaces/ConnectionJSON';\nimport {EvolveOptions} from '../interfaces/EvolveOptions';\nimport {NetworkJSON} from '../interfaces/NetworkJSON';\nimport {TrainOptions} from '../interfaces/TrainOptions';\nimport {ALL_LOSSES, lossType, MSELoss} from '../methods/Loss';\nimport {ALL_MUTATIONS, Mutation, SubNodeMutation} from '../methods/Mutation';\nimport {TestWorker} from '../multithreading/TestWorker';\nimport {NEAT} from '../NEAT';\nimport {\n  pairing,\n  pickRandom,\n  randBoolean,\n  randInt,\n  removeFromArray,\n  shuffle,\n} from '../utils/Utils';\nimport {Connection} from './Connection';\nimport {Node} from './Node';\nimport {Species} from './Species';\n\n/**\n * Create a neural network\n *\n * Networks are easy to create, all you need to specify is an `input` and an `output` size.\n *\n * @constructs Network\n */\nexport class Network {\n  /**\n   * Species of this network\n   */\n  public species: Species | null;\n  /**\n   * The input size of this network.\n   */\n  public readonly inputSize: number;\n  /**\n   * The output size of this network.\n   */\n  public readonly outputSize: number;\n  /**\n   * The nodes inside this network. Stored in activation order.\n   */\n  public nodes: Node[];\n  /**\n   * The connections inside this network.\n   */\n  public connections: Set<Connection>;\n  /**\n   * The gates inside this network.\n   */\n  public gates: Set<Connection>;\n  /**\n   * The score of this network for evolution.\n   */\n  public score: number | undefined;\n\n  constructor(inputSize: number, outputSize: number) {\n    this.inputSize = inputSize;\n    this.outputSize = outputSize;\n\n    this.nodes = [];\n    this.connections = new Set<Connection>();\n    this.gates = new Set<Connection>();\n    this.score = undefined;\n    this.species = null;\n\n    // Create input and output nodes\n    for (let i = 0; i < inputSize; i++) {\n      this.nodes.push(new Node(NodeType.INPUT));\n    }\n    for (let i = 0; i < outputSize; i++) {\n      this.nodes.push(new Node(NodeType.OUTPUT));\n    }\n\n    // Connect input and output nodes\n    for (let i = 0; i < this.inputSize; i++) {\n      for (\n        let j: number = this.inputSize;\n        j < this.outputSize + this.inputSize;\n        j++\n      ) {\n        // https://stats.stackexchange.com/a/248040/147931\n        const weight: number =\n          (Math.random() - 0.5) *\n          this.inputSize *\n          Math.sqrt(2 / this.inputSize);\n        this.connect(this.nodes[i], this.nodes[j], weight);\n      }\n    }\n  }\n\n  /**\n   * Convert a json object to a network\n   *\n   * @param {{input:{number},output:{number},dropout:{number},nodes:Array<object>,connections:Array<object>}} json A network represented as a json object\n   *\n   * @returns {Network} Network A reconstructed network\n   */\n  public static fromJSON(json: NetworkJSON): Network {\n    const network: Network = new Network(json.inputSize, json.outputSize);\n\n    network.nodes = [];\n    network.connections.clear();\n\n    json.nodes\n      .map(nodeJSON => new Node().fromJSON(nodeJSON))\n      .forEach(node => (network.nodes[node.index] = node));\n\n    json.connections.forEach(jsonConnection => {\n      const connection: Connection = network.connect(\n        network.nodes[jsonConnection.fromIndex],\n        network.nodes[jsonConnection.toIndex],\n        jsonConnection.weight\n      );\n\n      if (jsonConnection.gateNodeIndex !== null) {\n        network.addGate(\n          network.nodes[jsonConnection.gateNodeIndex],\n          connection\n        );\n      }\n    });\n    return network;\n  }\n\n  /**\n   * Create an offspring from two parent networks.\n   *\n   * Networks are not required to have the same size, however input and output size should be the same!\n   *\n   * @todo Add custom [crossover](crossover) method customization\n   *\n   * @param {Network} network1 First parent network\n   * @param {Network} network2 Second parent network\n   *\n   * @returns {Network} New network created from mixing parent networks\n   */\n  public static crossOver(network1: Network, network2: Network): Network {\n    if (\n      network1.inputSize !== network2.inputSize ||\n      network1.outputSize !== network2.outputSize\n    ) {\n      throw new Error('Networks don`t have the same input/output size!');\n    }\n\n    // Initialise offspring\n    const offspring: Network = new Network(\n      network1.inputSize,\n      network1.outputSize\n    );\n    offspring.connections.clear(); // clear\n    offspring.nodes = []; // clear\n\n    // Save scores and create a copy\n    const score1: number = network1.score ?? 0;\n    const score2: number = network2.score ?? 0;\n\n    // Determine offspring node size\n    let offspringSize: number;\n    if (score1 === score2) {\n      const max: number = Math.max(\n        network1.nodes.length,\n        network2.nodes.length\n      );\n      const min: number = Math.min(\n        network1.nodes.length,\n        network2.nodes.length\n      );\n      offspringSize = randInt(min, max + 1); // [min,max]\n    } else if (score1 > score2) {\n      offspringSize = network1.nodes.length;\n    } else {\n      offspringSize = network2.nodes.length;\n    }\n\n    const inputSize: number = network1.inputSize;\n    const outputSize: number = network1.outputSize;\n\n    // set node indices\n    for (let i = 0; i < network1.nodes.length; i++) {\n      network1.nodes[i].index = i;\n    }\n\n    // set node indices\n    for (let i = 0; i < network2.nodes.length; i++) {\n      network2.nodes[i].index = i;\n    }\n\n    // Assign nodes from parents to offspring\n    for (let i = 0; i < offspringSize; i++) {\n      let chosenNode: Node;\n      let chosenNodeType: NodeType | null = null;\n\n      // decide what type of node is needed first check for input and output nodes and fill up with hidden nodes\n      if (i < inputSize) {\n        // pick input node\n        chosenNodeType = NodeType.INPUT;\n        const sourceNetwork: Network = randBoolean() ? network1 : network2;\n        let inputNumber = -1;\n        let j = -1;\n        while (inputNumber < i) {\n          if (j++ >= sourceNetwork.nodes.length) {\n            throw RangeError('something is wrong with the size of the input');\n          }\n          if (sourceNetwork.nodes[j].isInputNode()) {\n            inputNumber++;\n          }\n        }\n        chosenNode = sourceNetwork.nodes[j];\n      } else if (i < inputSize + outputSize) {\n        // pick output node\n        chosenNodeType = NodeType.OUTPUT;\n        const sourceNetwork: Network = randBoolean() ? network1 : network2;\n        let outputNumber = -1;\n        let j = -1;\n        while (outputNumber < i - inputSize) {\n          j++;\n          if (j >= sourceNetwork.nodes.length) {\n            throw RangeError('something is wrong with the size of the output');\n          }\n          if (sourceNetwork.nodes[j].isOutputNode()) {\n            outputNumber++;\n          }\n        }\n        chosenNode = sourceNetwork.nodes[j];\n      } else {\n        // pick hidden node\n        chosenNodeType = NodeType.HIDDEN;\n        let sourceNetwork: Network;\n        if (i >= network1.nodes.length) {\n          sourceNetwork = network2;\n        } else if (i >= network2.nodes.length) {\n          sourceNetwork = network1;\n        } else {\n          sourceNetwork = randBoolean() ? network1 : network2;\n        }\n        chosenNode = pickRandom(sourceNetwork.nodes);\n      }\n\n      const newNode: Node = new Node(chosenNodeType);\n      newNode.bias = chosenNode.bias;\n      newNode.squash = chosenNode.squash;\n      offspring.nodes.push(newNode);\n    }\n\n    // Create arrays of connection genes\n    const n1connections: (ConnectionJSON | undefined)[] = [];\n    const n2connections: (ConnectionJSON | undefined)[] = [];\n\n    // Add the connections of network 1\n    network1.connections.forEach(connection => {\n      n1connections[\n        pairing(connection.from.index, connection.to.index)\n      ] = connection.toJSON();\n    });\n    // Add the connections of network 2\n    network2.connections.forEach(connection => {\n      n2connections[\n        pairing(connection.from.index, connection.to.index)\n      ] = connection.toJSON();\n    });\n\n    // Split common conn genes from disjoint or excess conn genes\n    const connections: (ConnectionJSON | undefined)[] = [];\n    const keys1: string[] = Object.keys(n1connections);\n    const keys2: string[] = Object.keys(n2connections);\n    for (let i: number = keys1.length - 1; i >= 0; i--) {\n      if (n2connections[parseInt(keys1[i])] !== undefined) {\n        connections.push(\n          randBoolean()\n            ? n1connections[parseInt(keys1[i])]\n            : n2connections[parseInt(keys1[i])]\n        );\n\n        n2connections[parseInt(keys1[i])] = undefined;\n      } else if (score1 >= score2) {\n        connections.push(n1connections[parseInt(keys1[i])]);\n      }\n    }\n\n    // Excess/disjoint gene\n    if (score2 >= score1) {\n      keys2\n        .map(key => parseInt(key)) // convert to numbers\n        .map(key => n2connections[key]) // get the connection\n        .filter(conn => conn !== undefined) // filter out undefined connections\n        .forEach(conn => connections.push(conn)); // add the filtered connections\n    }\n\n    // Add common conn genes uniformly\n    connections.forEach(connectionJSON => {\n      if (\n        connectionJSON !== undefined &&\n        connectionJSON.toIndex < offspringSize &&\n        connectionJSON.fromIndex < offspringSize\n      ) {\n        const from: Node = offspring.nodes[connectionJSON.fromIndex];\n        const to: Node = offspring.nodes[connectionJSON.toIndex];\n        const connection: Connection = offspring.connect(\n          from,\n          to,\n          connectionJSON.weight\n        );\n\n        if (\n          connectionJSON.gateNodeIndex !== null &&\n          connectionJSON.gateNodeIndex < offspringSize\n        ) {\n          offspring.addGate(\n            offspring.nodes[connectionJSON.gateNodeIndex],\n            connection\n          );\n        }\n      }\n    });\n\n    return offspring;\n  }\n\n  /**\n   * Returns a copy of Network.\n   * @returns {Network} Returns an identical network\n   */\n  public copy(): Network {\n    return Network.fromJSON(this.toJSON());\n  }\n\n  /**\n   * Connects a Node to another Node or Group in the network\n   *\n   * @param {Node} from The source Node\n   * @param {Node} to The destination Node or Group\n   * @param {number} [weight=0] An initial weight for the connections to be formed\n   *\n   * @returns {Connection[]} An array of the formed connections\n   */\n  public connect(from: Node, to: Node, weight = 0): Connection {\n    const connection: Connection = from.connect(to, weight); // run node-level connect\n    this.connections.add(connection); // add it to the array\n    return connection;\n  }\n\n  /**\n   * Activates the network\n   *\n   * It will activate all the nodes in activation order and produce an output.\n   *\n   * @param {number[]} [input] Input values to activate nodes with\n   * @param options\n   * @returns {number[]} Squashed output values\n   */\n  public activate(\n    input: number[],\n    options: {\n      /**\n       * The dropout rate. [dropout](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5)\n       */\n      dropoutRate?: number;\n      /**\n       * Controls whether traces are created when activation happens (a trace is meta information left behind for different uses, e.g. backpropagation).\n       */\n      trace?: boolean;\n    } = {}\n  ): number[] {\n    if (input.length !== this.inputSize) {\n      throw new RangeError(\n        'Input size of dataset is different to network input size!'\n      );\n    }\n    // get default value if no value is given\n    options.dropoutRate = options.dropoutRate ?? 0;\n    options.trace = options.trace ?? true;\n\n    this.nodes\n      .filter(node => node.isInputNode()) // only input nodes\n      .forEach((node: Node, index: number) =>\n        node.activate(input[index], options.trace)\n      ); // activate them with the input\n\n    this.nodes\n      .filter(node => node.isHiddenNode()) // only hidden nodes\n      .forEach((node: Node) => {\n        if (options.dropoutRate) {\n          node.mask = Math.random() >= options.dropoutRate ? 1 : 0;\n        }\n\n        node.activate(undefined, options.trace); // activate them\n      });\n\n    return this.nodes\n      .filter(node => node.isOutputNode()) // only output nodes\n      .map((node: Node) => node.activate(undefined, options.trace)); // map them to there activation value will give the network's output\n  }\n\n  /**\n   * Backpropagate the network\n   *\n   * This function allows you to teach the network. If you want to do more complex training, use the `network.train()` function.\n   *\n   * @param {number[]} target Ideal values of the previous activate. Will use the difference to improve the weights\n   * @param options More option for propagation\n   */\n  public propagate(\n    target: number[],\n    options: {\n      /**\n       * Sets the [learning rate](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10) of the backpropagation process.\n       */\n      rate?: number;\n      /**\n       * [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html). Adds a fraction of the previous weight update to the current one.\n       */\n      momentum?: number;\n      /**\n       * When set to false weights won't update, but when set to true after being false the last propagation will include the delta weights of the first \"update:false\" propagation too.\n       */\n      update?: boolean;\n    } = {}\n  ): void {\n    // get default value if value isn't given\n    options.rate = options.rate ?? 0.3;\n    options.momentum = options.momentum ?? 0;\n    options.update = options.update ?? false;\n\n    if (target.length !== this.outputSize) {\n      throw new Error(\n        'Output target length should match network output length'\n      );\n    }\n\n    // Backpropagation: output -> hidden -> input\n\n    // propagate through the output nodes\n    this.nodes\n      .filter(node => node.isOutputNode()) // only output nodes\n      .forEach((node, index) => node.propagate(target[index], options)); // propagate\n\n    // propagate backwards through the hidden nodes\n    for (let i: number = this.nodes.length - 1; i >= 0; i--) {\n      if (this.nodes[i].isHiddenNode()) {\n        // only hidden nodes\n        this.nodes[i].propagate(undefined, options);\n      }\n    }\n\n    // propagate through the input nodes\n    this.nodes\n      .filter(node => node.isInputNode()) // only input nodes\n      .forEach(node => node.propagate(undefined, options)); // propagate\n  }\n\n  /**\n   * Clear the context of the network\n   */\n  public clear(): void {\n    this.nodes.forEach(node => node.clear());\n  }\n\n  /**\n   * Removes the connection of the `from` node to the `to` node\n   *\n   * @param {Node} from Source node\n   * @param {Node} to Destination node\n   */\n  public disconnect(from: Node, to: Node): Connection {\n    // remove the connection network-level\n    this.connections.forEach(conn => {\n      if (conn.from === from && conn.to === to) {\n        if (conn.gateNode !== null) {\n          this.removeGate(conn); // remove possible gate\n        }\n        this.connections.delete(conn); // remove connection from array\n      }\n    });\n    // disconnect node-level\n    return from.disconnect(to);\n  }\n\n  /**\n   * Makes a network node gate a connection\n   *\n   * @param {Node} node Gating node\n   * @param {Connection} connection Connection to gate with node\n   */\n  public addGate(node: Node, connection: Connection): void {\n    if (this.nodes.indexOf(node) === -1) {\n      throw new ReferenceError('This node is not part of the network!');\n    } else if (connection.gateNode !== null) {\n      return;\n    }\n    node.addGate(connection);\n    this.gates.add(connection);\n  }\n\n  /**\n   * Remove the gate of a connection.\n   *\n   * @param {Connection} connection Connection to remove gate from\n   */\n  public removeGate(connection: Connection): void {\n    if (!this.gates.has(connection)) {\n      throw new Error('This connection is not gated!');\n    }\n    this.gates.delete(connection);\n    if (connection.gateNode !== null) {\n      connection.gateNode.removeGate(connection);\n    }\n  }\n\n  /**\n   * Removes a node from a network, all its connections will be redirected. If it gates a connection, the gate will be removed.\n   *\n   * @param {Node} node Node to remove from the network\n   * @param keepGates\n   */\n  public removeNode(\n    node: Node,\n    keepGates: boolean = new SubNodeMutation().keepGates\n  ): void {\n    if (!this.nodes.includes(node)) {\n      throw new ReferenceError('This node does not exist in the network!');\n    }\n\n    this.disconnect(node, node); // remove self connection\n\n    const inputs: Node[] = []; // keep track\n    const gates: Node[] = []; // keep track\n    const outputs: Node[] = []; // keep track\n    const connections: Connection[] = []; // keep track\n\n    // read all inputs from node and keep track of the nodes that gate the incoming connection\n    node.incoming.forEach(connection => {\n      if (\n        keepGates &&\n        connection.gateNode !== null &&\n        connection.gateNode !== node\n      ) {\n        gates.push(connection.gateNode);\n      }\n      inputs.push(connection.from);\n      this.disconnect(connection.from, node);\n    });\n\n    // read all outputs from node and keep track of the nodes that gate the outgoing connection\n    node.outgoing.forEach(connection => {\n      if (\n        keepGates &&\n        connection.gateNode !== null &&\n        connection.gateNode !== node\n      ) {\n        gates.push(connection.gateNode);\n      }\n      outputs.push(connection.to);\n      this.disconnect(node, connection.to);\n    });\n\n    // add all connections the node has\n    inputs.forEach(input => {\n      outputs.forEach(output => {\n        if (!input.isProjectingTo(output)) {\n          connections.push(this.connect(input, output));\n        }\n      });\n    });\n\n    // as long as there are gates and connections\n    while (gates.length > 0 && connections.length > 0) {\n      const gate: Node | undefined = gates.shift(); // take a gate node and remove it from the array\n      if (gate === undefined) {\n        continue;\n      }\n\n      const connection: Connection = pickRandom(connections); // take a random connection\n      this.addGate(gate, connection); // gate the connection with the gate node\n      removeFromArray(connections, connection); // remove the connection from the array\n    }\n\n    // remove every gate the node has\n    node.gated.forEach(this.removeGate);\n\n    removeFromArray(this.nodes, node); // remove the node from the nodes array\n  }\n\n  /**\n   * Mutates the network with the given method.\n   *\n   * @param {Mutation} method [Mutation method](mutation)\n   * @param {object} options\n   * @param {number} [options.maxNodes]\n   * @param {number} [options.maxConnections]\n   * @param {number} [options.maxGates] Maximum amount of Gates a network can grow to\n   */\n  public mutate(\n    method: Mutation,\n    options?: {\n      /**\n       * Maximum amount of [Nodes](node) a network can grow to\n       */\n      maxNodes?: number;\n      /**\n       * Maximum amount of [Connections](connection) a network can grow to\n       */\n      maxConnections?: number;\n      /**\n       * Maximum amount of Gates a network can grow to\n       */\n      maxGates?: number;\n      /**\n       * All allowed activations\n       */\n      allowedActivations?: ActivationType[];\n    }\n  ): void {\n    method.mutate(this, options);\n  }\n\n  /**\n   * Selects a random mutation method and returns a mutated copy of the network. Warning! Mutates network directly.\n   *\n   * @param {Mutation[]} [allowedMethods=methods.mutation.ALL] An array of [Mutation methods](mutation) to automatically pick from\n   * @param {object} options\n   * @param {number} [options.maxNodes] Maximum amount of [Nodes](node) a network can grow to\n   * @param {number} [options.maxConnections] Maximum amount of [Connections](connection) a network can grow to\n   * @param {number} [options.maxGates] Maximum amount of Gates a network can grow to\n   */\n  public mutateRandom(\n    allowedMethods: Mutation[] = ALL_MUTATIONS,\n    options: {\n      /**\n       * Maximum amount of [Nodes](node) a network can grow to\n       */\n      maxNodes?: number;\n      /**\n       * Maximum amount of [Connections](connection) a network can grow to\n       */\n      maxConnections?: number;\n      /**\n       * Maximum amount of Gates a network can grow to\n       */\n      maxGates?: number;\n      /**\n       * All allowed activations\n       */\n      allowedActivations?: ActivationType[];\n    } = {}\n  ): void {\n    if (allowedMethods.length === 0) {\n      return;\n    }\n    // mutate the network with a random allowed mutation\n    this.mutate(pickRandom(allowedMethods), options);\n  }\n\n  /**\n   * Train the given data to this network\n   *\n   * @param {TrainOptions} options Options used to train network\n   *\n   * @returns {{error:{number},iterations:{number},time:{number}}} A summary object of the network's performance\n   */\n  public train(\n    options: TrainOptions\n  ): {\n    /**\n     * The loss of the network after training.\n     */\n    error: number;\n    /**\n     * The iterations took for training the network.\n     */\n    iterations: number;\n    /**\n     * The time from begin to end in milliseconds\n     */\n    time: number;\n  } {\n    if (\n      options.dataset[0].input.length !== this.inputSize ||\n      options.dataset[0].output.length !== this.outputSize\n    ) {\n      throw new Error(\n        'Dataset input/output size should be same as network input/output size!'\n      );\n    }\n\n    const start: number = Date.now();\n\n    if (options.iterations <= 0 && options.error <= 0) {\n      throw new Error(\n        'At least one of the following options must be specified: error, iterations'\n      );\n    }\n\n    // Split into trainingSet and testSet if cross validation is enabled\n    let trainingSetSize: number;\n    let trainingSet: {\n      /**\n       * The input values of the dataset.\n       */\n      input: number[];\n      /**\n       * The output values of the dataset.\n       */\n      output: number[];\n    }[];\n    let testSet: {\n      /**\n       * The input values of the dataset.\n       */\n      input: number[];\n      /**\n       * The output values of the dataset.\n       */\n      output: number[];\n    }[];\n    if (options.crossValidateTestSize > 0) {\n      trainingSetSize = Math.ceil(\n        (1 - options.crossValidateTestSize) * options.dataset.length\n      );\n      trainingSet = options.dataset.slice(0, trainingSetSize);\n      testSet = options.dataset.slice(trainingSetSize);\n    } else {\n      trainingSet = options.dataset;\n      testSet = [];\n    }\n\n    let currentTrainingRate: number;\n    let iterationCount = 0;\n    let error = 1;\n\n    // train until the target error is reached or the target iterations are reached\n    while (\n      error > options.error &&\n      (options.iterations <= 0 || iterationCount < options.iterations)\n    ) {\n      iterationCount++;\n\n      // update the rate according to the rate policy\n      currentTrainingRate = options.rate.calc(iterationCount);\n\n      // train a single epoch\n      error = this.trainEpoch({\n        dataset: trainingSet,\n        batchSize: options.batchSize,\n        trainingRate: currentTrainingRate,\n        momentum: options.momentum,\n        loss: options.loss,\n        dropoutRate: options.dropout,\n      });\n\n      if (options.clear) {\n        this.clear();\n      }\n\n      // Run test with the testSet, if cross validation is enabled\n      if (options.crossValidateTestSize > 0) {\n        error = this.test(testSet, options.loss);\n        if (options.clear) {\n          this.clear();\n        }\n      }\n\n      if (options.shuffle) {\n        shuffle(options.dataset);\n      }\n\n      if (options.log > 0 && iterationCount % options.log === 0) {\n        console.log(\n          'iteration number',\n          iterationCount,\n          'error',\n          error,\n          'training rate',\n          currentTrainingRate\n        );\n      }\n\n      if (\n        options.schedule &&\n        iterationCount % options.schedule.iterations === 0\n      ) {\n        options.schedule.function(error, iterationCount);\n      }\n    }\n\n    if (options.clear) {\n      this.clear();\n    }\n\n    return {\n      error,\n      iterations: iterationCount,\n      time: Date.now() - start,\n    };\n  }\n\n  /**\n   * Tests a set and returns the error and elapsed time\n   *\n   * @param {Array<{input:number[],output:number[]}>} dataset A set of input values and ideal output values to test the network against\n   * @param {lossType} [loss=MSELoss] The [loss function](https://en.wikipedia.org/wiki/Loss_function) used to determine network error\n   *\n   * @returns {number} A summary object of the network's performance\n   */\n  public test(\n    dataset: {\n      /**\n       * The input values of the dataset.\n       */\n      input: number[];\n      /**\n       * The output values of the dataset.\n       */\n      output: number[];\n    }[],\n    loss: lossType = MSELoss\n  ): number {\n    let error = 0;\n\n    for (const entry of dataset) {\n      const input: number[] = entry.input;\n      const target: number[] = entry.output;\n      const output: number[] = this.activate(input, {trace: false});\n      error += loss(target, output);\n    }\n\n    return error / dataset.length;\n  }\n\n  /**\n   * Convert the network to a json object\n   *\n   * @returns {NetworkJSON} The network represented as a json object\n   */\n  public toJSON(): NetworkJSON {\n    const json: NetworkJSON = {\n      nodes: [],\n      connections: [],\n      inputSize: this.inputSize,\n      outputSize: this.outputSize,\n    };\n\n    // set node indices\n    for (let i = 0; i < this.nodes.length; i++) {\n      this.nodes[i].index = i;\n    }\n\n    // convert all nodes to json and add the to the json object\n    this.nodes.forEach(node => {\n      json.nodes.push(node.toJSON());\n\n      if (node.selfConnection.weight !== 0) {\n        // if there is a self connection\n        // add it to the json object\n        json.connections.push(node.selfConnection.toJSON());\n      }\n    });\n\n    this.connections.forEach(conn => {\n      json.connections.push(conn.toJSON());\n    });\n    return json;\n  }\n\n  /**\n   * Evolves the network to reach a lower error on a dataset using the [NEAT algorithm](http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf)\n   *\n   * If both `iterations` and `error` options are unset, evolve will default to `iterations` as an end condition.\n   *\n   * @param {object} [options] Configuration options\n   *\n   * @returns {{error:{number},iterations:{number},time:{number}}} A summary object of the network's performance. <br /> Properties include: `error` - error of the best genome, `iterations` - generations used to evolve networks, `time` - clock time elapsed while evolving\n   */\n  public async evolve(\n    options: EvolveOptions = new EvolveOptions()\n  ): Promise<{\n    /**\n     * The loss of the network after training.\n     */\n    error: number;\n    /**\n     * The iterations took for training the network.\n     */\n    iterations: number;\n    /**\n     * The time from begin to end in milliseconds\n     */\n    time: number;\n  }> {\n    if (\n      !options.fitnessFunction &&\n      options.dataset &&\n      (options.dataset[0].input.length !== this.inputSize ||\n        options.dataset[0].output.length !== this.outputSize)\n    ) {\n      throw new Error(\n        'Dataset input/output size should be same as network input/output size!'\n      );\n    }\n\n    // set options to default if necessary\n    options.input = this.inputSize;\n    options.output = this.outputSize;\n\n    const start: number = Date.now();\n\n    // tslint:disable-next-line:no-any\n    let workerPool: Pool<any> | null = null;\n\n    if (!options.fitnessFunction) {\n      // if no fitness function is given\n      // create default one\n\n      // Serialize the dataset using JSON\n      const serializedDataSet: string = JSON.stringify(options.dataset);\n      const lossIndex: number = Object.values(ALL_LOSSES).indexOf(options.loss);\n      // init a pool of workers\n      workerPool = Pool(\n        () => spawn<TestWorker>(new Worker('../multithreading/TestWorker')),\n        options.threads\n      );\n      options.fitnessFunction = async function (\n        population: Network[]\n      ): Promise<void> {\n        for (const genome of population) {\n          // add a task to the workerPool's queue\n          if (workerPool) {\n            workerPool.queue(async (test: TestWorker) => {\n              if (genome === undefined) {\n                throw new ReferenceError();\n              }\n              // test the genome\n              genome.score = -(await test(\n                serializedDataSet,\n                JSON.stringify(genome.toJSON()),\n                lossIndex\n              ));\n            });\n          }\n        }\n\n        if (workerPool) {\n          await workerPool.completed(); // wait until every task is done\n        }\n      };\n    }\n    options.template = this; // set this network as template for first generation\n\n    const neat: NEAT = new NEAT(options);\n\n    let error: number;\n    let bestFitness = 0;\n    let bestGenome: Network | null = null;\n\n    // run until error goal is reached or iteration goal is reached\n    do {\n      const fittest: Network = await neat.evolve(); // run one generation\n\n      if (!fittest.score) {\n        throw new ReferenceError();\n      }\n\n      error = fittest.score;\n\n      if (neat.options.generation === 1 || fittest.score > bestFitness) {\n        bestFitness = fittest.score;\n        bestGenome = fittest;\n      }\n\n      if (\n        options.schedule &&\n        neat.options.generation % options.schedule.iterations === 0\n      ) {\n        options.schedule.function(\n          fittest.score,\n          -error,\n          neat.options.generation\n        );\n      }\n    } while (\n      error < -options.error &&\n      (options.iterations === 0 || neat.options.generation < options.iterations)\n    );\n\n    if (bestGenome) {\n      // set this network to the fittest from NEAT\n      this.nodes = bestGenome.nodes;\n      this.connections = bestGenome.connections;\n      this.gates = bestGenome.gates;\n\n      if (options.clear) {\n        this.clear();\n      }\n    }\n\n    if (workerPool !== null) {\n      await workerPool.terminate(); // stop all processes\n    }\n\n    return {\n      error: -error,\n      iterations: neat.options.generation,\n      time: Date.now() - start,\n    };\n  }\n\n  /**\n   * Distance function\n   * @param g2 other network\n   * @param c1\n   * @param c2\n   * @param c3\n   */\n  public distance(g2: Network, c1: number, c2: number, c3: number): number {\n    // set node indices\n    for (let i = 0; i < this.nodes.length; i++) {\n      this.nodes[i].index = i;\n    }\n\n    // set node indices\n    for (let i = 0; i < g2.nodes.length; i++) {\n      g2.nodes[i].index = i;\n    }\n\n    let indexG1 = 0;\n    let indexG2 = 0;\n\n    const connections1: Connection[] = Array.from(this.connections).filter(\n      conn => conn !== undefined\n    );\n    const connections2: Connection[] = Array.from(g2.connections).filter(\n      conn => conn !== undefined\n    );\n\n    TimSort.sort(connections1, (a: Connection, b: Connection) => {\n      return a.getInnovationID() - b.getInnovationID();\n    });\n\n    TimSort.sort(connections2, (a: Connection, b: Connection) => {\n      return a.getInnovationID() - b.getInnovationID();\n    });\n\n    const highestInnovationID1: number = connections1[\n      connections1.length - 1\n    ].getInnovationID();\n    const highestInnovationID2: number = connections2[\n      connections2.length - 1\n    ].getInnovationID();\n    if (highestInnovationID1 < highestInnovationID2) {\n      return g2.distance(this, c1, c2, c3);\n    }\n\n    let disjointGenes = 0;\n    let totalWeightDiff = 0;\n    let similarGenes = 0;\n\n    while (indexG1 < connections1.length && indexG2 < connections2.length) {\n      const gene1: Connection = connections1[indexG1];\n      const gene2: Connection = connections2[indexG2];\n\n      if (gene1 === undefined || gene2 === undefined) {\n        throw Error('HERE');\n      }\n\n      const in1: number = gene1.getInnovationID();\n      const in2: number = gene2.getInnovationID();\n\n      if (in1 === in2) {\n        // similarGenes\n        indexG1++;\n        indexG2++;\n        totalWeightDiff += Math.abs(gene1.weight - gene2.weight);\n        similarGenes++;\n      } else if (indexG1 > indexG2) {\n        // disjoint of b\n        indexG2++;\n        disjointGenes++;\n      } else {\n        // disjoint of a\n        indexG1++;\n        disjointGenes++;\n      }\n    }\n    totalWeightDiff /= similarGenes;\n    const excessGenes: number = this.connections.size - indexG1;\n\n    let N: number = Math.max(this.connections.size, g2.connections.size);\n    if (N < 20) {\n      N = 1;\n    }\n\n    return (\n      (c1 * excessGenes) / N + (c2 * disjointGenes) / N + c3 * totalWeightDiff\n    );\n  }\n\n  /**\n   * Performs one training epoch and returns the error - this is a private function used in `self.train`\n   *\n   * @private\n   *\n   * @returns {number}\n   */\n  private trainEpoch(options: {\n    /**\n     * The dataset.\n     */\n    dataset: {\n      /**\n       * The input values of the dataset.\n       */\n      input: number[];\n      /**\n       * The output values of the dataset.\n       */\n      output: number[];\n    }[];\n    /**\n     * The batch size.\n     */\n    batchSize: number;\n    /**\n     * The training rate.\n     */\n    trainingRate: number;\n    /**\n     * The momentum.\n     */\n    momentum: number;\n    /**\n     * The loss function.\n     */\n    loss: lossType;\n    /**\n     * The dropout rate\n     */\n    dropoutRate: number;\n  }): number {\n    let errorSum = 0;\n    for (let i = 0; i < options.dataset.length; i++) {\n      const input: number[] = options.dataset[i].input;\n      const correctOutput: number[] = options.dataset[i].output;\n\n      const update: boolean =\n        (i + 1) % options.batchSize === 0 || i + 1 === options.dataset.length;\n\n      const output: number[] = this.activate(input, {\n        dropoutRate: options.dropoutRate,\n      });\n      this.propagate(correctOutput, {\n        rate: options.trainingRate,\n        momentum: options.momentum,\n        update,\n      });\n\n      errorSum += options.loss(correctOutput, output);\n    }\n    return errorSum / options.dataset.length;\n  }\n}\n","import {ConnectionType} from '../enums/ConnectionType';\nimport {InputLayer} from './Layers/CoreLayers/InputLayer';\nimport {OutputLayer} from './Layers/CoreLayers/OutputLayer';\nimport {Layer} from './Layers/Layer';\nimport {Network} from './Network';\n\n/**\n * Architect constructs multilayer networks with various types of layers.\n */\nexport class Architect {\n  /**\n   * Array with all layers and there incoming connection type\n   */\n  private readonly layers: {\n    /**\n     * The Layer\n     */\n    layer: Layer;\n    /**\n     * The incoming connection type for this layer\n     */\n    incomingConnectionType: ConnectionType;\n  }[];\n\n  constructor() {\n    this.layers = [];\n  }\n\n  /**\n   * Adds a layer to the architect.\n   *\n   * @param layer The layer\n   * @param incomingConnectionType The incoming connection to this layer\n   * @returns this object to function as builder class\n   */\n  public addLayer(\n    layer: Layer,\n    incomingConnectionType?: ConnectionType\n  ): Architect {\n    const connectionType: ConnectionType =\n      incomingConnectionType ?? layer.getDefaultIncomingConnectionType();\n\n    if (!layer.connectionTypeisAllowed(connectionType)) {\n      throw new ReferenceError(\n        'Connection type ' +\n          connectionType +\n          ' is not allowed at layer ' +\n          layer.constructor.name\n      );\n    }\n\n    this.layers.push({\n      layer,\n      incomingConnectionType: connectionType,\n    });\n    return this; // function as builder class\n  }\n\n  /**\n   * Build the network from the layers added to the architect.\n   *\n   * @returns the constructed network\n   */\n  public buildModel(): Network {\n    if (!(this.layers[0].layer instanceof InputLayer)) {\n      throw new ReferenceError(\n        'First layer has to be a InputLayer! Currently is: ' +\n          this.layers[0].layer.constructor.name\n      );\n    }\n    if (!(this.layers[this.layers.length - 1].layer instanceof OutputLayer)) {\n      throw new ReferenceError(\n        'Last layer has to be a OutputLayer! Currently is: ' +\n          this.layers[this.layers.length - 1].layer.constructor.name\n      );\n    }\n\n    const inputSize: number = this.layers[0].layer.nodes.length;\n    const outputSize: number = this.layers[this.layers.length - 1].layer.nodes\n      .length;\n\n    const network: Network = new Network(inputSize, outputSize);\n    network.nodes = [];\n    network.connections.clear();\n\n    for (let i = 0; i < this.layers.length - 1; i++) {\n      Layer.connect(\n        this.layers[i].layer,\n        this.layers[i + 1].layer,\n        this.layers[i + 1].incomingConnectionType\n      ).forEach(conn => network.connections.add(conn));\n\n      network.nodes.push(...this.layers[i].layer.nodes);\n      this.layers[i].layer.connections.forEach(conn =>\n        network.connections.add(conn)\n      );\n      this.layers[i].layer.gates.forEach(conn => network.gates.add(conn));\n    }\n    network.nodes.push(...this.layers[this.layers.length - 1].layer.nodes);\n    return network;\n  }\n}\n","import {sum} from '../../utils/Utils';\nimport {ConstantNode} from './ConstantNode';\n\n/**\n * Activation node\n */\nexport class ActivationNode extends ConstantNode {\n  constructor() {\n    super();\n  }\n\n  /**\n   * Actives the node.\n   *\n   * When a neuron activates, it computes its state from all its input connections and 'squashes' it using its activation function, and returns the output (activation).\n   *\n   * You can also provide the activation (a float between 0 and 1) as a parameter, which is useful for neurons in the input layer.\n   *\n   * @returns A neuron's output value\n   */\n  public activate(): number {\n    this.old = this.state;\n\n    const incomingStates: number[] = Array.from(this.incoming).map(\n      conn => conn.from.activation * conn.weight * conn.gain\n    );\n\n    if (incomingStates.length !== 1) {\n      throw new ReferenceError('Only 1 incoming connections is allowed!');\n    }\n\n    this.state = incomingStates[0];\n\n    this.activation = this.squash(this.state, false) * this.mask;\n    this.derivativeState = this.squash(this.state, true);\n\n    return this.activation;\n  }\n\n  /**\n   * Backpropagate the error (a.k.a. learn).\n   *\n   * After an activation, you can teach the node what should have been the correct output (a.k.a. train). This is done by backpropagating. [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html) adds a fraction of the previous weight update to the current one. When the gradient keeps pointing in the same direction, this will increase the size of the steps taken towards the minimum.\n   *\n   * If you combine a high learning rate with a lot of momentum, you will rush past the minimum (of the error function) with huge steps. It is therefore often necessary to reduce the global learning rate µ when using a lot of momentum (m close to 1).\n   *\n   * @param target The target value (i.e. \"the value the network SHOULD have given\")\n   * @param options More options for propagation\n   */\n  public propagate(\n    target: number,\n    options: {\n      /**\n       * [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html) adds a fraction of the previous weight update to the current one.\n       */\n      momentum?: number;\n      /**\n       * [Learning rate](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10)\n       */\n      rate?: number;\n      /**\n       * When set to false weights won't update, but when set to true after being false the last propagation will include the delta weights of the first \"update:false\" propagations too.\n       */\n      update?: boolean;\n    }\n  ): void {\n    options.momentum = options.momentum ?? 0;\n    options.rate = options.rate ?? 0.3;\n    options.update = options.update ?? true;\n\n    const connectionsStates: number[] = Array.from(this.outgoing).map(\n      conn => conn.to.errorResponsibility * conn.weight * conn.gain\n    );\n    this.errorResponsibility = this.errorProjected =\n      sum(connectionsStates) * this.derivativeState;\n\n    this.incoming.forEach(connection => {\n      // calculate gradient\n      let gradient: number = this.errorProjected * connection.eligibility;\n      connection.xTrace.forEach((value, key) => {\n        gradient += key.errorResponsibility * value;\n      });\n\n      connection.deltaWeightsTotal +=\n        (options.rate ?? 0.3) * gradient * this.mask;\n      if (options.update) {\n        connection.deltaWeightsTotal +=\n          (options.momentum ?? 0) * connection.deltaWeightsPrevious;\n        connection.weight += connection.deltaWeightsTotal;\n        connection.deltaWeightsPrevious = connection.deltaWeightsTotal;\n        connection.deltaWeightsTotal = 0;\n      }\n    });\n  }\n}\n","import {ActivationType, Logistic} from 'activations/build/src';\nimport {ConnectionType} from '../../../enums/ConnectionType';\nimport {ActivationNode} from '../../Nodes/ActivationNode';\nimport {Layer} from '../Layer';\n\n/**\n * Activation layer\n */\nexport class ActivationLayer extends Layer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n    } = {}\n  ) {\n    super(outputSize);\n\n    const activation: ActivationType = options.activation ?? Logistic;\n\n    for (let i = 0; i < outputSize; i++) {\n      this.inputNodes.add(new ActivationNode().setActivationType(activation));\n    }\n\n    this.outputNodes = this.inputNodes;\n    this.nodes.push(...Array.from(this.inputNodes));\n  }\n\n  /**\n   * Checks if a given connection type is allowed on this layer.\n   *\n   * @param type the type to check\n   *\n   * @return Is this connection type allowed?\n   */\n  public connectionTypeisAllowed(type: ConnectionType): boolean {\n    return type === ConnectionType.ONE_TO_ONE;\n  }\n\n  /**\n   * Gets the default connection type for a incoming connection to this layer.\n   *\n   * @returns the default incoming connection\n   */\n  public getDefaultIncomingConnectionType(): ConnectionType {\n    return ConnectionType.ONE_TO_ONE;\n  }\n}\n","import {ActivationType, Logistic} from 'activations/build/src';\nimport {ConnectionType} from '../../../enums/ConnectionType';\nimport {NodeType} from '../../../enums/NodeType';\nimport {Node} from '../../Node';\nimport {Layer} from '../Layer';\n\n/**\n * Dense layer\n */\nexport class DenseLayer extends Layer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activationType?: ActivationType;\n    } = {}\n  ) {\n    super(outputSize);\n\n    const activation: ActivationType = options.activationType ?? Logistic;\n\n    for (let i = 0; i < outputSize; i++) {\n      this.inputNodes.add(\n        new Node(NodeType.HIDDEN).setActivationType(activation)\n      );\n    }\n\n    this.outputNodes = this.inputNodes;\n    this.nodes.push(...Array.from(this.inputNodes));\n  }\n\n  /**\n   * Checks if a given connection type is allowed on this layer.\n   *\n   * @return Is this connection type allowed?\n   */\n  public connectionTypeisAllowed(): boolean {\n    return true;\n  }\n\n  /**\n   * Gets the default connection type for a incoming connection to this layer.\n   *\n   * @returns the default incoming connection\n   */\n  public getDefaultIncomingConnectionType(): ConnectionType {\n    return ConnectionType.ALL_TO_ALL;\n  }\n}\n","import {DropoutNodeJSON} from '../../interfaces/NodeJSON';\nimport {randDouble, sum} from '../../utils/Utils';\nimport {Connection} from '../Connection';\nimport {ConstantNode} from './ConstantNode';\n\n/**\n * Dropout node\n */\nexport class DropoutNode extends ConstantNode {\n  /**\n   * Dropout probability\n   */\n  private probability: number;\n  /**\n   * Is dropped out at last activation?\n   */\n  private droppedOut: boolean;\n\n  constructor(probability: number) {\n    super();\n    this.probability = probability;\n    this.droppedOut = false;\n  }\n\n  /**\n   * Actives the node.\n   *\n   * When a neuron activates, it computes its state from all its input connections and 'squashes' it using its activation function, and returns the output (activation).\n   *\n   * You can also provide the activation (a float between 0 and 1) as a parameter, which is useful for neurons in the input layer.\n   *\n   * @returns A neuron's output value\n   */\n  public activate(): number {\n    if (this.incoming.size !== 1) {\n      throw new RangeError(\n        'Dropout node should have exactly one incoming connection!'\n      );\n    }\n    const incomingConnection: Connection = Array.from(this.incoming)[0];\n\n    // https://stats.stackexchange.com/a/219240\n    if (randDouble(0, 1) < this.probability) {\n      // DROPOUT\n      this.droppedOut = true;\n      this.state = 0;\n    } else {\n      this.droppedOut = false;\n      this.state =\n        incomingConnection.from.activation *\n        incomingConnection.weight *\n        incomingConnection.gain;\n      this.state *= 1 / (1 - this.probability);\n    }\n    this.activation = this.squash(this.state, false) * this.mask;\n\n    // Adjust gain\n    this.gated.forEach(conn => (conn.gain = this.activation));\n\n    return this.activation;\n  }\n\n  /**\n   * Backpropagate the error (a.k.a. learn).\n   *\n   * After an activation, you can teach the node what should have been the correct output (a.k.a. train). This is done by backpropagating. [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html) adds a fraction of the previous weight update to the current one. When the gradient keeps pointing in the same direction, this will increase the size of the steps taken towards the minimum.\n   *\n   * If you combine a high learning rate with a lot of momentum, you will rush past the minimum (of the error function) with huge steps. It is therefore often necessary to reduce the global learning rate µ when using a lot of momentum (m close to 1).\n   *\n   * @param target The target value (i.e. \"the value the network SHOULD have given\")\n   * @param options More options for propagation\n   */\n  public propagate(\n    target?: number,\n    options: {\n      /**\n       * [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html) adds a fraction of the previous weight update to the current one.\n       */\n      momentum?: number;\n      /**\n       * [Learning rate](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10)\n       */\n      rate?: number;\n      /**\n       * When set to false weights won't update, but when set to true after being false the last propagation will include the delta weights of the first \"update:false\" propagations too.\n       */\n      update?: boolean;\n    } = {}\n  ): void {\n    options.momentum = options.momentum ?? 0;\n    options.rate = options.rate ?? 0.3;\n    options.update = options.update ?? true;\n\n    const connectionsStates: number[] = Array.from(this.outgoing).map(\n      conn => conn.to.errorResponsibility * conn.weight * conn.gain\n    );\n    this.errorResponsibility = this.errorProjected =\n      sum(connectionsStates) / (1 - this.probability);\n\n    if (this.incoming.size !== 1) {\n      throw new RangeError(\n        'Dropout node should have exactly one incoming connection!'\n      );\n    }\n    const connection: Connection = Array.from(this.incoming)[0];\n\n    // calculate gradient\n    if (!this.droppedOut) {\n      let gradient: number = this.errorProjected * connection.eligibility;\n\n      connection.xTrace.forEach((value, key) => {\n        gradient += key.errorResponsibility * value;\n      });\n\n      if (options.update) {\n        connection.deltaWeightsTotal +=\n          options.rate * gradient * this.mask +\n          options.momentum * connection.deltaWeightsPrevious;\n        connection.weight += connection.deltaWeightsTotal;\n        connection.deltaWeightsPrevious = connection.deltaWeightsTotal;\n        connection.deltaWeightsTotal = 0;\n      }\n    }\n  }\n\n  /**\n   * Create a constant node from json object.\n   *\n   * @param json the json object representing the node\n   *\n   * @returns the created node\n   */\n  public fromJSON(json: DropoutNodeJSON): DropoutNode {\n    super.fromJSON(json);\n    this.probability = json.probability;\n    return this;\n  }\n\n  /**\n   * Convert this node into a json object.\n   *\n   * @returns the json object representing this node\n   */\n  public toJSON(): DropoutNodeJSON {\n    return Object.assign(super.toJSON(), {\n      probability: this.probability,\n    });\n  }\n}\n","import {ActivationType, Identitiy} from 'activations/build/src';\nimport {ConnectionType} from '../../../enums/ConnectionType';\nimport {DropoutNode} from '../../Nodes/DropoutNode';\nimport {Layer} from '../Layer';\n\n/**\n * Dropout layer\n */\nexport class DropoutLayer extends Layer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n      /**\n       * The dropout probability\n       */\n      probability?: number;\n    } = {}\n  ) {\n    super(outputSize);\n\n    const activation: ActivationType = options.activation ?? Identitiy;\n    const probability: number = options.probability ?? 0.1;\n\n    for (let i = 0; i < outputSize; i++) {\n      this.inputNodes.add(\n        new DropoutNode(probability).setActivationType(activation)\n      );\n    }\n\n    this.outputNodes = this.inputNodes;\n    this.nodes.push(...Array.from(this.inputNodes));\n  }\n\n  /**\n   * Gets the default connection type for a incoming connection to this layer.\n   *\n   * @returns the default incoming connection\n   */\n  public getDefaultIncomingConnectionType(): ConnectionType {\n    return ConnectionType.ONE_TO_ONE;\n  }\n\n  /**\n   * Checks if a given connection type is allowed on this layer.\n   *\n   * @param type the type to check\n   *\n   * @return Is this connection type allowed?\n   */\n  public connectionTypeisAllowed(type: ConnectionType): boolean {\n    return type === ConnectionType.ONE_TO_ONE;\n  }\n}\n","import {PoolNodeType} from '../../enums/NodeType';\nimport {PoolNodeJSON} from '../../interfaces/NodeJSON';\nimport {avg, maxValueIndex, minValueIndex, sum} from '../../utils/Utils';\nimport {Connection} from '../Connection';\nimport {Node} from '../Node';\nimport {ConstantNode} from './ConstantNode';\n\n/**\n * Pool node\n */\nexport class PoolNode extends ConstantNode {\n  /**\n   * The type of pooling\n   */\n  private poolingType: PoolNodeType;\n  /**\n   * The used input neuron\n   */\n  private receivingNode: Node | null;\n\n  constructor(poolingType: PoolNodeType = PoolNodeType.MAX_POOLING) {\n    super();\n    this.poolingType = poolingType;\n    this.receivingNode = null;\n  }\n\n  /**\n   * Create a constant node from json object.\n   *\n   * @param json the json object representing the node\n   *\n   * @returns the created node\n   */\n  public fromJSON(json: PoolNodeJSON): PoolNode {\n    super.fromJSON(json);\n    this.poolingType = json.poolType;\n    return this;\n  }\n\n  /**\n   * Actives the node.\n   *\n   * When a neuron activates, it computes its state from all its input connections and 'squashes' it using its activation function, and returns the output (activation).\n   *\n   * You can also provide the activation (a float between 0 and 1) as a parameter, which is useful for neurons in the input layer.\n   *\n   * @returns A neuron's output value\n   */\n  public activate(): number {\n    const connections: Connection[] = Array.from(this.incoming);\n    const incomingStates: number[] = connections.map(\n      conn => conn.from.activation * conn.weight * conn.gain\n    );\n\n    if (this.poolingType === PoolNodeType.MAX_POOLING) {\n      const index: number = maxValueIndex(incomingStates);\n      this.receivingNode = connections[index].from;\n      this.state = incomingStates[index];\n    } else if (this.poolingType === PoolNodeType.AVG_POOLING) {\n      this.state = avg(incomingStates);\n    } else if (this.poolingType === PoolNodeType.MIN_POOLING) {\n      const index: number = minValueIndex(incomingStates);\n      this.receivingNode = connections[index].from;\n      this.state = incomingStates[index];\n    } else {\n      throw new ReferenceError(\n        'No valid pooling type! Type: ' + this.poolingType\n      );\n    }\n\n    this.activation = this.squash(this.state, false) * this.mask;\n    if (this.poolingType === PoolNodeType.AVG_POOLING) {\n      this.derivativeState = this.squash(this.state, true);\n    }\n\n    // Adjust gain\n    this.gated.forEach(conn => (conn.gain = this.activation));\n\n    return this.activation;\n  }\n\n  /**\n   * Backpropagate the error (a.k.a. learn).\n   *\n   * After an activation, you can teach the node what should have been the correct output (a.k.a. train). This is done by backpropagating. [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html) adds a fraction of the previous weight update to the current one. When the gradient keeps pointing in the same direction, this will increase the size of the steps taken towards the minimum.\n   *\n   * If you combine a high learning rate with a lot of momentum, you will rush past the minimum (of the error function) with huge steps. It is therefore often necessary to reduce the global learning rate µ when using a lot of momentum (m close to 1).\n   *\n   * @param target The target value (i.e. \"the value the network SHOULD have given\")\n   * @param options More options for propagation\n   */\n  public propagate(\n    target?: number,\n    options: {\n      /**\n       * [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html) adds a fraction of the previous weight update to the current one.\n       */\n      momentum?: number;\n      /**\n       * [Learning rate](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10)\n       */\n      rate?: number;\n      /**\n       * When set to false weights won't update, but when set to true after being false the last propagation will include the delta weights of the first \"update:false\" propagations too.\n       */\n      update?: boolean;\n    } = {}\n  ): void {\n    options.momentum = options.momentum ?? 0;\n    options.rate = options.rate ?? 0.3;\n    options.update = options.update ?? true;\n\n    const connectionsStates: number[] = Array.from(this.outgoing).map(\n      conn => conn.to.errorResponsibility * conn.weight * conn.gain\n    );\n    this.errorResponsibility = this.errorProjected =\n      sum(connectionsStates) * this.derivativeState;\n    if (this.poolingType === PoolNodeType.AVG_POOLING) {\n      this.incoming.forEach(connection => {\n        // calculate gradient\n        let gradient: number = this.errorProjected * connection.eligibility;\n        connection.xTrace.forEach((value, key) => {\n          gradient += key.errorResponsibility * value;\n        });\n\n        connection.deltaWeightsTotal +=\n          (options.rate ?? 0.3) * gradient * this.mask;\n        if (options.update) {\n          connection.deltaWeightsTotal +=\n            (options.momentum ?? 0) * connection.deltaWeightsPrevious;\n          connection.weight += connection.deltaWeightsTotal;\n          connection.deltaWeightsPrevious = connection.deltaWeightsTotal;\n          connection.deltaWeightsTotal = 0;\n        }\n      });\n    } else {\n      // TODO: don't think that this is correct\n      // Passing only the connections that were used for getting the min or max\n      this.incoming.forEach(conn => {\n        conn.weight = this.receivingNode === conn.from ? 1 : 0;\n        conn.gain = this.receivingNode === conn.from ? 1 : 0;\n      });\n    }\n  }\n\n  /**\n   * Convert this node into a json object.\n   *\n   * @returns the json object representing this node\n   */\n  public toJSON(): PoolNodeJSON {\n    return Object.assign(super.toJSON(), {\n      poolType: this.poolingType,\n    });\n  }\n}\n","import {ConnectionType} from '../../../enums/ConnectionType';\nimport {Layer} from '../Layer';\n\n/**\n * Parent class for all pooling layers\n */\nexport abstract class PoolingLayer extends Layer {\n  protected constructor(outputSize: number) {\n    super(outputSize);\n  }\n\n  /**\n   * Gets the default connection type for a incoming connection to this layer.\n   *\n   * @returns the default incoming connection\n   */\n  public getDefaultIncomingConnectionType(): ConnectionType {\n    return ConnectionType.POOLING;\n  }\n\n  /**\n   * Checks if a given connection type is allowed on this layer.\n   *\n   * @return Is this connection type allowed?\n   */\n  public connectionTypeisAllowed(): boolean {\n    return true;\n  }\n}\n","import {ActivationType, Identitiy} from 'activations/build/src';\nimport {PoolNodeType} from '../../../enums/NodeType';\nimport {PoolNode} from '../../Nodes/PoolNode';\nimport {PoolingLayer} from './PoolingLayer';\n\n/**\n * Average pooling layer 1D\n */\nexport class AvgPooling1DLayer extends PoolingLayer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n    } = {}\n  ) {\n    super(outputSize);\n\n    const activationType: ActivationType = options.activation ?? Identitiy;\n\n    for (let i = 0; i < outputSize; i++) {\n      this.inputNodes.add(\n        new PoolNode(PoolNodeType.AVG_POOLING).setActivationType(activationType)\n      );\n    }\n\n    this.outputNodes = this.inputNodes;\n    this.nodes.push(...Array.from(this.inputNodes));\n  }\n}\n","import {ActivationType} from 'activations/build/src';\nimport {AvgPooling1DLayer} from './AvgPooling1DLayer';\n\n/**\n * Global average pooling layer 1D\n */\nexport class GlobalAvgPooling1DLayer extends AvgPooling1DLayer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n    } = {}\n  ) {\n    super(1, options);\n  }\n}\n","import {ActivationType, Identitiy} from 'activations/build/src';\nimport {PoolNodeType} from '../../../enums/NodeType';\nimport {PoolNode} from '../../Nodes/PoolNode';\nimport {PoolingLayer} from './PoolingLayer';\n\n/**\n * Maximum pooling layer 1D\n */\nexport class MaxPooling1DLayer extends PoolingLayer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n    } = {}\n  ) {\n    super(outputSize);\n\n    const activationType: ActivationType = options.activation ?? Identitiy;\n\n    for (let i = 0; i < outputSize; i++) {\n      this.inputNodes.add(\n        new PoolNode(PoolNodeType.MAX_POOLING).setActivationType(activationType)\n      );\n    }\n\n    this.outputNodes = this.inputNodes;\n    this.nodes.push(...Array.from(this.inputNodes));\n  }\n}\n","import {ActivationType} from 'activations/build/src';\nimport {MaxPooling1DLayer} from './MaxPooling1DLayer';\n\n/**\n * Global maximum pooling layer 1D\n */\nexport class GlobalMaxPooling1DLayer extends MaxPooling1DLayer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n    } = {}\n  ) {\n    super(1, options);\n  }\n}\n","import {ActivationType, Identitiy} from 'activations/build/src';\nimport {PoolNodeType} from '../../../enums/NodeType';\nimport {PoolNode} from '../../Nodes/PoolNode';\nimport {PoolingLayer} from './PoolingLayer';\n\n/**\n * Minimum pooling layer 1D\n */\nexport class MinPooling1DLayer extends PoolingLayer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n    } = {}\n  ) {\n    super(outputSize);\n\n    const activationType: ActivationType = options.activation ?? Identitiy;\n\n    for (let i = 0; i < outputSize; i++) {\n      this.inputNodes.add(\n        new PoolNode(PoolNodeType.MIN_POOLING).setActivationType(activationType)\n      );\n    }\n\n    this.outputNodes = this.inputNodes;\n    this.nodes.push(...Array.from(this.inputNodes));\n  }\n}\n","import {ActivationType} from 'activations/build/src';\nimport {MinPooling1DLayer} from './MinPooling1DLayer';\n\n/**\n * Global minimum pooling layer 1D\n */\nexport class GlobalMinPooling1DLayer extends MinPooling1DLayer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n    } = {}\n  ) {\n    super(1, options);\n  }\n}\n","import {ActivationType, Logistic, TANH} from 'activations/build/src';\nimport {ConnectionType} from '../../../enums/ConnectionType';\nimport {GatingType} from '../../../enums/GatingType';\nimport {NodeType} from '../../../enums/NodeType';\nimport {Connection} from '../../Connection';\nimport {Node} from '../../Node';\nimport {Layer} from '../Layer';\n\n/**\n * GRU layer\n */\nexport class GRULayer extends Layer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n    } = {}\n  ) {\n    super(outputSize);\n    const updateGate: Node[] = [];\n    const inverseUpdateGate: Node[] = [];\n    const resetGate: Node[] = [];\n    const memoryCell: Node[] = [];\n    const previousOutput: Node[] = [];\n\n    for (let i = 0; i < outputSize; i++) {\n      this.inputNodes.add(new Node(NodeType.HIDDEN));\n      updateGate.push(new Node(NodeType.HIDDEN).setBias(1));\n      inverseUpdateGate.push(\n        new Node(NodeType.HIDDEN).setBias(0).setActivationType(Logistic)\n      );\n      resetGate.push(new Node(NodeType.HIDDEN).setBias(0));\n      memoryCell.push(new Node(NodeType.HIDDEN).setActivationType(TANH));\n      previousOutput.push(\n        new Node(NodeType.HIDDEN).setBias(0).setActivationType(Logistic)\n      );\n      this.outputNodes.add(new Node(NodeType.HIDDEN));\n    }\n\n    this.connections.push(\n      ...Layer.connect(this.inputNodes, updateGate, ConnectionType.ALL_TO_ALL)\n    );\n    this.connections.push(\n      ...Layer.connect(this.inputNodes, resetGate, ConnectionType.ALL_TO_ALL)\n    );\n    this.connections.push(\n      ...Layer.connect(this.inputNodes, memoryCell, ConnectionType.ALL_TO_ALL)\n    );\n\n    this.connections.push(\n      ...Layer.connect(previousOutput, updateGate, ConnectionType.ALL_TO_ALL)\n    );\n\n    this.connections.push(\n      ...Layer.connect(\n        updateGate,\n        inverseUpdateGate,\n        ConnectionType.ONE_TO_ONE,\n        1\n      )\n    );\n\n    this.connections.push(\n      ...Layer.connect(previousOutput, resetGate, ConnectionType.ALL_TO_ALL)\n    );\n\n    const reset: Connection[] = Layer.connect(\n      previousOutput,\n      memoryCell,\n      ConnectionType.ALL_TO_ALL\n    );\n    this.connections.push(...reset);\n    this.gates.push(...Layer.gate(resetGate, reset, GatingType.OUTPUT));\n\n    const update: Connection[] = Layer.connect(\n      previousOutput,\n      this.outputNodes,\n      ConnectionType.ALL_TO_ALL\n    );\n    const inverseUpdate: Connection[] = Layer.connect(\n      memoryCell,\n      this.outputNodes,\n      ConnectionType.ALL_TO_ALL\n    );\n    this.connections.push(...update);\n    this.connections.push(...inverseUpdate);\n\n    this.gates.push(...Layer.gate(updateGate, update, GatingType.OUTPUT));\n    this.gates.push(\n      ...Layer.gate(inverseUpdateGate, inverseUpdate, GatingType.OUTPUT)\n    );\n\n    this.connections.push(\n      ...Layer.connect(\n        this.outputNodes,\n        previousOutput,\n        ConnectionType.ONE_TO_ONE,\n        1\n      )\n    );\n\n    this.nodes.push(...Array.from(this.inputNodes));\n    this.nodes.push(...updateGate);\n    this.nodes.push(...inverseUpdateGate);\n    this.nodes.push(...resetGate);\n    this.nodes.push(...memoryCell);\n    this.nodes.push(...Array.from(this.outputNodes));\n    this.nodes.push(...previousOutput);\n\n    this.outputNodes.forEach(\n      node => (node.squash = options.activation ?? Logistic)\n    );\n  }\n\n  /**\n   * Checks if a given connection type is allowed on this layer.\n   *\n   * @return Is this connection type allowed?\n   */\n  public connectionTypeisAllowed(): boolean {\n    return true;\n  }\n\n  /**\n   * Gets the default connection type for a incoming connection to this layer.\n   *\n   * @returns the default incoming connection\n   */\n  public getDefaultIncomingConnectionType(): ConnectionType {\n    return ConnectionType.ALL_TO_ALL;\n  }\n}\n","import {BinaryStep} from 'activations/build/src';\nimport {ConnectionType} from '../../../enums/ConnectionType';\nimport {NodeType} from '../../../enums/NodeType';\nimport {Node} from '../../Node';\nimport {Layer} from '../Layer';\n\n/**\n * Hopfield layer\n */\nexport class HopfieldLayer extends Layer {\n  constructor(outputSize: number) {\n    super(outputSize);\n\n    for (let i = 0; i < outputSize; i++) {\n      this.inputNodes.add(new Node(NodeType.HIDDEN));\n      this.outputNodes.add(\n        new Node(NodeType.HIDDEN).setActivationType(BinaryStep)\n      );\n    }\n\n    this.connections.push(\n      ...Layer.connect(\n        this.inputNodes,\n        this.outputNodes,\n        ConnectionType.ALL_TO_ALL\n      )\n    );\n    this.connections.push(\n      ...Layer.connect(\n        this.outputNodes,\n        this.inputNodes,\n        ConnectionType.ALL_TO_ALL\n      )\n    );\n\n    this.nodes.push(...Array.from(this.inputNodes));\n    this.nodes.push(...Array.from(this.outputNodes));\n  }\n\n  /**\n   * Checks if a given connection type is allowed on this layer.\n   *\n   * @return Is this connection type allowed?\n   */\n  public connectionTypeisAllowed(): boolean {\n    return true;\n  }\n\n  /**\n   * Gets the default connection type for a incoming connection to this layer.\n   *\n   * @returns the default incoming connection\n   */\n  public getDefaultIncomingConnectionType(): ConnectionType {\n    return ConnectionType.ALL_TO_ALL;\n  }\n}\n","import {ActivationType, Logistic, TANH} from 'activations/build/src';\nimport {ConnectionType} from '../../../enums/ConnectionType';\nimport {GatingType} from '../../../enums/GatingType';\nimport {NodeType} from '../../../enums/NodeType';\nimport {Connection} from '../../Connection';\nimport {Node} from '../../Node';\nimport {Layer} from '../Layer';\n\n/**\n * LSTM layer\n */\nexport class LSTMLayer extends Layer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n    } = {}\n  ) {\n    super(outputSize);\n\n    const inputGate: Node[] = [];\n    const forgetGate: Node[] = [];\n    const memoryCell: Node[] = [];\n    const outputGate: Node[] = [];\n\n    for (let i = 0; i < outputSize; i++) {\n      this.inputNodes.add(new Node(NodeType.HIDDEN));\n      inputGate.push(new Node(NodeType.HIDDEN).setBias(1));\n      forgetGate.push(\n        new Node(NodeType.HIDDEN).setBias(1).setActivationType(Logistic)\n      );\n      memoryCell.push(new Node(NodeType.HIDDEN));\n      outputGate.push(new Node(NodeType.HIDDEN).setBias(1));\n      this.outputNodes.add(new Node(NodeType.HIDDEN));\n    }\n\n    this.connections.push(\n      ...Layer.connect(memoryCell, inputGate, ConnectionType.ALL_TO_ALL)\n    );\n    this.connections.push(\n      ...Layer.connect(memoryCell, forgetGate, ConnectionType.ALL_TO_ALL)\n    );\n    this.connections.push(\n      ...Layer.connect(memoryCell, outputGate, ConnectionType.ALL_TO_ALL)\n    );\n    const forgetGateConnections: Connection[] = Layer.connect(\n      memoryCell,\n      memoryCell,\n      ConnectionType.ONE_TO_ONE\n    );\n    const outputGateConnections: Connection[] = Layer.connect(\n      memoryCell,\n      this.outputNodes,\n      ConnectionType.ALL_TO_ALL\n    );\n    this.connections.push(...forgetGateConnections);\n    this.connections.push(...outputGateConnections);\n\n    this.connections.push(\n      ...Layer.connect(this.inputNodes, memoryCell, ConnectionType.ALL_TO_ALL)\n    );\n    this.connections.push(\n      ...Layer.connect(this.inputNodes, outputGate, ConnectionType.ALL_TO_ALL)\n    );\n    this.connections.push(\n      ...Layer.connect(this.inputNodes, forgetGate, ConnectionType.ALL_TO_ALL)\n    );\n    const inputGateConnections: Connection[] = Layer.connect(\n      this.inputNodes,\n      inputGate,\n      ConnectionType.ALL_TO_ALL\n    );\n    this.connections.push(...inputGateConnections);\n\n    this.gates.push(\n      ...Layer.gate(forgetGate, forgetGateConnections, GatingType.SELF)\n    );\n    this.gates.push(\n      ...Layer.gate(outputGate, outputGateConnections, GatingType.OUTPUT)\n    );\n    this.gates.push(\n      ...Layer.gate(inputGate, inputGateConnections, GatingType.INPUT)\n    );\n\n    this.nodes.push(...Array.from(this.inputNodes));\n    this.nodes.push(...inputGate);\n    this.nodes.push(...forgetGate);\n    this.nodes.push(...memoryCell);\n    this.nodes.push(...outputGate);\n    this.nodes.push(...Array.from(this.outputNodes));\n\n    this.outputNodes.forEach(\n      node => (node.squash = options.activation ?? TANH)\n    );\n  }\n\n  /**\n   * Checks if a given connection type is allowed on this layer.\n   *\n   * @return Is this connection type allowed?\n   */\n  public connectionTypeisAllowed(): boolean {\n    return true;\n  }\n\n  /**\n   * Gets the default connection type for a incoming connection to this layer.\n   *\n   * @returns the default incoming connection\n   */\n  public getDefaultIncomingConnectionType(): ConnectionType {\n    return ConnectionType.ALL_TO_ALL;\n  }\n}\n","import {ActivationType, Identitiy, Logistic} from 'activations/build/src';\nimport {ConnectionType} from '../../../enums/ConnectionType';\nimport {NodeType} from '../../../enums/NodeType';\nimport {Node} from '../../Node';\nimport {Layer} from '../Layer';\n\n/**\n * Memory layer\n */\nexport class MemoryLayer extends Layer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n      /**\n       * The size of the memory.\n       */\n      memorySize?: number;\n    } = {}\n  ) {\n    super(outputSize);\n\n    for (let i = 0; i < outputSize; i++) {\n      this.inputNodes.add(new Node(NodeType.HIDDEN));\n    }\n\n    let prevNodes: Node[] = Array.from(this.inputNodes);\n    const nodes: Node[] = [];\n    for (let i = 0; i < (options.memorySize ?? 1); i++) {\n      const block: Node[] = [];\n      for (let j = 0; j < outputSize; j++) {\n        const node: Node = new Node(NodeType.HIDDEN);\n        node.squash = Identitiy;\n        node.bias = 0;\n        block.push(node);\n      }\n\n      this.connections.push(\n        ...Layer.connect(prevNodes, block, ConnectionType.ONE_TO_ONE)\n      );\n      nodes.push(...block);\n      prevNodes = block;\n    }\n\n    this.nodes.push(...Array.from(this.inputNodes));\n    this.nodes.push(...nodes.reverse());\n    prevNodes.forEach(node => this.outputNodes.add(node));\n\n    this.outputNodes.forEach(\n      node => (node.squash = options.activation ?? Logistic)\n    );\n  }\n\n  /**\n   * Checks if a given connection type is allowed on this layer.\n   *\n   * @return Is this connection type allowed?\n   */\n  public connectionTypeisAllowed(): boolean {\n    return true;\n  }\n\n  /**\n   * Gets the default connection type for a incoming connection to this layer.\n   *\n   * @returns the default incoming connection\n   */\n  public getDefaultIncomingConnectionType(): ConnectionType {\n    return ConnectionType.ALL_TO_ALL;\n  }\n}\n","import {ActivationType, Logistic} from 'activations/build/src';\nimport {ConnectionType} from '../../../enums/ConnectionType';\nimport {NodeType} from '../../../enums/NodeType';\nimport {Node} from '../../Node';\nimport {Layer} from '../Layer';\n\n/**\n * RNN layer\n */\nexport class RNNLayer extends Layer {\n  constructor(\n    outputSize: number,\n    options: {\n      /**\n       * The activation type for the output nodes of this layer.\n       */\n      activation?: ActivationType;\n    } = {}\n  ) {\n    super(outputSize);\n\n    for (let i = 0; i < outputSize; i++) {\n      this.inputNodes.add(\n        new Node(NodeType.HIDDEN).setActivationType(\n          options.activation ?? Logistic\n        )\n      );\n    }\n\n    this.outputNodes = this.inputNodes;\n    this.nodes.push(...Array.from(this.inputNodes));\n\n    // Adding self connections\n    this.connections.push(\n      ...Layer.connect(this.nodes, this.nodes, ConnectionType.ONE_TO_ONE)\n    );\n  }\n\n  /**\n   * Checks if a given connection type is allowed on this layer.\n   *\n   * @return Is this connection type allowed?\n   */\n  public connectionTypeisAllowed(): boolean {\n    return true;\n  }\n\n  /**\n   * Gets the default connection type for a incoming connection to this layer.\n   *\n   * @returns the default incoming connection\n   */\n  public getDefaultIncomingConnectionType(): ConnectionType {\n    return ConnectionType.ALL_TO_ALL;\n  }\n}\n","/**\n * Built-in learning rate policies, which allow for a dynamic learning rate during neural network training.\n *\n * @see [Learning rates and how-to improve performance](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10)\n * @see [Learning rate policy](https://stackoverflow.com/questions/30033096/what-is-lr-policy-in-caffe/30045244)\n *\n */\nabstract class Rate {\n  /**\n   * The rate at the first iteration.\n   */\n  protected readonly baseRate: number;\n\n  /**\n   * Constructs a rate policy\n   * @param baseRate the rate at first iteration\n   */\n  constructor(baseRate: number) {\n    this.baseRate = baseRate;\n  }\n\n  /**\n   * Calculates the current training rate.\n   *\n   * @param iteration count\n   * @returns the current training rate\n   */\n  public abstract calc(iteration: number): number;\n}\n\n/**\n * Fixed Learning Rate\n *\n * Default rate policy. Using this will make learning rate static (no change). Useful as a way to update a previous rate policy.\n */\nclass FixedRate extends Rate {\n  /**\n   * Calculates the current training rate.\n   *\n   * @returns the current training rate\n   */\n  public calc(): number {\n    return this.baseRate;\n  }\n}\n\n/**\n * Step Learning Rate\n *\n * The learning rate will decrease (i.e. 'step down') every `stepSize` iterations.\n */\nclass StepRate extends Rate {\n  /**\n   * Learning rate retention per step; - _0 < `gamma` < 1_ - _large `gamma` CAN cause networks to never converge, low `gamma` CAN cause networks to converge too quickly_\n   */\n  private readonly gamma: number;\n  /**\n   * Learning rate is updated every `step_size` iterations\n   */\n  private readonly stepSize: number;\n\n  /**\n   * Constructs a step rate policy.\n   *\n   * @param baseRate the rate at first iteration\n   * @param gamma=0.9 Learning rate retention per step; - _0 < `gamma` < 1_ - _large `gamma` CAN cause networks to never converge, low `gamma` CAN cause networks to converge too quickly_\n   * @param stepSize=100 Learning rate is updated every `step_size` iterations\n   */\n  constructor(baseRate: number, gamma = 0.9, stepSize = 100) {\n    super(baseRate);\n    this.gamma = gamma;\n    this.stepSize = stepSize;\n  }\n\n  /**\n   * Calculates the current training rate.\n   *\n   * @param iteration count\n   * @returns the current training rate\n   */\n  public calc(iteration: number): number {\n    return this.baseRate * this.gamma ** Math.floor(iteration / this.stepSize);\n  }\n}\n\n/**\n * Exponential Learning Rate\n *\n * The learning rate will exponentially decrease.\n *\n * The rate at `iteration` is calculated as: `rate = base_rate * Math.pow(gamma, iteration)`\n */\nclass ExponentialRate extends Rate {\n  /**\n   * Learning rate retention per step; - _0 < `gamma` < 1_ - _large `gamma` CAN cause networks to never converge, low `gamma` CAN cause networks to converge too quickly_\n   */\n  private readonly gamma: number;\n\n  /**\n   * Constructs a step rate policy.\n   *\n   * @param baseRate the rate at first iteration\n   * @param gamma=0.9 Learning rate retention per step; - _0 < `gamma` < 1_ - _large `gamma` CAN cause networks to never converge, low `gamma` CAN cause networks to converge too quickly_\n   */\n  constructor(baseRate: number, gamma = 0.999) {\n    super(baseRate);\n    this.gamma = gamma;\n  }\n\n  /**\n   * Calculates the current training rate.\n   *\n   * @param iteration count\n   * @returns the current training rate\n   */\n  public calc(iteration: number): number {\n    return this.baseRate * this.gamma ** iteration;\n  }\n}\n\n/**\n * Inverse Exponential Learning Rate\n *\n * The learning rate will exponentially decrease.\n *\n * The rate at `iteration` is calculated as: `rate = baseRate * Math.pow(1 + gamma * iteration, -power)`\n */\nclass InverseRate extends Rate {\n  /**\n   * Learning rate decay per iteration; - _0 < `gamma` < 1_ - _large `gamma` CAN cause networks to converge too quickly and stop learning, low `gamma` CAN cause networks to converge to learn VERY slowly_\n   */\n  private readonly gamma: number;\n  /**\n   * Decay rate per iteration - _0 < `power`_ - _large `power` CAN cause networks to stop learning quickly, low `power` CAN cause networks to learn VERY slowly_\n   */\n  private readonly power: number;\n\n  /**\n   * Constructs a step rate policy.\n   *\n   * @param baseRate the rate at first iteration\n   * @param gamma=0.001 Learning rate decay per iteration; - _0 < `gamma` < 1_ - _large `gamma` CAN cause networks to converge too quickly and stop learning, low `gamma` CAN cause networks to converge to learn VERY slowly_\n   * @param power=2 Decay rate per iteration - _0 < `power`_ - _large `power` CAN cause networks to stop learning quickly, low `power` CAN cause networks to learn VERY slowly_\n   */\n  constructor(baseRate: number, gamma = 0.001, power = 2) {\n    super(baseRate);\n    this.gamma = gamma;\n    this.power = power;\n  }\n\n  /**\n   * Calculates the current training rate.\n   *\n   * @param iteration count\n   * @returns the current training rate\n   */\n  public calc(iteration: number): number {\n    return this.baseRate * (1 + this.gamma * iteration) ** -this.power;\n  }\n}\n\nexport {Rate, FixedRate, StepRate, ExponentialRate, InverseRate};\n","import {lossType, MSELoss} from '../methods/Loss';\nimport {FixedRate, Rate} from '../methods/Rate';\n\n/**\n * Options used to train network\n */\nexport class TrainOptions {\n  constructor(\n    dataset: {\n      /**\n       * The input values\n       */\n      input: number[];\n      /**\n       * The target output values\n       */\n      output: number[];\n    }[]\n  ) {\n    this._dataset = dataset;\n    this._iterations = -1;\n    this._error = -1;\n    this._loss = MSELoss;\n    this._dropout = 0;\n    this._momentum = 0;\n    this._batchSize = this.dataset.length;\n    this._rate = new FixedRate(0.3);\n    this._log = -1;\n    this._crossValidateTestSize = -1;\n    this._shuffle = false;\n    this._clear = false;\n  }\n\n  /**\n   * A data of input values and ideal output values to train the network with\n   */\n  private _dataset: {\n    /**\n     * The input values\n     */\n    input: number[];\n    /**\n     * The target output values\n     */\n    output: number[];\n  }[];\n\n  /**\n   * Getter\n   */\n  public get dataset(): {\n    /**\n     * The input values\n     */\n    input: number[];\n    /**\n     * The target output values\n     */\n    output: number[];\n  }[] {\n    return this._dataset;\n  }\n\n  /**\n   * Setter\n   */\n  public set dataset(\n    value: {\n      /**\n       * The input values\n       */\n      input: number[];\n      /**\n       * The target output values\n       */\n      output: number[];\n    }[]\n  ) {\n    this._dataset = value;\n  }\n\n  /**\n   * If set to true, will shuffle the training data every iterationNumber. Good option to use if the network is performing worse in [cross validation](https://artint.info/html/ArtInt_189.html) than in the real training data.\n   */\n  private _shuffle: boolean;\n\n  /**\n   * Getter\n   */\n  public get shuffle(): boolean {\n    return this._shuffle;\n  }\n\n  /**\n   * Setter\n   */\n  public set shuffle(value: boolean) {\n    this._shuffle = value;\n  }\n\n  /**\n   * If set to true, will clear the network after every activation. This is useful for training LSTM's, more importantly for time series prediction.\n   */\n  private _clear: boolean;\n\n  /**\n   * Getter\n   */\n  public get clear(): boolean {\n    return this._clear;\n  }\n\n  /**\n   * Setter\n   */\n  public set clear(value: boolean) {\n    this._clear = value;\n  }\n\n  /**\n   * You can schedule tasks to happen every n iterations. Paired with `options.schedule.function`\n   */\n  private _schedule?: {\n    /**\n     * You can schedule tasks to happen every n iterations. Paired with `options.schedule.function`\n     */\n    iterations: number;\n    /**\n     * A function to run every n iterations as data by `options.schedule.iterations`. Passed as an object with a \"function\" property that contains the function to run.\n     *\n     * @param error the current network error\n     * @param iteration the current iteration count\n     */\n    function: (error: number, iteration: number) => undefined;\n  };\n\n  /**\n   * Getter\n   */\n  public get schedule():\n    | {\n        /**\n         * You can schedule tasks to happen every n iterations. Paired with `options.schedule.function`\n         */\n        iterations: number;\n        /**\n         * A function to run every n iterations as data by `options.schedule.iterations`. Passed as an object with a \"function\" property that contains the function to run.\n         *\n         * @param error the current network error\n         * @param iteration the current iteration count\n         */\n        function: (error: number, iteration: number) => undefined;\n      }\n    | undefined {\n    return this._schedule;\n  }\n\n  /**\n   * Setter\n   */\n  public set schedule(\n    value:\n      | {\n          /**\n           * You can schedule tasks to happen every n iterations. Paired with `options.schedule.function`\n           */\n          iterations: number;\n          /**\n           * A function to run every n iterations as data by `options.schedule.iterations`. Passed as an object with a \"function\" property that contains the function to run.\n           *\n           * @param error the current network error\n           * @param iteration the current iteration count\n           */\n          function: (error: number, iteration: number) => undefined;\n        }\n      | undefined\n  ) {\n    this._schedule = value;\n  }\n\n  /**\n   * Sets the amount of test cases that should be assigned to cross validation. If data to 0.4, 40% of the given data will be used for cross validation.\n   */\n  private _crossValidateTestSize: number;\n\n  /**\n   * Getter\n   */\n  public get crossValidateTestSize(): number {\n    return this._crossValidateTestSize;\n  }\n\n  /**\n   * Setter\n   */\n  public set crossValidateTestSize(value: number) {\n    this._crossValidateTestSize = value;\n  }\n\n  /**\n   * A [learning rate policy](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10), i.e. how to change the learning rate during training to better network performance\n   */\n  private _rate: Rate;\n\n  /**\n   * Getter\n   */\n  public get rate(): Rate {\n    return this._rate;\n  }\n\n  /**\n   * Setter\n   */\n  public set rate(value: Rate) {\n    this._rate = value;\n  }\n\n  /**\n   * The [options.loss function](https://en.wikipedia.org/wiki/Loss_function) used to determine network error\n   */\n  private _loss: lossType;\n\n  /**\n   * Getter\n   */\n  public get loss(): lossType {\n    return this._loss;\n  }\n\n  /**\n   * Setter\n   */\n  public set loss(value: lossType) {\n    this._loss = value;\n  }\n\n  /**\n   * Sets amount of training cycles the process will maximally run, even when the target error has not been reached.\n   */\n  private _iterations: number;\n\n  /**\n   * Getter\n   */\n  public get iterations(): number {\n    return this._iterations;\n  }\n\n  /**\n   * Setter\n   */\n  public set iterations(value: number) {\n    this._iterations = value;\n  }\n\n  /**\n   * The target error to train for, once the network falls below this error, the process is stopped. Lower error rates require more training cycles.\n   */\n  private _error: number;\n\n  /**\n   * Getter\n   */\n  public get error(): number {\n    return this._error;\n  }\n\n  /**\n   * Setter\n   */\n  public set error(value: number) {\n    this._error = value;\n  }\n\n  /**\n   * [Momentum](https://www.willamette.edu/~gorr/classes/cs449/momrate.html). Adds a fraction of the previous weight update to the current one.\n   */\n  private _momentum: number;\n\n  /**\n   * Getter\n   */\n  public get momentum(): number {\n    return this._momentum;\n  }\n\n  /**\n   * Setter\n   */\n  public set momentum(value: number) {\n    this._momentum = value;\n  }\n\n  /**\n   * [Dropout rate](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-options.dropout-in-deep-machine-learning-74334da4bfc5) likelihood for any given neuron to be ignored during network training. Must be between zero and one, numbers closer to one will result in more neurons ignored.\n   */\n  private _dropout: number;\n\n  /**\n   * Getter\n   */\n  public get dropout(): number {\n    return this._dropout;\n  }\n\n  /**\n   * Setter\n   */\n  public set dropout(value: number) {\n    this._dropout = value;\n  }\n\n  /**\n   * If set to n, outputs training status every n iterations. Setting `log` to 1 will log the status every iteration_number\n   */\n  private _log: number;\n\n  /**\n   * Getter\n   */\n  public get log(): number {\n    return this._log;\n  }\n\n  /**\n   * Setter\n   */\n  public set log(value: number) {\n    this._log = value;\n  }\n\n  /**\n   * Sets the (mini-) batch size of your training. Default: 1 [(online training)](https://www.quora.com/What-is-the-difference-between-batch-online-and-mini-batch-training-in-neural-networks-Which-one-should-I-use-for-a-small-to-medium-sized-dataset-for-prediction-purposes)\n   */\n  private _batchSize: number;\n\n  /**\n   * Getter\n   */\n  public get batchSize(): number {\n    return this._batchSize;\n  }\n\n  /**\n   * Setter\n   */\n  public set batchSize(value: number) {\n    this._batchSize = value;\n  }\n}\n","import {Architect} from '../src/architecture/Architect';\nimport {Connection} from '../src/architecture/Connection';\nimport {ActivationLayer} from '../src/architecture/Layers/CoreLayers/ActivationLayer';\nimport {DenseLayer} from '../src/architecture/Layers/CoreLayers/DenseLayer';\nimport {DropoutLayer} from '../src/architecture/Layers/CoreLayers/DropoutLayer';\nimport {InputLayer} from '../src/architecture/Layers/CoreLayers/InputLayer';\nimport {OutputLayer} from '../src/architecture/Layers/CoreLayers/OutputLayer';\nimport {Layer} from '../src/architecture/Layers/Layer';\nimport {NoiseLayer} from '../src/architecture/Layers/NoiseLayers/NoiseLayer';\nimport {AvgPooling1DLayer} from '../src/architecture/Layers/PoolingLayers/AvgPooling1DLayer';\nimport {GlobalAvgPooling1DLayer} from '../src/architecture/Layers/PoolingLayers/GlobalAvgPooling1DLayer';\nimport {GlobalMaxPooling1DLayer} from '../src/architecture/Layers/PoolingLayers/GlobalMaxPooling1DLayer';\nimport {GlobalMinPooling1DLayer} from '../src/architecture/Layers/PoolingLayers/GlobalMinPooling1DLayer';\nimport {MaxPooling1DLayer} from '../src/architecture/Layers/PoolingLayers/MaxPooling1DLayer';\nimport {MinPooling1DLayer} from '../src/architecture/Layers/PoolingLayers/MinPooling1DLayer';\nimport {PoolingLayer} from '../src/architecture/Layers/PoolingLayers/PoolingLayer';\nimport {GRULayer} from '../src/architecture/Layers/RecurrentLayers/GRULayer';\nimport {HopfieldLayer} from '../src/architecture/Layers/RecurrentLayers/HopfieldLayer';\nimport {LSTMLayer} from '../src/architecture/Layers/RecurrentLayers/LSTMLayer';\nimport {MemoryLayer} from '../src/architecture/Layers/RecurrentLayers/MemoryLayer';\nimport {RNNLayer} from '../src/architecture/Layers/RecurrentLayers/RNNLayer';\nimport {Network} from '../src/architecture/Network';\nimport {Node} from '../src/architecture/Node';\nimport {ConstantNode} from '../src/architecture/Nodes/ConstantNode';\nimport {DropoutNode} from '../src/architecture/Nodes/DropoutNode';\nimport {NoiseNode} from '../src/architecture/Nodes/NoiseNode';\nimport {PoolNode} from '../src/architecture/Nodes/PoolNode';\nimport {Species} from '../src/architecture/Species';\nimport {ConnectionType} from '../src/enums/ConnectionType';\nimport {GatingType} from '../src/enums/GatingType';\nimport {NodeType, NoiseNodeType, PoolNodeType} from '../src/enums/NodeType';\nimport {ConnectionJSON} from '../src/interfaces/ConnectionJSON';\nimport {EvolveOptions} from '../src/interfaces/EvolveOptions';\nimport {NetworkJSON} from '../src/interfaces/NetworkJSON';\nimport {\n  DropoutNodeJSON,\n  NodeJSON,\n  PoolNodeJSON,\n} from '../src/interfaces/NodeJSON';\nimport {TrainOptions} from '../src/interfaces/TrainOptions';\nimport {\n  ALL_LOSSES,\n  BinaryLoss,\n  HINGELoss,\n  MAELoss,\n  MAPELoss,\n  MBELoss,\n  MSELoss,\n  MSLELoss,\n  WAPELoss,\n} from '../src/methods/Loss';\nimport {\n  AddBackConnectionMutation,\n  AddConnectionMutation,\n  AddGateMutation,\n  AddNodeMutation,\n  AddSelfConnectionMutation,\n  ALL_MUTATIONS,\n  FEEDFORWARD_MUTATIONS,\n  ModActivationMutation,\n  ModBiasMutation,\n  ModWeightMutation,\n  Mutation,\n  NO_STRUCTURE_MUTATIONS,\n  ONLY_STRUCTURE,\n  SubBackConnectionMutation,\n  SubConnectionMutation,\n  SubGateMutation,\n  SubNodeMutation,\n  SubSelfConnectionMutation,\n  SwapNodesMutation,\n} from '../src/methods/Mutation';\nimport {\n  ExponentialRate,\n  FixedRate,\n  InverseRate,\n  Rate,\n  StepRate,\n} from '../src/methods/Rate';\nimport {\n  FitnessProportionateSelection,\n  PowerSelection,\n  Selection,\n  TournamentSelection,\n} from '../src/methods/Selection';\nimport {\n  avg,\n  generateGaussian,\n  max,\n  maxValueIndex,\n  min,\n  minValueIndex,\n  pickRandom,\n  randBoolean,\n  randDouble,\n  randInt,\n  removeFromArray,\n  shuffle,\n  sum,\n} from '../src/utils/Utils';\n\n// TODO this could be more beautiful and also dynamic\nexport {\n  DenseLayer,\n  DropoutLayer,\n  InputLayer,\n  OutputLayer,\n  NoiseLayer,\n  AvgPooling1DLayer,\n  MinPooling1DLayer,\n  MaxPooling1DLayer,\n  GlobalAvgPooling1DLayer,\n  GlobalMinPooling1DLayer,\n  GlobalMaxPooling1DLayer,\n  PoolingLayer,\n  ActivationLayer,\n  HopfieldLayer,\n  RNNLayer,\n  GRULayer,\n  LSTMLayer,\n  MemoryLayer,\n  Layer,\n  ConstantNode,\n  DropoutNode,\n  NoiseNode,\n  PoolNode,\n  Architect,\n  Connection,\n  Network,\n  Species,\n  Node,\n  ConnectionType,\n  GatingType,\n  NodeType,\n  PoolNodeType,\n  NoiseNodeType,\n  ConnectionJSON,\n  EvolveOptions,\n  NetworkJSON,\n  NodeJSON,\n  PoolNodeJSON,\n  DropoutNodeJSON,\n  TrainOptions,\n  ALL_LOSSES,\n  MSELoss,\n  MBELoss,\n  BinaryLoss,\n  MAELoss,\n  MAPELoss,\n  WAPELoss,\n  MSLELoss,\n  HINGELoss,\n  ALL_MUTATIONS,\n  FEEDFORWARD_MUTATIONS,\n  NO_STRUCTURE_MUTATIONS,\n  ONLY_STRUCTURE,\n  Mutation,\n  AddNodeMutation,\n  SubNodeMutation,\n  AddConnectionMutation,\n  SubConnectionMutation,\n  ModWeightMutation,\n  ModBiasMutation,\n  ModActivationMutation,\n  AddGateMutation,\n  SubGateMutation,\n  AddSelfConnectionMutation,\n  SubSelfConnectionMutation,\n  AddBackConnectionMutation,\n  SubBackConnectionMutation,\n  SwapNodesMutation,\n  Rate,\n  FixedRate,\n  StepRate,\n  ExponentialRate,\n  InverseRate,\n  Selection,\n  FitnessProportionateSelection,\n  PowerSelection,\n  TournamentSelection,\n  pickRandom,\n  randInt,\n  randDouble,\n  randBoolean,\n  removeFromArray,\n  shuffle,\n  max,\n  maxValueIndex,\n  minValueIndex,\n  min,\n  sum,\n  avg,\n  generateGaussian,\n};\n"]}